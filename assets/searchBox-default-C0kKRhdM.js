const t='{"documentCount":185,"nextId":185,"documentIds":{"0":"/article/8szf7f9j/#前言","1":"/article/8djf7t1b/#一、本文介绍","2":"/article/8szf7f9j/#_1-tex-live-下载与安装","3":"/article/3pv1asqx/#一、本文介绍","4":"/article/8djf7t1b/#二、biformer的作用机制","5":"/article/ebule7cy/#一、本文介绍","6":"/article/8szf7f9j/#_2-vscode下载与安装","7":"/article/3pv1asqx/#二、rcs-osa模块原理","8":"/article/ln4qficp/#一、本文介绍","9":"/article/8djf7t1b/#三、biformer的优劣势","10":"/article/ebule7cy/#二、triplet-attention机制原理","11":"/article/8szf7f9j/#_3-中文语言环境配置","12":"/article/3pv1asqx/#_2-1-rcs-osa的基本原理","13":"/article/ln4qficp/#二、msda框架原理","14":"/article/l7o183q2/#一、本文介绍","15":"/article/8djf7t1b/#四、biformer的结构","16":"/article/ebule7cy/#_2-1-triplet-attention的基本原理","17":"/article/8szf7f9j/#_4-latex的支持插件-latex-workshop安装","18":"/article/3pv1asqx/#_2-2-rcs","19":"/article/ln4qficp/#三、msda核心代码","20":"/article/l7o183q2/#二、lskattention的机制原理","21":"/article/llrg5yeo/#一、本文介绍","22":"/article/8djf7t1b/#五、添加biformer注意力机制","23":"/article/ebule7cy/#_2-2-triplet-attention和其它简单注意力机制的对比","24":"/article/8szf7f9j/#_5-打开latex环境设置页面","25":"/article/3pv1asqx/#_2-3-rcs模块","26":"/article/ln4qficp/#四、手把手教你添加msda模块","27":"/article/l7o183q2/#三、lskattention的代码","28":"/article/llrg5yeo/#二、hattention框架原理","29":"/article/7qi9b2wu/#一、本文介绍","30":"/article/8djf7t1b/#步骤一","31":"/article/ebule7cy/#_2-3-triplet-attention的实现流程","32":"/article/8szf7f9j/#_6-latex环境的代码配置","33":"/article/3pv1asqx/#_2-4-osa","34":"/article/ln4qficp/#_4-1-msda添加步骤","35":"/article/l7o183q2/#四、手把手教你将lskattention添加到你的网络结构中","36":"/article/llrg5yeo/#_2-1-混合注意力变换器-hat","37":"/article/7qi9b2wu/#二、focused-linear-attention的机制原理","38":"/article/3cw8b7e9/#一、本文介绍","39":"/article/8djf7t1b/#步骤二","40":"/article/ebule7cy/#三、triplet-attention的完整代码","41":"/article/8szf7f9j/#_6-1-latex配置代码展示","42":"/article/3pv1asqx/#_2-5-特征级联","43":"/article/ln4qficp/#_4-1-1-步骤一","44":"/article/l7o183q2/#_4-1-lskattention的添加教程","45":"/article/llrg5yeo/#三、hattention的核心代码","46":"/article/7qi9b2wu/#_2-1-softmax和线性注意力机制的对比","47":"/article/3cw8b7e9/#二、-deformable-lka机制原理","48":"/article/2p0fwpcg/#一、本文介绍","49":"/article/8djf7t1b/#步骤三","50":"/article/ebule7cy/#_3-1-triplet-attention的核心代码","51":"/article/8szf7f9j/#_6-2-latex配置代码解读","52":"/article/3pv1asqx/#三、rcs-osa核心代码","53":"/article/ln4qficp/#_4-1-2-步骤二","54":"/article/l7o183q2/#_4-2-lskattention的yaml文件和训练截图","55":"/article/llrg5yeo/#四、手把手教你添加hattention机制","56":"/article/7qi9b2wu/#_2-2-focused-linear-attention的提出","57":"/article/3cw8b7e9/#_2-1-deformable-lka的基本原理","58":"/article/2p0fwpcg/#二、dat的网络结构思想","59":"/article/uirz1e4c/#一、本文介绍","60":"/article/8djf7t1b/#六、配置biformer注意力机制","61":"/article/ebule7cy/#_3-2-修改了triplet-attention机制的c2f和bottleneck","62":"/article/8szf7f9j/#_7-tex文件编译","63":"/article/3pv1asqx/#四、手把手教你添加rcs-osa模块","64":"/article/ln4qficp/#_4-1-3-步骤三","65":"/article/l7o183q2/#_4-2-1-lskattention的yaml文件","66":"/article/llrg5yeo/#修改一","67":"/article/7qi9b2wu/#_2-3-效果对比","68":"/article/3cw8b7e9/#_2-2-大卷积核","69":"/article/2p0fwpcg/#_2-1-dat的主要思想和改进","70":"/article/uirz1e4c/#_2-1-acmix的基本原理","71":"/article/8djf7t1b/#七、训练模型","72":"/article/ebule7cy/#四、手把手教你添加triplet-attention","73":"/article/8szf7f9j/#_7-1-tex测试文件下载","74":"/article/3pv1asqx/#_4-1-rcs-osa添加步骤","75":"/article/ln4qficp/#_4-2-msda的yaml文件和训练截图","76":"/article/l7o183q2/#_4-2-2-lskattention的训练过程截图","77":"/article/llrg5yeo/#修改二","78":"/article/7qi9b2wu/#三、实验效果对比","79":"/article/3cw8b7e9/#_2-3-可变形卷积","80":"/article/2p0fwpcg/#_2-2-dat的网络结构图","81":"/article/uirz1e4c/#_2-1-1-自注意力和卷积的整合","82":"/article/8djf7t1b/#八、结果分析","83":"/article/ebule7cy/#_4-1-triplet-attention的添加教程","84":"/article/8szf7f9j/#_7-2-tex-测试文件编译","85":"/article/3pv1asqx/#_4-1-1-步骤一","86":"/article/ln4qficp/#_4-2-1-msda的yaml版本一-推荐","87":"/article/l7o183q2/#五、lskattention可添加的位置","88":"/article/llrg5yeo/#五、hattention的yaml文件","89":"/article/7qi9b2wu/#四、focusedlinearattention代码","90":"/article/3cw8b7e9/#_2-4-2d和3d适应性","91":"/article/2p0fwpcg/#_2-3-dat和其他机制的对比","92":"/article/uirz1e4c/#_2-1-2-运算分解与重构","93":"/article/a9jn9iq6/#标题-2","94":"/article/ebule7cy/#_4-2-triplet-attention的yaml文件和训练截图","95":"/article/8szf7f9j/#_8-sumatrapdf-安装设置-可选","96":"/article/3pv1asqx/#_4-1-2-步骤二","97":"/article/ln4qficp/#_4-2-2-msda的yaml版本二","98":"/article/l7o183q2/#_5-1-推荐lskattention可添加的位置","99":"/article/llrg5yeo/#_5-1-hattention的yaml文件一","100":"/article/7qi9b2wu/#五、添加focused-linear-attention到模型中","101":"/article/3cw8b7e9/#三、d-lka代码和c2f-d-lka","102":"/article/2p0fwpcg/#三、dat即插即用的代码块","103":"/article/uirz1e4c/#四、手把手教你添加acmix","104":"/article/a9jn9iq6/#标题-3","105":"/stack/pjtlad1w/#简介","106":"/article/ebule7cy/#_4-2-1-triplet-attention的yaml文件一-推荐","107":"/stack/pjqaed1w/#为什么选择在-roboflow-上进行数据增强","108":"/article/8szf7f9j/#_8-1-sumatrapdf下载与安装","109":"/article/3pv1asqx/#_4-1-3-步骤三","110":"/article/ln4qficp/#_4-3-推荐msda可添加的位置","111":"/article/l7o183q2/#_5-2图示lskattention可添加的位置","112":"/article/llrg5yeo/#_5-2-hattention的训练过程截图","113":"/article/7qi9b2wu/#_5-1-focused-linear-attention的添加教程","114":"/article/3cw8b7e9/#四、手把手教你添加d-lka","115":"/article/2p0fwpcg/#四、添加dat到你的网络中","116":"/article/uirz1e4c/#_4-1-acmix添加步骤","117":"/article/a9jn9iq6/#标题-4","118":"/stack/pjtlad1w/#roboflow的官方地址","119":"/article/ebule7cy/#_4-2-2-triplet-attention的yaml文件二","120":"/stack/pjqaed1w/#roboflow具备数据增强的功能","121":"/article/8szf7f9j/#_8-2-使用sumatrapdf查看的代码配置","122":"/article/3pv1asqx/#_4-2-rcs-osa的yaml文件和训练截图","123":"/article/ln4qficp/#_4-4-msda的训练过程截图","124":"/article/7qi9b2wu/#_5-2-focused-linear-attention的yaml文件和训练截图","125":"/article/3cw8b7e9/#_4-1-1-修改一","126":"/article/2p0fwpcg/#_4-1-dat的yaml文件和训练过程","127":"/article/uirz1e4c/#_4-1-1-步骤一","128":"/article/a9jn9iq6/#标题-5","129":"/stack/pjtlad1w/#roboflow具有的数据预处理","130":"/article/ebule7cy/#_4-2-2-d-lka的训练过程截图","131":"/stack/pjqaed1w/#翻转","132":"/article/8szf7f9j/#_8-2-1-代码展示","133":"/article/3pv1asqx/#_4-2-1-rcs-osa的yaml版本一-推荐","134":"/article/7qi9b2wu/#_5-2-1-focused-linear-attention的yaml文件","135":"/article/3cw8b7e9/#_4-1-2-修改二","136":"/article/2p0fwpcg/#五、dat可添加的位置","137":"/article/uirz1e4c/#_4-1-2-步骤二","138":"/article/a9jn9iq6/#标题-6","139":"/stack/pjtlad1w/#自动定向","140":"/article/ebule7cy/#五、triplet-attention可添加的位置","141":"/stack/pjqaed1w/#_90度旋转","142":"/article/8szf7f9j/#_8-2-2-代码解读","143":"/article/3pv1asqx/#_4-2-2-rcs-osa的yaml版本二","144":"/article/7qi9b2wu/#_5-2-2-focused-linear-attention的训练过程截图","145":"/article/3cw8b7e9/#_4-1-3-修改三","146":"/article/2p0fwpcg/#_5-1推荐dat可添加的位置","147":"/article/uirz1e4c/#_4-1-3-步骤三","148":"/stack/pjtlad1w/#调整","149":"/article/ebule7cy/#_5-1-推荐triplet-attention可添加的位置","150":"/stack/pjqaed1w/#随机裁剪","151":"/article/8szf7f9j/#_9-sumatrapdf-的使用","152":"/article/3pv1asqx/#_4-2-2-rcs-osa的训练过程截图","153":"/article/3cw8b7e9/#_4-1-4-修改四","154":"/article/2p0fwpcg/#_5-2图示dat可添加的位置","155":"/article/uirz1e4c/#五、acmix的yaml文件和运行记录","156":"/stack/pjtlad1w/#灰度","157":"/article/ebule7cy/#_5-2-图示d-lka可添加的位置","158":"/stack/pjqaed1w/#随机剪切","159":"/article/8szf7f9j/#_10-pdf-内部查看与外部查看的切换","160":"/article/3cw8b7e9/#_4-2-d-lka的yaml文件和训练截图-仔细看这个否则会报错","161":"/article/uirz1e4c/#_5-1-acmix的yaml版本一-推荐","162":"/stack/pjtlad1w/#自动调整对比度","163":"/stack/pjqaed1w/#噪声","164":"/article/8szf7f9j/#_11-个人完整配置","165":"/article/3cw8b7e9/#_4-2-1-d-lka的yaml文件一-推荐","166":"/article/uirz1e4c/#_5-2-acmix的yaml版本二","167":"/stack/pjtlad1w/#隔离对象","168":"/stack/pjqaed1w/#曝光","169":"/article/3cw8b7e9/#_4-2-2-d-lka的yaml文件二","170":"/article/uirz1e4c/#_5-3-推荐acmix可添加的位置","171":"/stack/pjtlad1w/#静态裁剪","172":"/stack/pjqaed1w/#随机噪声","173":"/article/3cw8b7e9/#_4-2-2-d-lka的训练过程截图","174":"/article/uirz1e4c/#_5-4-acmix的训练过程截图","175":"/stack/pjtlad1w/#切片","176":"/stack/pjqaed1w/#边界框扩充","177":"/article/3cw8b7e9/#五、d-lka可添加的位置","178":"/stack/pjtlad1w/#修改类","179":"/stack/pjqaed1w/#数据增强操作过程","180":"/article/3cw8b7e9/#_5-1-推荐d-lka可添加的位置","181":"/stack/pjtlad1w/#筛选器空","182":"/article/3cw8b7e9/#_5-2-图示d-lka可添加的位置","183":"/stack/pjtlad1w/#按标签筛选","184":"/stack/pjtlad1w/#数据预处理具体操作流程"},"fieldIds":{"title":0,"titles":1,"text":2},"fieldLength":{"0":[1,2,63],"1":[2,2,19],"2":[4,2,142],"3":[2,3,24],"4":[2,2,98],"5":[2,3,19],"6":[2,2,32],"7":[3,3,5],"8":[2,2,23],"9":[2,2,52],"10":[3,3,5],"11":[2,2,36],"12":[4,4,34],"13":[2,2,97],"14":[2,2,16],"15":[2,2,33],"16":[4,4,55],"17":[4,2,36],"18":[2,4,16],"19":[2,2,311],"20":[2,2,106],"21":[2,2,12],"22":[2,2,8],"23":[3,4,65],"24":[2,2,36],"25":[3,4,33],"26":[2,2,1],"27":[2,2,64],"28":[2,2,81],"29":[2,2,22],"30":[1,3,346],"31":[4,4,40],"32":[2,2,1],"33":[3,4,46],"34":[3,3,1],"35":[2,2,1],"36":[5,3,33],"37":[4,2,5],"38":[2,2,18],"39":[1,3,12],"40":[3,3,1],"41":[3,3,105],"42":[3,4,47],"43":[3,6,9],"44":[3,3,24],"45":[2,2,582],"46":[3,5,53],"47":[3,2,6],"48":[2,2,26],"49":[1,3,20],"50":[4,4,84],"51":[3,3,259],"52":[3,3,221],"53":[4,6,12],"54":[3,3,1],"55":[2,2,8],"56":[4,5,37],"57":[4,4,29],"58":[2,2,7],"59":[2,2,19],"60":[2,2,150],"61":[4,4,104],"62":[2,2,1],"63":[3,3,1],"64":[4,6,13],"65":[4,6,10],"66":[1,3,12],"67":[3,5,66],"68":[2,4,51],"69":[3,3,31],"70":[3,3,25],"71":[2,2,13],"72":[3,3,1],"73":[3,3,74],"74":[4,5,1],"75":[3,3,8],"76":[3,6,2],"77":[1,3,18],"78":[2,2,7],"79":[3,4,12],"80":[2,3,22],"81":[3,6,51],"82":[2,2,8],"83":[4,4,22],"84":[4,3,96],"85":[3,8,9],"86":[6,6,138],"87":[2,2,1],"88":[2,2,9],"89":[2,2,217],"90":[3,4,41],"91":[3,3,7],"92":[3,6,183],"93":[2,2,1],"94":[4,4,1],"95":[5,2,31],"96":[4,8,12],"97":[3,6,134],"98":[3,3,22],"99":[3,3,136],"100":[4,2,1],"101":[4,2,198],"102":[2,2,217],"103":[2,2,1],"104":[2,3,1],"105":[1,2,16],"106":[7,7,135],"107":[4,2,26],"108":[3,6,12],"109":[4,8,10],"110":[3,3,20],"111":[2,3,1],"112":[3,3,8],"113":[5,5,19],"114":[3,2,1],"115":[2,2,1],"116":[3,3,1],"117":[2,4,1],"118":[1,2,2],"119":[4,7,137],"120":[1,2,20],"121":[3,6,1],"122":[4,5,1],"123":[2,3,3],"124":[5,5,1],"125":[3,7,8],"126":[3,3,3],"127":[3,6,8],"128":[2,5,1],"129":[1,2,20],"130":[4,7,4],"131":[1,2,11],"132":[4,7,45],"133":[7,8,136],"134":[6,9,6],"135":[4,7,5],"136":[2,2,1],"137":[4,6,12],"138":[2,6,174],"139":[1,3,16],"140":[3,3,1],"141":[1,2,13],"142":[3,7,104],"143":[4,8,132],"144":[5,9,6],"145":[4,7,7],"146":[2,3,22],"147":[4,6,20],"148":[1,3,67],"149":[4,4,19],"150":[1,2,9],"151":[3,2,42],"152":[4,8,6],"153":[3,7,5],"154":[2,3,1],"155":[2,2,8],"156":[1,3,21],"157":[4,4,2],"158":[1,2,8],"159":[3,2,10],"160":[6,4,1],"161":[5,3,140],"162":[1,3,21],"163":[1,2,8],"164":[2,2,145],"165":[7,10,135],"166":[3,3,134],"167":[1,3,13],"168":[1,2,12],"169":[4,10,138],"170":[3,3,15],"171":[1,3,3],"172":[1,2,6],"173":[4,10,4],"174":[3,3,3],"175":[1,3,13],"176":[1,2,9],"177":[3,2,1],"178":[1,3,17],"179":[1,2,38],"180":[4,4,24],"181":[1,3,28],"182":[4,4,2],"183":[1,3,17],"184":[1,2,46]},"averageFieldLength":[2.7675675675675664,3.616216216216216,43.772972972972966],"storedFields":{"0":{"title":"前言","titles":["vscode配置latex环境",null]},"1":{"title":"一、本文介绍","titles":["BiFormer",null]},"2":{"title":"1 TeX Live 下载与安装","titles":["vscode配置latex环境",null]},"3":{"title":"一、本文介绍","titles":["RCS-OSA",null]},"4":{"title":"二、Biformer的作用机制","titles":["BiFormer",null]},"5":{"title":"一、本文介绍","titles":["Triplet Attention",null]},"6":{"title":"2 vscode下载与安装","titles":["vscode配置latex环境",null]},"7":{"title":"二、RCS-OSA模块原理","titles":["RCS-OSA",null]},"8":{"title":"一、本文介绍","titles":["多尺度空洞注意力",null]},"9":{"title":"三、Biformer的优劣势","titles":["BiFormer",null]},"10":{"title":"二、Triplet Attention机制原理","titles":["Triplet Attention",null]},"11":{"title":"3 中文语言环境配置","titles":["vscode配置latex环境",null]},"12":{"title":"2.1 RCS-OSA的基本原理","titles":["RCS-OSA",null,"二、RCS-OSA模块原理"]},"13":{"title":"二、MSDA框架原理","titles":["多尺度空洞注意力",null]},"14":{"title":"一、本文介绍","titles":["大核注意力机制",null]},"15":{"title":"四、Biformer的结构","titles":["BiFormer",null]},"16":{"title":"2.1 Triplet Attention的基本原理","titles":["Triplet Attention",null,"二、Triplet Attention机制原理"]},"17":{"title":"4 LaTeX的支持插件 LaTeX Workshop安装","titles":["vscode配置latex环境",null]},"18":{"title":"2.2 RCS","titles":["RCS-OSA",null,"二、RCS-OSA模块原理"]},"19":{"title":"三、MSDA核心代码","titles":["多尺度空洞注意力",null]},"20":{"title":"二、LSKAttention的机制原理","titles":["大核注意力机制",null]},"21":{"title":"一、本文介绍","titles":["变换器HAT",null]},"22":{"title":"五、添加Biformer注意力机制","titles":["BiFormer",null]},"23":{"title":"2.2 Triplet Attention和其它简单注意力机制的对比","titles":["Triplet Attention",null,"二、Triplet Attention机制原理"]},"24":{"title":"5 打开LaTeX环境设置页面","titles":["vscode配置latex环境",null]},"25":{"title":"2.3 RCS模块","titles":["RCS-OSA",null,"二、RCS-OSA模块原理"]},"26":{"title":"四、手把手教你添加MSDA模块","titles":["多尺度空洞注意力",null]},"27":{"title":"三、LSKAttention的代码","titles":["大核注意力机制",null]},"28":{"title":"二、HAttention框架原理","titles":["变换器HAT",null]},"29":{"title":"一、本文介绍","titles":["聚焦线性注意力",null]},"30":{"title":"步骤一","titles":["BiFormer",null,"五、添加Biformer注意力机制"]},"31":{"title":"2.3 Triplet Attention的实现流程","titles":["Triplet Attention",null,"二、Triplet Attention机制原理"]},"32":{"title":"6 LaTeX环境的代码配置","titles":["vscode配置latex环境",null]},"33":{"title":"2.4 OSA","titles":["RCS-OSA",null,"二、RCS-OSA模块原理"]},"34":{"title":"4.1 MSDA添加步骤","titles":["多尺度空洞注意力",null,"四、手把手教你添加MSDA模块"]},"35":{"title":"四、手把手教你将LSKAttention添加到你的网络结构中","titles":["大核注意力机制",null]},"36":{"title":"2.1 混合注意力变换器（HAT）","titles":["变换器HAT",null,"二、HAttention框架原理"]},"37":{"title":"二、Focused Linear Attention的机制原理","titles":["聚焦线性注意力",null]},"38":{"title":"一、本文介绍","titles":["可变形大核注意力",null]},"39":{"title":"步骤二","titles":["BiFormer",null,"五、添加Biformer注意力机制"]},"40":{"title":"三、Triplet Attention的完整代码","titles":["Triplet Attention",null]},"41":{"title":"6.1 LaTeX配置代码展示","titles":["vscode配置latex环境",null,"6 LaTeX环境的代码配置"]},"42":{"title":"2.5 特征级联","titles":["RCS-OSA",null,"二、RCS-OSA模块原理"]},"43":{"title":"4.1.1 步骤一","titles":["多尺度空洞注意力",null,"四、手把手教你添加MSDA模块","4.1 MSDA添加步骤"]},"44":{"title":"4.1 LSKAttention的添加教程","titles":["大核注意力机制",null,"四、手把手教你将LSKAttention添加到你的网络结构中"]},"45":{"title":"三、HAttention的核心代码","titles":["变换器HAT",null]},"46":{"title":"2.1 Softmax和线性注意力机制的对比","titles":["聚焦线性注意力",null,"二、Focused Linear Attention的机制原理"]},"47":{"title":"二、 Deformable-LKA机制原理","titles":["可变形大核注意力",null]},"48":{"title":"一、本文介绍","titles":["DAT",null]},"49":{"title":"步骤三","titles":["BiFormer",null,"五、添加Biformer注意力机制"]},"50":{"title":"3.1 Triplet Attention的核心代码","titles":["Triplet Attention",null,"三、Triplet Attention的完整代码"]},"51":{"title":"6.2 LaTeX配置代码解读","titles":["vscode配置latex环境",null,"6 LaTeX环境的代码配置"]},"52":{"title":"三、RCS-OSA核心代码","titles":["RCS-OSA",null]},"53":{"title":"4.1.2 步骤二","titles":["多尺度空洞注意力",null,"四、手把手教你添加MSDA模块","4.1 MSDA添加步骤"]},"54":{"title":"4.2 LSKAttention的yaml文件和训练截图","titles":["大核注意力机制",null,"四、手把手教你将LSKAttention添加到你的网络结构中"]},"55":{"title":"四、手把手教你添加HAttention机制","titles":["变换器HAT",null]},"56":{"title":"2.2 Focused Linear Attention的提出","titles":["聚焦线性注意力",null,"二、Focused Linear Attention的机制原理"]},"57":{"title":"2.1 Deformable-LKA的基本原理","titles":["可变形大核注意力",null,"二、 Deformable-LKA机制原理"]},"58":{"title":"二、DAT的网络结构思想","titles":["DAT",null]},"59":{"title":"一、本文介绍","titles":["ACmix自注意力机制",null]},"60":{"title":"六、配置Biformer注意力机制","titles":["BiFormer",null]},"61":{"title":"3.2 修改了Triplet Attention机制的C2f和Bottleneck","titles":["Triplet Attention",null,"三、Triplet Attention的完整代码"]},"62":{"title":"7 tex文件编译","titles":["vscode配置latex环境",null]},"63":{"title":"四、手把手教你添加RCS-OSA模块","titles":["RCS-OSA",null]},"64":{"title":"4.1.3 步骤三","titles":["多尺度空洞注意力",null,"四、手把手教你添加MSDA模块","4.1 MSDA添加步骤"]},"65":{"title":"4.2.1 LSKAttention的yaml文件","titles":["大核注意力机制",null,"四、手把手教你将LSKAttention添加到你的网络结构中","4.2 LSKAttention的yaml文件和训练截图"]},"66":{"title":"修改一","titles":["变换器HAT",null,"四、手把手教你添加HAttention机制"]},"67":{"title":"2.3 效果对比","titles":["聚焦线性注意力",null,"二、Focused Linear Attention的机制原理"]},"68":{"title":"2.2 大卷积核","titles":["可变形大核注意力",null,"二、 Deformable-LKA机制原理"]},"69":{"title":"2.1 DAT的主要思想和改进","titles":["DAT",null,"二、DAT的网络结构思想"]},"70":{"title":"2.1 ACMix的基本原理","titles":["ACmix自注意力机制",null,"一、本文介绍"]},"71":{"title":"七、训练模型","titles":["BiFormer",null]},"72":{"title":"四、手把手教你添加Triplet Attention","titles":["Triplet Attention",null]},"73":{"title":"7.1 tex测试文件下载","titles":["vscode配置latex环境",null,"7 tex文件编译"]},"74":{"title":"4.1 RCS-OSA添加步骤","titles":["RCS-OSA",null,"四、手把手教你添加RCS-OSA模块"]},"75":{"title":"4.2 MSDA的yaml文件和训练截图","titles":["多尺度空洞注意力",null,"四、手把手教你添加MSDA模块"]},"76":{"title":"4.2.2 LSKAttention的训练过程截图","titles":["大核注意力机制",null,"四、手把手教你将LSKAttention添加到你的网络结构中","4.2 LSKAttention的yaml文件和训练截图"]},"77":{"title":"修改二","titles":["变换器HAT",null,"四、手把手教你添加HAttention机制"]},"78":{"title":"三、实验效果对比","titles":["聚焦线性注意力",null]},"79":{"title":"2.3 可变形卷积","titles":["可变形大核注意力",null,"二、 Deformable-LKA机制原理"]},"80":{"title":"2.2 DAT的网络结构图","titles":["DAT",null,"二、DAT的网络结构思想"]},"81":{"title":"2.1.1 自注意力和卷积的整合","titles":["ACmix自注意力机制",null,"一、本文介绍","2.1 ACMix的基本原理"]},"82":{"title":"八、结果分析","titles":["BiFormer",null]},"83":{"title":"4.1 Triplet Attention的添加教程","titles":["Triplet Attention",null,"四、手把手教你添加Triplet Attention"]},"84":{"title":"7.2 tex 测试文件编译","titles":["vscode配置latex环境",null,"7 tex文件编译"]},"85":{"title":"4.1.1 步骤一","titles":["RCS-OSA",null,"四、手把手教你添加RCS-OSA模块","4.1 RCS-OSA添加步骤"]},"86":{"title":"4.2.1 MSDA的yaml版本一(推荐)","titles":["多尺度空洞注意力",null,"四、手把手教你添加MSDA模块","4.2 MSDA的yaml文件和训练截图"]},"87":{"title":"五、LSKAttention可添加的位置","titles":["大核注意力机制",null]},"88":{"title":"五、HAttention的yaml文件","titles":["变换器HAT",null]},"89":{"title":"四、FocusedLinearAttention代码","titles":["聚焦线性注意力",null]},"90":{"title":"2.4 2D和3D适应性","titles":["可变形大核注意力",null,"二、 Deformable-LKA机制原理"]},"91":{"title":"2.3 DAT和其他机制的对比","titles":["DAT",null,"二、DAT的网络结构思想"]},"92":{"title":"2.1.2 运算分解与重构","titles":["ACmix自注意力机制",null,"一、本文介绍","2.1 ACMix的基本原理"]},"93":{"title":"标题 2","titles":["Markdown",null]},"94":{"title":"4.2 Triplet Attention的yaml文件和训练截图","titles":["Triplet Attention",null,"四、手把手教你添加Triplet Attention"]},"95":{"title":"8 SumatraPDF 安装设置（可选）","titles":["vscode配置latex环境",null]},"96":{"title":"4.1.2 步骤二","titles":["RCS-OSA",null,"四、手把手教你添加RCS-OSA模块","4.1 RCS-OSA添加步骤"]},"97":{"title":"4.2.2 MSDA的yaml版本二","titles":["多尺度空洞注意力",null,"四、手把手教你添加MSDA模块","4.2 MSDA的yaml文件和训练截图"]},"98":{"title":"5.1 推荐LSKAttention可添加的位置","titles":["大核注意力机制",null,"五、LSKAttention可添加的位置"]},"99":{"title":"5.1 HAttention的yaml文件一","titles":["变换器HAT",null,"五、HAttention的yaml文件"]},"100":{"title":"五、添加Focused Linear Attention到模型中","titles":["聚焦线性注意力",null]},"101":{"title":"三、D-LKA代码和C2f-D-LKA","titles":["可变形大核注意力",null]},"102":{"title":"三、DAT即插即用的代码块","titles":["DAT",null]},"103":{"title":"四、手把手教你添加ACmix","titles":["ACmix自注意力机制",null]},"104":{"title":"标题 3","titles":["Markdown",null,"标题 2"]},"105":{"title":"简介","titles":["Roboflow",null]},"106":{"title":"4.2.1 Triplet Attention的yaml文件一(推荐)","titles":["Triplet Attention",null,"四、手把手教你添加Triplet Attention","4.2 Triplet Attention的yaml文件和训练截图"]},"107":{"title":"为什么选择在 Roboflow 上进行数据增强?","titles":["ultralytics",null,null]},"108":{"title":"8.1 SumatraPDF下载与安装","titles":["vscode配置latex环境",null,"8 SumatraPDF 安装设置（可选）"]},"109":{"title":"4.1.3 步骤三","titles":["RCS-OSA",null,"四、手把手教你添加RCS-OSA模块","4.1 RCS-OSA添加步骤"]},"110":{"title":"4.3 推荐MSDA可添加的位置","titles":["多尺度空洞注意力",null,"四、手把手教你添加MSDA模块"]},"111":{"title":"5.2图示LSKAttention可添加的位置","titles":["大核注意力机制",null,"五、LSKAttention可添加的位置"]},"112":{"title":"5.2 HAttention的训练过程截图","titles":["变换器HAT",null,"五、HAttention的yaml文件"]},"113":{"title":"5.1 Focused Linear Attention的添加教程","titles":["聚焦线性注意力",null,"五、添加Focused Linear Attention到模型中"]},"114":{"title":"四、手把手教你添加D-LKA","titles":["可变形大核注意力",null]},"115":{"title":"四、添加DAT到你的网络中","titles":["DAT",null]},"116":{"title":"4.1 ACmix添加步骤","titles":["ACmix自注意力机制",null,"四、手把手教你添加ACmix"]},"117":{"title":"标题 4","titles":["Markdown",null,"标题 2","标题 3"]},"118":{"title":"Roboflow的官方地址","titles":["Roboflow",null,"简介"]},"119":{"title":"4.2.2 Triplet Attention的yaml文件二","titles":["Triplet Attention",null,"四、手把手教你添加Triplet Attention","4.2 Triplet Attention的yaml文件和训练截图"]},"120":{"title":"Roboflow具备数据增强的功能","titles":["ultralytics",null,null]},"121":{"title":"8.2 使用SumatraPDF查看的代码配置","titles":["vscode配置latex环境",null,"8 SumatraPDF 安装设置（可选）"]},"122":{"title":"4.2 RCS-OSA的yaml文件和训练截图","titles":["RCS-OSA",null,"四、手把手教你添加RCS-OSA模块"]},"123":{"title":"4.4 MSDA的训练过程截图","titles":["多尺度空洞注意力",null,"四、手把手教你添加MSDA模块"]},"124":{"title":"5.2 Focused Linear Attention的yaml文件和训练截图","titles":["聚焦线性注意力",null,"五、添加Focused Linear Attention到模型中"]},"125":{"title":"4.1.1 修改一","titles":["可变形大核注意力",null,"四、手把手教你添加D-LKA","2.4 2D和3D适应性"]},"126":{"title":"4.1 DAT的yaml文件和训练过程","titles":["DAT",null,"四、添加DAT到你的网络中"]},"127":{"title":"4.1.1 步骤一","titles":["ACmix自注意力机制",null,"四、手把手教你添加ACmix","4.1 ACmix添加步骤"]},"128":{"title":"标题 5","titles":["Markdown",null,"标题 2","标题 3","标题 4"]},"129":{"title":"Roboflow具有的数据预处理","titles":["Roboflow",null,"简介"]},"130":{"title":"4.2.2 D-LKA的训练过程截图","titles":["Triplet Attention",null,"四、手把手教你添加Triplet Attention","4.2 Triplet Attention的yaml文件和训练截图"]},"131":{"title":"翻转","titles":["ultralytics",null,null,"Roboflow具备数据增强的功能"]},"132":{"title":"8.2.1 代码展示","titles":["vscode配置latex环境",null,"8 SumatraPDF 安装设置（可选）","8.2 使用SumatraPDF查看的代码配置"]},"133":{"title":"4.2.1 RCS-OSA的yaml版本一(推荐)","titles":["RCS-OSA",null,"四、手把手教你添加RCS-OSA模块","4.2 RCS-OSA的yaml文件和训练截图"]},"134":{"title":"5.2.1 Focused Linear Attention的yaml文件","titles":["聚焦线性注意力",null,"五、添加Focused Linear Attention到模型中","5.2 Focused Linear Attention的yaml文件和训练截图"]},"135":{"title":"4.1.2 修改二","titles":["可变形大核注意力",null,"四、手把手教你添加D-LKA","2.4 2D和3D适应性"]},"136":{"title":"五、DAT可添加的位置","titles":["DAT",null]},"137":{"title":"4.1.2 步骤二","titles":["ACmix自注意力机制",null,"四、手把手教你添加ACmix","4.1 ACmix添加步骤"]},"138":{"title":"标题 6","titles":["Markdown",null,"标题 2","标题 3","标题 4","标题 5"]},"139":{"title":"自动定向","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"140":{"title":"五、Triplet Attention可添加的位置","titles":["Triplet Attention",null]},"141":{"title":"90度旋转","titles":["ultralytics",null,null,"Roboflow具备数据增强的功能"]},"142":{"title":"8.2.2 代码解读","titles":["vscode配置latex环境",null,"8 SumatraPDF 安装设置（可选）","8.2 使用SumatraPDF查看的代码配置"]},"143":{"title":"4.2.2 RCS-OSA的yaml版本二","titles":["RCS-OSA",null,"四、手把手教你添加RCS-OSA模块","4.2 RCS-OSA的yaml文件和训练截图"]},"144":{"title":"5.2.2 Focused Linear Attention的训练过程截图","titles":["聚焦线性注意力",null,"五、添加Focused Linear Attention到模型中","5.2 Focused Linear Attention的yaml文件和训练截图"]},"145":{"title":"4.1.3 修改三","titles":["可变形大核注意力",null,"四、手把手教你添加D-LKA","2.4 2D和3D适应性"]},"146":{"title":"5.1推荐DAT可添加的位置","titles":["DAT",null,"五、DAT可添加的位置"]},"147":{"title":"4.1.3 步骤三","titles":["ACmix自注意力机制",null,"四、手把手教你添加ACmix","4.1 ACmix添加步骤"]},"148":{"title":"调整","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"149":{"title":"5.1 推荐Triplet Attention可添加的位置","titles":["Triplet Attention",null,"五、Triplet Attention可添加的位置"]},"150":{"title":"随机裁剪","titles":["ultralytics",null,null,"Roboflow具备数据增强的功能"]},"151":{"title":"9 SumatraPDF 的使用","titles":["vscode配置latex环境",null]},"152":{"title":"4.2.2 RCS-OSA的训练过程截图","titles":["RCS-OSA",null,"四、手把手教你添加RCS-OSA模块","4.2 RCS-OSA的yaml文件和训练截图"]},"153":{"title":"4.1.4 修改四","titles":["可变形大核注意力",null,"四、手把手教你添加D-LKA","2.4 2D和3D适应性"]},"154":{"title":"5.2图示DAT可添加的位置","titles":["DAT",null,"五、DAT可添加的位置"]},"155":{"title":"五、ACmix的yaml文件和运行记录","titles":["ACmix自注意力机制",null]},"156":{"title":"灰度","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"157":{"title":"5.2 图示D-LKA可添加的位置","titles":["Triplet Attention",null,"五、Triplet Attention可添加的位置"]},"158":{"title":"随机剪切","titles":["ultralytics",null,null,"Roboflow具备数据增强的功能"]},"159":{"title":"10 pdf 内部查看与外部查看的切换","titles":["vscode配置latex环境",null]},"160":{"title":"4.2 D-LKA的yaml文件和训练截图(仔细看这个否则会报错)","titles":["可变形大核注意力",null,"四、手把手教你添加D-LKA"]},"161":{"title":"5.1 ACMix的yaml版本一(推荐)","titles":["ACmix自注意力机制",null,"五、ACmix的yaml文件和运行记录"]},"162":{"title":"自动调整对比度","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"163":{"title":"噪声","titles":["ultralytics",null,null,"Roboflow具备数据增强的功能"]},"164":{"title":"11 个人完整配置","titles":["vscode配置latex环境",null]},"165":{"title":"4.2.1 D-LKA的yaml文件一(推荐)","titles":["可变形大核注意力",null,"四、手把手教你添加D-LKA","4.2 D-LKA的yaml文件和训练截图(仔细看这个否则会报错)"]},"166":{"title":"5.2 ACMix的yaml版本二","titles":["ACmix自注意力机制",null,"五、ACmix的yaml文件和运行记录"]},"167":{"title":"隔离对象","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"168":{"title":"曝光","titles":["ultralytics",null,null,"Roboflow具备数据增强的功能"]},"169":{"title":"4.2.2 D-LKA的yaml文件二","titles":["可变形大核注意力",null,"四、手把手教你添加D-LKA","4.2 D-LKA的yaml文件和训练截图(仔细看这个否则会报错)"]},"170":{"title":"5.3 推荐ACMix可添加的位置","titles":["ACmix自注意力机制",null,"五、ACmix的yaml文件和运行记录"]},"171":{"title":"静态裁剪","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"172":{"title":"随机噪声","titles":["ultralytics",null,null,"Roboflow具备数据增强的功能"]},"173":{"title":"4.2.2 D-LKA的训练过程截图","titles":["可变形大核注意力",null,"四、手把手教你添加D-LKA","4.2 D-LKA的yaml文件和训练截图(仔细看这个否则会报错)"]},"174":{"title":"5.4 ACMix的训练过程截图","titles":["ACmix自注意力机制",null,"五、ACmix的yaml文件和运行记录"]},"175":{"title":"切片","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"176":{"title":"边界框扩充","titles":["ultralytics",null,null,"Roboflow具备数据增强的功能"]},"177":{"title":"五、D-LKA可添加的位置","titles":["可变形大核注意力",null]},"178":{"title":"修改类","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"179":{"title":"数据增强操作过程","titles":["ultralytics",null,null]},"180":{"title":"5.1 推荐D-LKA可添加的位置","titles":["可变形大核注意力",null,"五、D-LKA可添加的位置"]},"181":{"title":"筛选器空","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"182":{"title":"5.2 图示D-LKA可添加的位置","titles":["可变形大核注意力",null,"五、D-LKA可添加的位置"]},"183":{"title":"按标签筛选","titles":["Roboflow",null,"简介","Roboflow具有的数据预处理"]},"184":{"title":"数据预处理具体操作流程","titles":["Roboflow",null,"简介"]}},"dirtCount":0,"index":[["条件是排除和需要规则",{"2":{"183":1}}],["已排除",{"2":{"183":1}}],["带有允许标记的图片将包含在版本中",{"2":{"183":1}}],["带有",{"2":{"183":1}}],["带有偏移量的变形卷积",{"2":{"68":1}}],["排除",{"2":{"183":1}}],["必需",{"2":{"183":1}}],["才应应用空注释",{"2":{"181":1}}],["缺少批注",{"2":{"181":1}}],["未对图像进行批注时会出现",{"2":{"181":1}}],["未注记",{"2":{"181":1}}],["筛选器",{"2":{"181":1}}],["筛选器空",{"0":{"181":1},"2":{"129":1}}],["检测头中的卷积",{"2":{"180":1}}],["检查权重的数据类型",{"2":{"102":1}}],["检查安装是否正常",{"2":{"2":1}}],["许可证",{"2":{"179":1,"184":1}}],["给你项目起一个名字",{"2":{"179":1,"184":1}}],["给大家",{"2":{"110":1}}],["里面需要导入你的数据集",{"2":{"179":1,"184":1}}],["里面详细的介绍了拿到一个任意机制",{"2":{"44":1,"83":1}}],["苹果叶",{"2":{"178":2}}],["观看视频点击这里",{"2":{"178":1,"181":1}}],["类",{"2":{"178":2}}],["类似地",{"2":{"67":1}}],["仅当",{"2":{"181":1}}],["仅边界框修改会产生系统性改进",{"2":{"176":1}}],["仅支持缩小规模",{"2":{"148":1}}],["研究人员表明",{"2":{"176":1}}],["边界框级别增强通过仅更改源图像边界框的内容来生成新的训练数据",{"2":{"176":1}}],["边界框扩充",{"0":{"176":1}}],["网格",{"2":{"175":1}}],["网络就能够更全面地理解图像内容",{"2":{"5":1}}],["平铺",{"2":{"175":1}}],["平台提供以下预处理选项",{"2":{"129":1}}],["尤其是在航空图像和显微镜等情况下",{"2":{"175":1}}],["尤其是在处理大规模数据集时的优势",{"2":{"46":1}}],["那个效果更好针对不同的数据集可能也不一样所以大家需要进行尝试",{"2":{"169":1}}],["那么可以点击上图左下角的",{"2":{"2":1}}],["深色",{"2":{"168":1}}],["深层特征提取",{"2":{"28":1}}],["全黑",{"2":{"168":1}}],["全白",{"2":{"168":1}}],["全局操作",{"2":{"4":1}}],["明亮",{"2":{"168":1}}],["曝光",{"0":{"168":1}}],["争取以后学得更扎实再编写这些文字",{"2":{"164":1}}],["欢迎收藏我的博客",{"2":{"164":1}}],["欢迎您在评论区批评指正",{"2":{"164":1}}],["欢迎进入",{"2":{"2":1}}],["写在最后",{"2":{"164":1}}],["噪声",{"0":{"163":1}}],["局部细节也可以得到增强",{"2":{"162":1}}],["均衡化图像具有大致均匀的分布",{"2":{"162":1}}],["均为笔者所安装的其余插件以及其余设置所致",{"2":{"0":1}}],["探索是否要使用对比度作为预处理步骤",{"2":{"162":1}}],["仔细看这个否则会报错",{"0":{"160":1},"1":{"165":1,"169":1,"173":1}}],["共有两种操作方式",{"2":{"159":1}}],["轴上随机剪切的最大量",{"2":{"158":2}}],["轴向条纹和扩张窗口",{"2":{"4":1}}],["绿色和蓝色的看法",{"2":{"156":1}}],["绿色和蓝色像素的加权和",{"2":{"156":1}}],["双向同步",{"2":{"151":1}}],["双层路由注意力",{"2":{"4":1}}],["百分比越高",{"2":{"150":1}}],["百分比",{"2":{"150":1,"168":1,"172":1}}],["白色填充",{"2":{"148":1}}],["白边",{"2":{"148":1}}],["黑色填充",{"2":{"148":1}}],["黑色边框的矩形代表特定的模块操作",{"2":{"25":1}}],["黑边",{"2":{"148":1}}],["默认设置是",{"2":{"175":1}}],["默认",{"2":{"164":1}}],["默认情况下也会反映注释",{"2":{"148":1}}],["默认会放大一些",{"2":{"95":1}}],["或省略任何不必要的类",{"2":{"181":1}}],["或双击",{"2":{"164":1}}],["或",{"2":{"148":3,"159":1,"168":1}}],["或者neck的输出部分是最好的",{"2":{"88":1}}],["或者复制以下代码进行文档的简单编译测试",{"2":{"73":1}}],["或者在前一页面",{"2":{"2":1}}],["任何新创建的填充都是白色区域",{"2":{"148":1}}],["任何新创建的填充都是黑色区域",{"2":{"148":1}}],["任何新创建的填充都是源图像的反射",{"2":{"148":1}}],["任务列表4",{"2":{"138":1}}],["任务列表3",{"2":{"138":1}}],["任务列表2",{"2":{"138":1}}],["任务列表1",{"2":{"138":1}}],["源尺寸的尺寸被缩放为输出图像的尺寸",{"2":{"148":3}}],["源尺寸的尺寸将缩放为输出图像的尺寸",{"2":{"148":1}}],["像素是最大噪声",{"2":{"163":1}}],["像素",{"2":{"148":7,"163":1}}],["像这种注意力机制不要添加在主干上",{"2":{"88":1}}],["次要尺寸",{"2":{"148":4}}],["纵横比保持不变",{"2":{"148":1}}],["纵向",{"2":{"20":1}}],["失真",{"2":{"148":1}}],["拉伸到",{"2":{"148":1}}],["除外",{"2":{"148":1}}],["除了代码块儿最后一句",{"2":{"41":1}}],["填充图像",{"2":{"148":1}}],["填充",{"2":{"148":2}}],["路径修改",{"2":{"142":2}}],["路径上维持有限数量的特征级联来实现的",{"2":{"42":1}}],["转换允许用户根据哪个版本筛选哪些图像应包含或不应包含在版本中标签应用",{"2":{"183":1}}],["转换允许用户要求对数据集中的图像共享进行批注",{"2":{"181":1}}],["转换可用于创建训练第二个模型所需的数据集",{"2":{"167":1}}],["转换将裁剪每个边界框并将其提取为单个图像",{"2":{"167":1}}],["转发到外部查看器时要执行的命令",{"2":{"142":1}}],["转到",{"2":{"24":1}}],["请确保已正确注释数据集中的所有图像",{"2":{"181":1}}],["请注意中间为",{"2":{"142":1}}],["请记得在最后一句",{"2":{"41":1}}],["正常情况下只需更改磁盘盘符即可",{"2":{"142":1}}],["正向同步和反向同步",{"2":{"151":1}}],["正向同步1",{"2":{"84":1}}],["正向同步测试",{"2":{"84":1}}],["命令上的",{"2":{"142":1}}],["内外切换",{"2":{"159":1}}],["内部查看与外部查看的切换",{"0":{"159":1}}],["内置",{"2":{"142":1}}],["内容区块",{"2":{"138":2}}],["内容右对齐",{"2":{"138":1}}],["内容居中",{"2":{"138":1}}],["内容",{"2":{"138":1,"181":1}}],["逆时针",{"2":{"141":2}}],["顺时针",{"2":{"141":2}}],["度",{"2":{"141":8}}],["度或",{"2":{"141":2}}],["度量上",{"2":{"28":1}}],["建议默认保持打开状态",{"2":{"139":1}}],["预览编译好的pdf文件",{"2":{"164":1}}],["预览",{"2":{"139":1}}],["预处理适用于训练集",{"2":{"129":1}}],["预处理可确保您的数据集采用标准格式",{"2":{"129":1}}],["行内脚注文本",{"2":{"138":1}}],["行内的脚注",{"2":{"138":1}}],["↩︎",{"2":{"138":4}}],["定义",{"2":{"138":1}}],["定义完成后",{"2":{"51":1}}],["脚注文字",{"2":{"138":1}}],["脚注",{"2":{"138":4}}],["非常强大",{"2":{"138":1}}],["错误内容",{"2":{"138":1}}],["错误",{"2":{"138":1}}],["警告内容",{"2":{"138":1}}],["警告",{"2":{"138":2}}],["信息内容",{"2":{"138":1}}],["信息",{"2":{"138":1}}],["示例",{"2":{"138":1}}],["外部链接",{"2":{"138":1}}],["外部查看器了",{"2":{"151":1}}],["外部查看器展示出来的",{"2":{"95":1}}],["外部查看器的优势是能够看到",{"2":{"95":1}}],["链接",{"2":{"138":3,"142":1,"164":1}}],["引用查看",{"2":{"142":1}}],["引用内容",{"2":{"138":2}}],["引入可变形注意力机制和动态采样点",{"2":{"48":1}}],["引入可以将其用在c2f和检测头中进行改进估计效果会更高",{"2":{"38":1}}],["引入了一种新颖的双层路由机制来改进传统的注意力机制",{"2":{"4":1}}],["$1",{"2":{"138":1}}],["$12",{"2":{"138":1}}],["$1600",{"2":{"138":1}}],["ωyω​",{"2":{"138":2}}],["∂ωr∂r​",{"2":{"138":1}}],["∂r∂ωr",{"2":{"138":1}}],["^",{"2":{"138":2}}],["^r",{"2":{"138":2}}],["~335",{"2":{"148":3}}],["~512",{"2":{"148":1}}],["~",{"2":{"138":1}}],["−1",{"2":{"138":2}}],["−",{"2":{"138":2}}],["删除文字",{"2":{"138":1}}],["斜体文字",{"2":{"138":1}}],["斜体",{"2":{"138":1}}],["加粗文字",{"2":{"138":1}}],["加粗",{"2":{"138":1}}],["加强了模型的特征提取能力",{"2":{"81":1}}],["帮助大家省了一些事",{"2":{"134":1}}],["帮助开发者优化训练数据",{"2":{"105":1}}],["让您进行查看",{"2":{"132":1}}],["让使用方法统一起来所以大家用着很简单",{"2":{"77":1}}],["向下方向",{"2":{"131":1}}],["垂直",{"2":{"131":1,"158":1}}],["水平",{"2":{"131":1,"158":1}}],["批注按比例缩放",{"2":{"148":1}}],["批注已正确镜像",{"2":{"131":1}}],["批次大小",{"2":{"89":1}}],["反射边缘",{"2":{"148":1}}],["反射",{"2":{"131":1}}],["反向同步",{"2":{"84":1}}],["反向同步测试",{"2":{"84":1}}],["随机噪声",{"0":{"172":1}}],["随机剪切",{"0":{"158":1}}],["随机创建图像的子集",{"2":{"150":1}}],["随机裁剪",{"0":{"150":1}}],["随机旋转",{"2":{"141":1}}],["随机翻转",{"2":{"131":1}}],["随机进入另一镜像网站进行下载尝试",{"2":{"2":1}}],["翻转图像向上",{"2":{"131":1}}],["翻转图像左",{"2":{"131":1}}],["翻转",{"0":{"131":1}}],["切片有助于检测小物体",{"2":{"175":1}}],["切片",{"0":{"175":1},"2":{"129":1}}],["切记",{"2":{"41":1}}],["静态裁剪等",{"2":{"184":1}}],["静态裁剪功能和示例输出",{"2":{"171":1}}],["静态裁剪",{"0":{"171":1},"2":{"129":1,"184":1}}],["隔离对象",{"0":{"167":1},"2":{"129":1,"167":2,"184":1}}],["灰度",{"0":{"156":1},"2":{"129":1,"184":2}}],["调整大小会更改图像大小",{"2":{"148":1}}],["调整",{"0":{"148":1},"2":{"129":1,"184":1}}],["调整输入以匹配原始模块的预期格式",{"2":{"89":1}}],["数据预处理具体操作流程",{"0":{"184":1}}],["数据",{"2":{"139":1}}],["数据增强操作过程",{"0":{"179":1}}],["数据增强过程在训练之前通过预处理步骤应用于原始数据集",{"2":{"120":1}}],["数据增强技术在训练模型时可以克服数据集有限的问题",{"2":{"120":1}}],["数据增强的目的是通过对原始数据应用各种变换和扰动",{"2":{"120":1}}],["数据增强是一种常见的技术",{"2":{"120":1}}],["数学表达式",{"2":{"138":1}}],["数值越高表示使用的像素越多",{"2":{"36":1}}],["估计也不影响运行和精度就没去处理",{"2":{"112":1}}],["记得更改安装路径并记住",{"2":{"108":1}}],["记得修改安装路径",{"2":{"6":1}}],["培训成本降低",{"2":{"107":1}}],["限制的操作",{"2":{"107":2}}],["寻",{"2":{"107":1}}],["离线增强",{"2":{"107":1}}],["离修改模型只差最后一步",{"2":{"60":1}}],["开发人员可以更好地控制创建更适合其问题条件的训练数据",{"2":{"176":1}}],["开发者可以轻松获取所需格式的数据集",{"2":{"105":1}}],["开始编译",{"2":{"84":1}}],["开始编译文件",{"2":{"84":1}}],["输出层前",{"2":{"98":1,"146":1}}],["输入特征先转换成查询",{"2":{"92":1}}],["输入为四维",{"2":{"89":1}}],["输入的低分辨率",{"2":{"36":1}}],["输入被分为两部分",{"2":{"33":1}}],["输入通过通道分割",{"2":{"25":1}}],["输入",{"2":{"11":1,"17":1}}],["输入cmd",{"2":{"2":1}}],["残差连接中",{"2":{"98":1,"110":1,"146":1,"149":1,"170":1,"180":1}}],["置大家可以进行参考",{"2":{"98":1,"110":1,"146":1,"149":1,"170":1,"180":1}}],["达到与内置",{"2":{"95":1}}],["阅读功能的同时很轻量",{"2":{"95":1}}],["要求",{"2":{"183":1}}],["要保留的原始图像的百分比区域",{"2":{"150":1}}],["要放置的原始图像的百分比区域",{"2":{"150":1}}],["要更加让人舒服一些",{"2":{"95":1}}],["要注意的是",{"2":{"2":1}}],["您可以根据需要进行调整",{"2":{"175":1}}],["您可根据个人适应选择相应的方法",{"2":{"159":1}}],["您可自行选择是否需要设置此部分内容",{"2":{"95":1}}],["您注意更改路径",{"2":{"142":1}}],["您的",{"2":{"107":1}}],["您无需担心",{"2":{"0":1}}],["强调了两种机制的融合并提供了每个操作块的计算复杂度",{"2":{"92":1}}],["强调在计算注意力权重时",{"2":{"16":1}}],["既包含了卷积的空间特征提取能力",{"2":{"92":1}}],["突出了它们处理查询的不同方法",{"2":{"91":1}}],["充分利用体积图像数据中的空间上下文信息",{"2":{"90":1}}],["技术应用于不同维度数据的能力",{"2":{"90":1}}],["序列长度",{"2":{"89":1}}],["宽度",{"2":{"89":1}}],["宽度三个维度之间的交互关系来计算注意力权重",{"2":{"16":1}}],["创建项目",{"2":{"179":1,"184":1}}],["创建一个py文件粘贴进去hattention",{"2":{"66":1}}],["创建一个py文件粘贴进去",{"2":{"45":1}}],["创作不易而且免费给大家看",{"2":{"89":1}}],["涨点效果最好",{"2":{"88":1}}],["推荐d",{"0":{"180":1}}],["推荐acmix可添加的位置",{"0":{"170":1}}],["推荐triplet",{"0":{"149":1}}],["推荐msda可添加的位置",{"0":{"110":1}}],["推荐lskattention可添加的位置",{"0":{"98":1}}],["推荐",{"0":{"86":1,"106":1,"133":1,"161":1,"165":1}}],["跳转到对应代码",{"2":{"84":1}}],["鼠标左键双击或ctrl+鼠标左键单击",{"2":{"84":1}}],["现在编译的结果为内部查看器查看",{"2":{"84":1}}],["现在我们以及将biformer文件导入了模型中了",{"2":{"49":1}}],["×",{"2":{"84":1}}],["说明编译失败",{"2":{"84":1}}],["说明编译成功",{"2":{"84":1}}],["说明安装完毕",{"2":{"2":1}}],["符号",{"2":{"84":1}}],["符号时",{"2":{"84":1}}],["符合word设定",{"2":{"73":1}}],["√",{"2":{"84":1}}],["快捷键",{"2":{"84":1}}],["快捷键编译",{"2":{"84":1}}],["快捷键绑定",{"2":{"84":1}}],["选择受影响的图像像素百分比",{"2":{"172":1}}],["选择图像随机变亮或变暗的百分比",{"2":{"168":1}}],["选择图像将在其",{"2":{"158":2}}],["选择第一个latex",{"2":{"17":1}}],["选择第一个chinese",{"2":{"11":1}}],["选项卡",{"2":{"138":1}}],["选中想要跳转行",{"2":{"84":1}}],["选中需要跳转的代码所在行",{"2":{"84":1}}],["选中",{"2":{"84":2}}],["选中tex文件的代码页面",{"2":{"84":1}}],["测试文件编译",{"0":{"84":1}}],["测试所用的",{"2":{"73":1}}],["八",{"0":{"82":1}}],["整体上",{"2":{"81":1}}],["包含多个3d",{"2":{"90":1}}],["包含一个k2",{"2":{"81":1}}],["包括",{"2":{"68":1}}],["包括1x1和3x3的卷积",{"2":{"25":1}}],["卷积",{"2":{"81":1,"92":1}}],["卷积和自注意力生成的特征通过求和操作进行融合",{"2":{"81":1}}],["卷积和自注意力共享相同的1x1卷积运算",{"2":{"81":1}}],["运算共享",{"2":{"81":1}}],["运算分解与重构的概念是指将传统的卷积运算和自注意力运算拆分",{"2":{"92":1}}],["运算分解与重构",{"0":{"92":1},"2":{"70":1}}],["键",{"2":{"81":1,"92":2}}],["键和值矩阵",{"2":{"46":1}}],["键和值",{"2":{"8":1,"13":1}}],["被用来增强模型对医学图像中的不规则形状和大小的捕捉能力",{"2":{"79":1}}],["被用来展示其它各个块对它的注意力程度",{"2":{"13":1}}],["实验效果图如下所示",{"2":{"78":1}}],["实验效果对比",{"0":{"78":1}}],["实现两者优势的结合",{"2":{"70":1}}],["实现了对象检测的任务",{"2":{"42":1}}],["实现了检测精度提升",{"2":{"14":1}}],["实现快速推理",{"2":{"18":1}}],["实现内容感知的稀疏性",{"2":{"15":1}}],["针对不同的数据集效果也不一样",{"2":{"75":1,"155":1}}],["世界",{"2":{"73":1}}],["\\t",{"2":{"73":2}}],["功能是否比较完整",{"2":{"73":1}}],["控制台进行了模型结构的输出如下",{"2":{"71":1}}],["训练模型",{"0":{"71":1}}],["七",{"0":{"71":1}}],["改进了视觉transformer的效率和性能",{"2":{"69":1}}],["动态采样点",{"2":{"69":1}}],["增加模型的鲁棒性和准确性",{"2":{"120":1}}],["增加非线性",{"2":{"68":1}}],["增强低对比度的图像",{"2":{"162":1}}],["增强是受",{"2":{"107":1}}],["增强网络的表征能力",{"2":{"81":1}}],["增强网络对复杂数据结构的理解和处理能力",{"2":{"31":1}}],["增强网络对特征的重要部分的关注度",{"2":{"23":1}}],["增强了输出转换特征的多头注意力",{"2":{"80":1}}],["增强了模型的表现力",{"2":{"13":1}}],["增强了模型的学习能力和效率",{"2":{"13":1}}],["激活函数gelu",{"2":{"68":1}}],["偏移场",{"2":{"68":1}}],["机制的感受野",{"2":{"68":1}}],["括号中的百分点",{"2":{"67":1}}],["表中突出了flatten版本的transformer模型在top",{"2":{"67":1}}],["表示",{"2":{"175":1}}],["表示卷积核大小和卷积操作的聚合",{"2":{"81":1}}],["表示使用二维卷积神经网络的检测层",{"2":{"42":1}}],["表示参与的像素范围",{"2":{"36":1}}],["计算量",{"2":{"67":1}}],["计算效率提升",{"2":{"20":1}}],["效果对比",{"0":{"67":1}}],["代表多头注意力机制中每个头部的线性变换",{"2":{"81":1}}],["代表卷积核的大小",{"2":{"65":1}}],["代码解读",{"0":{"142":1}}],["代码演示",{"2":{"138":1}}],["代码块聚焦",{"2":{"138":1}}],["代码块高亮",{"2":{"138":1}}],["代码分组",{"2":{"138":1}}],["代码",{"2":{"138":1}}],["代码展示",{"0":{"132":1}}],["代码进行编译",{"2":{"41":1}}],["代码地址",{"2":{"4":1,"7":1,"10":1,"13":1,"20":1,"37":1,"47":1,"58":1}}],["代码不算哈哈哈",{"2":{"0":1}}],["参数",{"2":{"142":1}}],["参数我以及设定好了",{"2":{"134":1}}],["参数量为407120",{"2":{"133":1}}],["参数数量",{"2":{"67":1}}],["参数位置可以填写的有7",{"2":{"65":1}}],["参数调整的挑战",{"2":{"9":1}}],["到此就修改完成了",{"2":{"77":1,"153":1}}],["到此我们的所有准备工作都已完成",{"2":{"71":1}}],["到此我们就注册成功了",{"2":{"64":1,"109":1,"147":1}}],["到这里我们就已经成功的导入了注意力机制",{"2":{"60":1}}],["你的图片标签是什么",{"2":{"179":1,"184":1}}],["你是检测什么",{"2":{"179":1,"184":1}}],["你现在不知道其是干什么用的可以看添加教程",{"2":{"113":1}}],["你放在主干上",{"2":{"88":1}}],["你也可以自己进行组合",{"2":{"75":1,"155":1}}],["你也可以根据你自己的习惯起",{"2":{"43":1}}],["你好",{"2":{"73":1}}],["你没有删除即可",{"2":{"64":1}}],["修改四",{"0":{"153":1}}],["修改三",{"0":{"145":1}}],["修改如下图",{"2":{"142":1}}],["修改类",{"0":{"178":1},"2":{"129":1}}],["修改了flattention的c2f和bottleneck",{"2":{"89":1}}],["修改了triplet",{"0":{"61":1}}],["修改二",{"0":{"77":1,"135":1}}],["修改一",{"0":{"66":1,"125":1}}],["修改路径",{"2":{"2":1}}],["🚀",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["恭喜你",{"2":{"60":1}}],["配置",{"2":{"164":1}}],["配置biformer注意力机制",{"0":{"60":1}}],["配置代码如下",{"2":{"41":1}}],["六",{"0":{"60":1}}],["又能通过卷积捕获局部特征",{"2":{"59":1,"70":1}}],["传统的transformer使用标准的自注意力机制",{"2":{"69":1}}],["传统卷积操作和自注意力模块的大部分计算都可以通过1x1的卷积来实现",{"2":{"59":1,"70":1}}],["传统方法在特征表达上缺乏多样性",{"2":{"56":1}}],["适合",{"2":{"148":3}}],["适合范围",{"2":{"148":1}}],["适应不同的数据模式",{"2":{"57":1}}],["适用于常见的医学成像方法",{"2":{"90":1}}],["适用于多种任务",{"2":{"20":1}}],["适用于各种计算机视觉任务",{"2":{"15":1}}],["允许",{"2":{"183":1}}],["允许网络根据输入特征自适应地调整其感受野",{"2":{"68":1}}],["允许模型的采样网格根据图像特征灵活变形",{"2":{"57":1}}],["允许用户使用操作系统字体来代替",{"2":{"51":1}}],["影响了模型的表现力",{"2":{"56":1}}],["应用修改类工具后标记为空注记或",{"2":{"181":1}}],["应用程序",{"2":{"139":1}}],["应用于原始注意力矩阵的秩恢复模块来增加特征多样性",{"2":{"56":1}}],["应如下图页面所示",{"2":{"6":1}}],["还需要注意数据增强不应导致过度拟合或无意义的数据变换",{"2":{"120":1}}],["还支持上传自己的数据集并进行格式转换",{"2":{"105":1}}],["还包括了作者提出的flatten版本的transformer模型",{"2":{"67":1}}],["还通过深度卷积",{"2":{"56":1}}],["还能够在目标检测",{"2":{"20":1}}],["尽管线性注意力降低了复杂度",{"2":{"56":1}}],["方便大家使用",{"2":{"55":1}}],["变为了在",{"2":{"151":1}}],["变量有两种",{"2":{"51":1}}],["变换器hat",{"1":{"21":1,"28":1,"36":1,"45":1,"55":1,"66":1,"77":1,"88":1,"99":1,"112":1}}],["清除辅助文件",{"2":{"51":1}}],["无序列表3",{"2":{"138":1}}],["无序列表2",{"2":{"138":1}}],["无序列表1",{"2":{"138":1}}],["无论何时",{"2":{"51":1}}],["无论是否编译成功",{"2":{"51":1}}],["无需进行传入会根据模型输入自动计算",{"2":{"134":1}}],["无需进行更改",{"2":{"51":1}}],["无需手动进行繁琐的格式转换工作",{"2":{"105":1}}],["无需在意",{"2":{"17":1}}],["无需理会",{"2":{"2":1}}],["速度快",{"2":{"51":1}}],["对象检测",{"2":{"167":1}}],["对象检测等",{"2":{"69":1}}],["对比度受限自适应直方图均衡",{"2":{"162":1}}],["对比度拉伸",{"2":{"162":1}}],["对比了swin",{"2":{"67":1}}],["对比了不同版本的pvt",{"2":{"67":1}}],["对应实验结果的图二",{"2":{"119":1}}],["对应的",{"2":{"51":1}}],["对字体的支持更好",{"2":{"51":1}}],["对于构建轻量级和大规模的对象检测器尤为重要",{"2":{"33":1}}],["对于每个头部i",{"2":{"13":1}}],["对于这种情况",{"2":{"4":1}}],["对于理工科",{"2":{"0":1}}],["标识对象是什么",{"2":{"167":1}}],["标题1标题2内容区块",{"2":{"138":2}}],["标题",{"0":{"93":1,"104":1,"117":1,"128":1,"138":1},"1":{"104":1,"117":2,"128":3,"138":4}}],["标准的2d卷积",{"2":{"68":1}}],["标准字体进行替换",{"2":{"51":1}}],["标记的图片将不会包含在版本中",{"2":{"183":1}}],["标记的映像才会包含在版本中",{"2":{"183":1}}],["标记",{"2":{"84":1,"138":1}}],["标记为",{"2":{"67":1}}],["标记能够编译文档",{"2":{"51":1}}],["标记使用",{"2":{"51":1}}],["区别如下",{"2":{"51":1}}],["编译工具和命令",{"2":{"164":1}}],["编译出错时设置是否弹出气泡设置",{"2":{"164":1}}],["编译成功",{"2":{"84":2}}],["编译bixtex文件",{"2":{"73":1}}],["编译",{"2":{"51":2}}],["编译模式与",{"2":{"51":1}}],["编译器中能够看到的编译顺序",{"2":{"51":1}}],["编译链的存在是为了更方便编译",{"2":{"51":1}}],["编译链",{"2":{"51":1}}],["编译链中被使用的编译命令",{"2":{"51":1}}],["编译链自动构建",{"2":{"51":1}}],["更加集中注意力于最关键的特征",{"2":{"98":1,"146":1,"180":1}}],["更多详情可以访问",{"2":{"51":1}}],["更好地捕获数据的内在特征",{"2":{"31":1}}],["导致计算量很大",{"2":{"69":1}}],["导致计算复杂度为",{"2":{"46":1}}],["导致计算复杂度较高",{"2":{"9":1}}],["导致模型难以有效地关注重要特征",{"2":{"56":1}}],["导致路径已经是中文了",{"2":{"51":1}}],["用作下文",{"2":{"51":1}}],["用于在生成数据集的新版本时省略特定类或重映射",{"2":{"178":1}}],["用于配置编译链",{"2":{"164":1}}],["用于增加训练数据的多样性和数量",{"2":{"120":1}}],["用于深度特征学习和分辨率恢复",{"2":{"90":1}}],["用于指导变形卷积层如何调整其采样位置",{"2":{"68":1}}],["用于反向同步的内部查看器的键绑定",{"2":{"164":1}}],["用于反向同步",{"2":{"51":1}}],["用于捕获空间维度之间的依赖性",{"2":{"31":1}}],["用于单图像超分辨率重建",{"2":{"28":1}}],["用于学习丰富的特征表示",{"2":{"25":1}}],["用于改进卷积神经网络",{"2":{"20":1}}],["则较长的尺寸",{"2":{"148":4}}],["则输出的大小调整为源图像的中心",{"2":{"148":1}}],["则为鼠标左键双击",{"2":{"84":1}}],["则无法进行编译",{"2":{"84":1}}],["则会导致编译不出完整结果甚至编译失败",{"2":{"51":1}}],["则该拓展能够从使用的宏包中自动提取命令和环境",{"2":{"51":1}}],["则安装正常",{"2":{"2":1}}],["菜单中多了两个选项",{"2":{"51":1}}],["左边为设置false情况",{"2":{"51":1}}],["左侧是3d",{"2":{"90":1}}],["左侧工具栏",{"2":{"84":1}}],["左侧部分",{"2":{"80":1}}],["左侧",{"2":{"15":1,"90":1}}],["新的",{"2":{"51":1}}],["启用上下文latex菜单",{"2":{"51":1}}],["启动页面",{"2":{"6":1}}],["甚至被其他应用程序修改",{"2":{"51":1}}],["项目名称",{"2":{"179":1,"184":1}}],["项目的类型",{"2":{"179":1,"184":1}}],["项目",{"2":{"51":1}}],["第二个模型",{"2":{"167":1}}],["第二步我们在该目录下创建一个新的py文件名字为",{"2":{"135":1}}],["第三步我门中到如下文件",{"2":{"145":1}}],["第三个分支则聚焦于图像的深度",{"2":{"5":1}}],["第一还是建立文件",{"2":{"125":1}}],["第一个模型",{"2":{"167":1}}],["第一个",{"2":{"51":1}}],["设置vscode内部查看生成的pdf文件",{"2":{"164":1}}],["设置为onfaild",{"2":{"164":1}}],["设置为true",{"2":{"51":1}}],["设置为true时",{"2":{"51":1}}],["设置是否自动编译",{"2":{"164":1}}],["设置当",{"2":{"142":1}}],["设置其位置参数",{"2":{"142":1}}],["设置外部查看器启动文件sumatrapdf",{"2":{"142":1}}],["设置pdf查看器用于在",{"2":{"142":1}}],["设置默认的pdf查看器",{"2":{"142":1}}],["设置快捷键步骤如下",{"2":{"84":1}}],["设置边距",{"2":{"73":1}}],["设置何时使用默认的",{"2":{"51":1}}],["设置页面交互能力较强",{"2":{"24":1}}],["设置页面和代码设置页面均为设置页面",{"2":{"24":1}}],["设置页面",{"2":{"24":1}}],["按标记筛选",{"2":{"183":1}}],["按标签筛选",{"0":{"183":1},"2":{"129":1}}],["按照我的添加在parse",{"2":{"153":1}}],["按照我的方法进行添加",{"2":{"77":1}}],["按ctrl+alt+v",{"2":{"151":1}}],["按ctrl+alt+j",{"2":{"84":1}}],["按快捷键ctrl+f可以进行文件搜索",{"2":{"49":1}}],["按win",{"2":{"2":1}}],["听着是不是和可变形动态卷积dcn挺相似",{"2":{"48":1}}],["享受更大的接收域和更高的吞吐量的好处",{"2":{"46":1}}],["此转换对于在新的数据子集上训练模型或从训练中排除不需要的图像非常有用",{"2":{"183":1}}],["此转换非常有用",{"2":{"181":1}}],["此步骤将对象检测数据集转换为分类数据集",{"2":{"167":1}}],["此步骤对于在训练模型之前确保数据集保持一致至关重要",{"2":{"129":1}}],["此功能不受官方支持",{"2":{"164":3}}],["此属性必须是字符串数组",{"2":{"164":1}}],["此路径为",{"2":{"142":1}}],["此命令是将生成的辅助文件",{"2":{"142":1}}],["此命令作用于",{"2":{"142":1}}],["此代码是设置使用外部查看器时",{"2":{"142":1}}],["此代码仅为展示所用",{"2":{"132":1}}],["此参数为下文进行pdf内部查看和外部查看进行切换的关键参数",{"2":{"142":1}}],["此版本的gflops大概涨到了24",{"2":{"133":1}}],["此串代码是对编译链进行定义",{"2":{"51":1}}],["此处就不再赘述",{"2":{"151":1}}],["此处需要您根据自身情况进行路径更改",{"2":{"142":1}}],["此处设置为auto",{"2":{"142":1}}],["此处选择",{"2":{"142":1}}],["此处快捷键的选择为上文设置",{"2":{"84":1}}],["此处笔者使用的为double",{"2":{"51":1}}],["此处为默认配置",{"2":{"51":1}}],["此处提出了线性注意力机制的优势",{"2":{"46":1}}],["此菜单默认状态下停用",{"2":{"51":1}}],["此项笔者设置为never",{"2":{"51":1}}],["此外",{"2":{"18":1,"28":1,"56":1,"57":1,"105":1,"120":1}}],["例如",{"2":{"46":1,"107":1,"129":1,"148":5,"150":2}}],["线性注意力的限制和改进",{"2":{"56":1}}],["线性注意力模块因此能够在节省计算成本的同时",{"2":{"46":1}}],["线性注意力模块实际上降低了总体计算成本",{"2":{"46":1}}],["线性注意力可以解耦softmax操作",{"2":{"46":1}}],["线性注意力",{"2":{"46":1}}],["`activating",{"2":{"45":1}}],["|",{"2":{"45":10}}],["大小",{"2":{"95":1}}],["大概在六百多行吧",{"2":{"64":1,"109":1,"147":1}}],["大卷积核与可变形卷积结合使用",{"2":{"68":1}}],["大卷积核",{"0":{"68":1},"2":{"57":1,"68":1}}],["大家可能看我描述不太懂",{"2":{"98":1,"146":1}}],["大家可以复制下面的yaml文件运行",{"2":{"153":1}}],["大家可以复制进行训练",{"2":{"75":1,"155":1}}],["大家可以看下面的运行结果和添加的位置所以不存在我发的代码不全或者运行不了的问题大家有问题也可以在评论区评论我看到都会为大家解答",{"2":{"112":1,"152":1}}],["大家可以看下面的网络结构图中我进行了标注",{"2":{"98":1,"146":1,"149":1,"180":1}}],["大家可以看我下面的文章",{"2":{"44":1,"83":1}}],["大家可以自行训练",{"2":{"82":1}}],["大家应该就清楚了",{"2":{"60":1}}],["大家在下面的代码中可以看到",{"2":{"52":1}}],["大家复制代码的时候需要注意这是一种无参数的注意力机制",{"2":{"50":1}}],["大核注意力机制",{"1":{"14":1,"20":1,"27":1,"35":1,"44":1,"54":1,"65":1,"76":1,"87":1,"98":1,"111":1}}],["名字可以根据你自己的习惯起",{"2":{"127":1}}],["名字为rcsosa即可",{"2":{"85":1}}],["名字为dilation即可",{"2":{"43":1}}],["名为biformer",{"2":{"4":1}}],["构成",{"2":{"42":1}}],["橙色模块",{"2":{"42":1}}],["蓝色模块",{"2":{"42":1}}],["后期我会发文件里面集成上百种的改进机制",{"2":{"110":1}}],["后面大家有什么想看的机制都可以指定",{"2":{"99":1}}],["后面经过各种处理信息早已经丢失了",{"2":{"88":1}}],["后添加上",{"2":{"41":1}}],["后合并",{"2":{"33":1}}],["否则就会报错",{"2":{"41":1}}],["否则后期手动添加比较麻烦",{"2":{"2":1}}],["都不清除辅助文件",{"2":{"51":1}}],["都不一样",{"2":{"0":1}}],["都选择清除辅助文件",{"2":{"51":1}}],["都需要加上英文状态下的",{"2":{"41":1}}],["查找对象",{"2":{"167":1}}],["查看效果图",{"2":{"151":1}}],["查看",{"2":{"142":1}}],["查看器查看",{"2":{"142":1}}],["查看器",{"2":{"142":1}}],["查看器设置",{"2":{"41":1}}],["查看具有相同的效果",{"2":{"95":1}}],["查询感知的自适应性",{"2":{"9":1}}],["查询感知的稀疏性",{"2":{"4":1}}],["先给出效果图",{"2":{"41":1}}],["步骤如下",{"2":{"179":1,"184":1}}],["步骤三",{"0":{"49":1,"64":1,"109":1,"147":1}}],["步骤二",{"0":{"39":1,"53":1,"96":1,"137":1}}],["步骤一",{"0":{"30":1,"43":1,"85":1,"127":1}}],["扩展名为",{"2":{"142":1}}],["扩散指数",{"2":{"36":1}}],["扩张深度卷积",{"2":{"20":1}}],["手把手教你添加d",{"0":{"114":1},"1":{"125":1,"135":1,"145":1,"153":1,"160":1,"165":1,"169":1,"173":1}}],["手把手教你添加acmix",{"0":{"103":1},"1":{"116":1,"127":1,"137":1,"147":1}}],["手把手教你添加triplet",{"0":{"72":1},"1":{"83":1,"94":1,"106":1,"119":1,"130":1}}],["手把手教你添加rcs",{"0":{"63":1},"1":{"74":1,"85":1,"96":1,"109":1,"122":1,"133":1,"143":1,"152":1}}],["手把手教你添加hattention机制",{"0":{"55":1},"1":{"66":1,"77":1}}],["手把手教你添加msda模块",{"0":{"26":1},"1":{"34":1,"43":1,"53":1,"64":1,"75":1,"86":1,"97":1,"110":1,"123":1}}],["手把手教你将lskattention添加到你的网络结构中",{"0":{"35":1},"1":{"44":1,"54":1,"65":1,"76":1}}],["处理后的特征和直接通过的特征在通道混洗",{"2":{"33":1}}],["处打开",{"2":{"24":1}}],["形成rcs",{"2":{"33":1}}],["之后我可以选择新建一个项目",{"2":{"179":1,"184":1}}],["之后我们找到",{"2":{"53":1,"96":1,"137":1}}],["之后也通过sigmoid函数生成注意力权重",{"2":{"31":1}}],["之后同样进行残差变换",{"2":{"16":1}}],["执行z池化和卷积操作",{"2":{"31":1}}],["负责捕获通道维度c与空间维度h和w之间的依赖性",{"2":{"31":1}}],["负责计算通道维度c和空间维度w的注意力权重",{"2":{"31":1}}],["操作",{"2":{"31":1}}],["zebra",{"2":{"138":1}}],["zeros",{"2":{"30":1,"45":5,"52":2,"89":3,"92":1,"102":2}}],["zihao",{"2":{"73":1}}],["zpool",{"2":{"50":2}}],["z",{"2":{"31":1,"89":3}}],["z池化",{"2":{"23":1}}],["该页面就显示了我们可以进行的所有数据预处理的操作包括",{"2":{"184":1}}],["该图像中不存在您希望模型检测到的任何",{"2":{"181":1}}],["该软件的优点在于在具有",{"2":{"95":1}}],["该代码本身存在一个bug",{"2":{"92":1}}],["该快捷键为默认设置",{"2":{"84":1}}],["该结果只能展示出该机制有效",{"2":{"78":1}}],["该模块由多个卷积层组成",{"2":{"68":1}}],["该模块通过简单的映射函数调整查询和键的特征方向",{"2":{"56":1}}],["该命令的作用为设置",{"2":{"51":1}}],["该目录的构造如下",{"2":{"30":1}}],["该架构包括多个biformer块的堆叠",{"2":{"15":1}}],["简介",{"0":{"105":1},"1":{"118":1,"129":1,"139":1,"148":1,"156":1,"162":1,"167":1,"171":1,"175":1,"178":1,"181":1,"183":1,"184":1}}],["简言之",{"2":{"29":1}}],["简称bra",{"2":{"4":1}}],["聚焦能力",{"2":{"56":1}}],["聚焦能力和特征多样性",{"2":{"29":1}}],["聚焦线性注意力",{"1":{"29":1,"37":1,"46":1,"56":1,"67":1,"78":1,"89":1,"100":1,"113":1,"124":1,"134":1,"144":1},"2":{"29":1,"56":1}}],["旨在减少计算开销并整合轻量级的聚合操作",{"2":{"81":1}}],["旨在提高网络在处理密集连接时的效率",{"2":{"33":1}}],["旨在提高效率和表现力",{"2":{"29":1,"56":1}}],["旨在训练阶段通过多分支结构学习丰富的特征信息",{"2":{"18":1}}],["是触发synctex的扩展名为",{"2":{"164":1}}],["是源图像的反射像素",{"2":{"148":1}}],["是当触发synctex被触发时",{"2":{"142":1}}],["是生成pdf文件的绝对路径的占位符",{"2":{"142":1,"164":1}}],["是行号",{"2":{"142":1,"164":1}}],["是用于生成pdf文件的绝对路径的占位符",{"2":{"142":1,"164":1}}],["是一种引入了可变形注意力机制的视觉transformer",{"2":{"69":1}}],["是一种用于捕捉图像中的广泛上下文信息的机制",{"2":{"68":1}}],["是一种用于视觉transformer模型的注意力机制",{"2":{"29":1,"56":1}}],["是一种技术",{"2":{"42":1}}],["是一个关键的模块",{"2":{"33":1}}],["是rcs",{"2":{"12":1,"18":1,"33":1}}],["恢复成高分辨率的图像",{"2":{"28":1}}],["峰值信噪比",{"2":{"28":1}}],["专门针对hat",{"2":{"28":1}}],["同任务预训练策略",{"2":{"28":1}}],["同时降低了模型的复杂度",{"2":{"92":1}}],["同时将自注意力机制中的查询",{"2":{"92":1}}],["同时通过减少参数数量来降低计算复杂度",{"2":{"68":1}}],["同时大家也可以放在其他的位置即插即用",{"2":{"61":1}}],["同时避免了传统自我关注机制的高计算成本",{"2":{"57":1}}],["同时避免了过度复杂化网络结构所带来的低效率和高资源消耗",{"2":{"42":1}}],["同时解决了上述两个问题",{"2":{"51":1}}],["同时在网络结构中引入一个dat计算量由8",{"2":{"48":1}}],["同时这种方法在计算上是高效的",{"2":{"31":1}}],["同时没有降低性能",{"2":{"20":1}}],["同时减少内存消耗",{"2":{"18":1}}],["同时保持源图像纵横比",{"2":{"148":4}}],["同时保持良好的性能",{"2":{"69":1}}],["同时保持计算效率",{"2":{"33":1}}],["同时保持训练阶段学到的特征表达能力",{"2":{"25":1}}],["同时保持通道间的信息交换",{"2":{"18":1}}],["同时保持了性能",{"2":{"13":1}}],["同时本文对rcs",{"2":{"3":1}}],["同时关注空间维度上的重要特征",{"2":{"3":1}}],["重命名",{"2":{"178":1}}],["重新标记",{"2":{"178":1}}],["重新缩放图像以包括落在第",{"2":{"162":1}}],["重新生成位置编码",{"2":{"89":1}}],["重复的页脚定义",{"2":{"138":1}}],["重要内容",{"2":{"138":1}}],["重要",{"2":{"138":2}}],["重构为混合模块",{"2":{"92":1}}],["重构为1×1卷积形式",{"2":{"70":1}}],["重叠交叉注意模块",{"2":{"28":1}}],["重启",{"2":{"11":1}}],["作者提出了一个新颖的聚焦线性注意力",{"2":{"56":1}}],["作者提出了一种新的预训练方法",{"2":{"28":1}}],["作者的模型",{"2":{"36":1}}],["作者还提出了一个重叠交叉注意模块来增强跨窗口信息的交互",{"2":{"28":1}}],["作为外部查看器",{"2":{"95":1}}],["作为最终输出",{"2":{"92":1}}],["作为",{"2":{"2":1}}],["作为一种强大的排版系统",{"2":{"0":1}}],["98",{"2":{"162":1}}],["90",{"2":{"141":6}}],["90度旋转",{"0":{"141":1}}],["9gflops涨到了9",{"2":{"48":1}}],["96",{"2":{"45":3}}],["9涨到了9",{"2":{"29":1}}],["9",{"0":{"151":1},"2":{"27":2,"45":1,"51":1,"60":3,"86":3,"97":3,"99":1,"106":3,"119":3,"133":3,"143":3,"161":3,"165":3,"166":3,"169":3}}],["7154",{"2":{"156":1}}],["79",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["768",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["75",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["700多行",{"2":{"28":1}}],["7",{"0":{"62":1,"73":1,"84":1},"1":{"73":1,"84":1},"2":{"27":3,"41":1,"45":1,"50":1,"60":2,"86":2,"97":2,"99":2,"101":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["7x7",{"2":{"13":1}}],["矩形的宽度代表张量的通道数",{"2":{"25":1}}],["渐变色的矩形代表张量的特定特征",{"2":{"25":1}}],["原本内嵌输出的",{"2":{"151":1}}],["原来的多分支结构被简化为一个单一的3x3",{"2":{"25":1}}],["原始图像的数量越少",{"2":{"150":1}}],["原始lka设计",{"2":{"20":1}}],["原始注意力",{"2":{"4":1}}],["与上文相同",{"2":{"142":1}}],["与通用软件安装过程一致",{"2":{"108":1}}],["与卷积操作通过1x1卷积进行特征分解",{"2":{"81":1}}],["与另一部分输入进行通道shuffle和连接",{"2":{"25":1}}],["与1×1卷积结合",{"2":{"20":1}}],["另一部分通过堆叠的rcs模块进行处理",{"2":{"33":1}}],["另一部分保持不变",{"2":{"25":1}}],["另一个分支专注于高度",{"2":{"5":1}}],["结果图如下",{"2":{"82":1}}],["结果分析",{"0":{"82":1}}],["结果表明",{"2":{"36":1}}],["结果",{"2":{"36":1}}],["结构被重参数化成一个单一的3x3卷积",{"2":{"25":1}}],["结构在训练阶段使用多个分支",{"2":{"25":1}}],["结合了",{"2":{"92":1}}],["结合了卷积和自注意力聚合",{"2":{"81":1}}],["结合了自注意力机制和卷积运算的优势",{"2":{"70":1}}],["结合了通道混洗",{"2":{"12":1}}],["结合可变形卷积技术",{"2":{"57":1}}],["结合",{"2":{"23":1}}],["比如编译目录和编译参考文献时",{"2":{"51":1}}],["比如说",{"2":{"5":1}}],["比swinir和edt有显著提升",{"2":{"28":1}}],["比较便捷",{"2":{"24":1}}],["比较麻烦",{"2":{"24":1,"51":1}}],["js",{"2":{"132":1,"142":1,"164":1}}],["json界面设置",{"2":{"159":1}}],["json设置",{"2":{"24":1}}],["json",{"2":{"24":1,"41":2,"132":1,"151":1}}],["just",{"2":{"45":1}}],["j=self",{"2":{"30":5}}],["j",{"2":{"30":10,"89":9}}],["jit",{"2":{"19":1,"45":2}}],["⊕代表广播元素级加法",{"2":{"23":1}}],["经过上图的操作你可以上传好自己的数据集",{"2":{"179":1,"184":1}}],["经过多个rhag处理的特征通过图像重建部分",{"2":{"28":1}}],["经过softmax函数进行归一化",{"2":{"23":1}}],["经过对方同意",{"2":{"0":1}}],["生成新的样本",{"2":{"120":1}}],["生成一组中间特征",{"2":{"59":1,"70":1}}],["生成的图像是所需输出尺寸的居中裁剪",{"2":{"148":1}}],["生成的",{"2":{"51":1}}],["生成通道描述符",{"2":{"23":1}}],["生成注意力权重",{"2":{"16":1}}],["希望大家能够举一反三",{"2":{"22":1}}],["希望能够对大家有所帮助",{"2":{"0":1}}],["添加dat到你的网络中",{"0":{"115":1},"1":{"126":1}}],["添加focused",{"0":{"100":1},"1":{"113":1,"124":1,"134":1,"144":1}}],["添加的位置是检测头和neck中间的位置",{"2":{"119":1}}],["添加的位置不同效果也不同",{"2":{"98":1,"110":1,"146":1,"149":1,"170":1,"180":1}}],["添加的版本二具体那种适合你需要大家自己多做实验来尝试",{"2":{"97":1,"143":1,"166":1}}],["添加在检测头里",{"2":{"88":1}}],["添加之后的效果如下",{"2":{"60":1}}],["添加如下图所示内容",{"2":{"49":1}}],["添加过程又需要截特别图片会导致文章大家读者也不通顺如果你已经会添加注意力机制了",{"2":{"44":1,"83":1}}],["添加教程这里不再重复介绍",{"2":{"44":1,"83":1}}],["添加biformer注意力机制",{"0":{"22":1},"1":{"30":1,"39":1,"49":1}}],["添加到path",{"2":{"6":1}}],["五",{"0":{"22":1,"87":1,"88":1,"100":1,"136":1,"140":1,"155":1,"177":1},"1":{"30":1,"39":1,"49":1,"98":1,"99":1,"111":1,"112":1,"113":1,"124":1,"134":1,"144":1,"146":1,"149":1,"154":1,"157":1,"161":1,"166":1,"170":1,"174":1,"180":1,"182":1}}],["通常按顺序使用两个模型",{"2":{"167":1}}],["通常",{"2":{"120":1}}],["通常会等待接收图像以进行训练",{"2":{"107":1}}],["通常会等待您的",{"2":{"107":1}}],["通常小于标记数",{"2":{"46":1}}],["通道的图像转换为具有单个灰度通道的图像",{"2":{"156":1}}],["通道数",{"2":{"89":1}}],["通道池化后的7x7卷积",{"2":{"23":1}}],["通道注意力关注于识别哪些通道更重要",{"2":{"21":1,"36":1}}],["通过",{"2":{"107":1}}],["通过使用roboflow",{"2":{"105":1}}],["通过使用深度可分离的卷积",{"2":{"68":1}}],["通过调整其与",{"2":{"95":1}}],["通过扩展",{"2":{"90":1}}],["通过模块化设计",{"2":{"81":1}}],["通过上面的方式产生多种参考点分布在图像上",{"2":{"80":1}}],["通过学习图像特征本身来确定这些偏移量",{"2":{"79":1}}],["通过分解自注意力和卷积中的运算",{"2":{"70":1}}],["通过采用大卷积核来模拟类似自我关注的感受野",{"2":{"57":1}}],["通过适当的近似手段",{"2":{"46":1}}],["通过在网络的一次性聚合",{"2":{"42":1}}],["通过在网络的最后一部分只进行一次特征聚合",{"2":{"33":1}}],["通过在不同头部设置不同的扩张率",{"2":{"13":1}}],["通过本文你能够了解到",{"2":{"29":1}}],["通过广泛的实验",{"2":{"28":1}}],["通过广播加法结合原始特征图",{"2":{"23":1}}],["通过结构重参数化",{"2":{"18":1}}],["通过结构化重参数化简化为单一分支",{"2":{"12":1}}],["通过这样的设计",{"2":{"16":1}}],["通过这种方法",{"2":{"13":1}}],["通过这种双层路由注意力机制",{"2":{"1":1}}],["通过旋转输入张量和应用残差变换来建立不同维度间的依赖",{"2":{"16":1}}],["通过一个创新的三支结构捕获通道",{"2":{"16":1}}],["通过对每个分支中的输入张量进行排列变换",{"2":{"16":1}}],["通过整体架构和biformer块的设计",{"2":{"15":1}}],["通过实验yolov8在整合lskattention机制后",{"2":{"14":1}}],["通过不同头部的自注意力机制",{"2":{"13":1}}],["通过为不同的头部设置不同的扩张率",{"2":{"13":1}}],["通过重参数化卷积来增强网络的特征提取能力",{"2":{"12":1}}],["通过双层路由注意力机制",{"2":{"9":1}}],["通过收集键",{"2":{"4":1}}],["通过构建一个区域级别的亲和度图",{"2":{"4":1}}],["通过网址",{"2":{"2":1}}],["混合注意力变换器",{"0":{"36":1},"2":{"21":1,"28":1,"36":1}}],["个类重新映射",{"2":{"178":1}}],["个人完整配置",{"0":{"164":1}}],["个人总结",{"2":{"20":1,"67":1}}],["个百分位数内的所有强度",{"2":{"162":1}}],["个性化安装",{"2":{"2":1}}],["每层输入和输出特征图的大小都有标注",{"2":{"80":1}}],["每层由两个1d卷积层组成",{"2":{"20":1}}],["每种模块都设计用于处理特征图",{"2":{"23":1}}],["每个标签有三个选项",{"2":{"183":1}}],["每个灰度像素的值计算为相应红色",{"2":{"156":1}}],["每个核处理不同的特征子集",{"2":{"92":1}}],["每个代码语句",{"2":{"41":1}}],["每个组内包含多个混合注意力块",{"2":{"28":1}}],["每个分支在生成注意力权重后",{"2":{"31":1}}],["每个分支都有一个permute操作来调整维度",{"2":{"23":1}}],["每个分支进行不同的处理",{"2":{"23":1}}],["每个分支负责捕获空间维度h或w与通道维度c之间的交互特征",{"2":{"16":1}}],["每个头部的自注意力操作针对的是其对应的扩张率和感受野",{"2":{"13":1}}],["每个头部处理不同的特征子集",{"2":{"13":1}}],["每个区域只需要关注前k个路由的区域",{"2":{"4":1}}],["每个图像块都与一个位置路由器相关联",{"2":{"1":1}}],["每个使用者的",{"2":{"0":1}}],["每个使用者都能够根据自己的需求和想法下载相应的插件",{"2":{"0":1}}],["串联的水平和垂直1d大核深度卷积与1×1卷积结合",{"2":{"20":1}}],["串联卷积操作",{"2":{"20":1}}],["图示d",{"0":{"157":1,"182":1}}],["图示包含了",{"2":{"92":1}}],["图标",{"2":{"138":1}}],["图像为正方形",{"2":{"148":3}}],["图像纵横比和原始数据保持不变",{"2":{"148":1}}],["图像呈方形",{"2":{"148":1}}],["图像垂直或水平",{"2":{"131":1}}],["图像中每个像素的重要性",{"2":{"36":1}}],["图像中标记框内区域时",{"2":{"36":1}}],["图片展示的很直观",{"2":{"91":1}}],["图片中的符号⊗代表矩阵乘法",{"2":{"23":1}}],["图中",{"2":{"81":1}}],["图中仅显示了4个参考点",{"2":{"80":1}}],["图中分为四个部分",{"2":{"67":1}}],["图中显示的多层rcs",{"2":{"42":1}}],["图中详细展示了三个分支如何处理输入张量",{"2":{"31":1}}],["图中的idetect是从yolov7中借鉴过来的",{"2":{"42":1}}],["图中的每个子图表示三重注意力中的一个分支",{"2":{"16":1}}],["图中的例子展示了三种不同的扩张率",{"2":{"13":1}}],["图表显示",{"2":{"28":1}}],["图d",{"2":{"20":1}}],["图c",{"2":{"20":1}}],["图b",{"2":{"20":1}}],["图a",{"2":{"20":1}}],["朴素的2d大核深度卷积",{"2":{"20":1}}],["论文展示了所提出模块和预训练策略的有效性",{"2":{"28":1}}],["论文还引入了一种同任务预训练策略",{"2":{"28":1}}],["论文提出的lska",{"2":{"20":1}}],["论文地址",{"2":{"4":1,"7":1,"10":1,"13":1,"20":1,"37":1,"47":1,"58":1}}],["十亿浮点运算次数",{"2":{"20":1}}],["精度权衡",{"2":{"20":1}}],["显示出更高的计算效率和更小的内存占用",{"2":{"20":1}}],["显示出其广泛的适用性",{"2":{"20":1}}],["显示如下",{"2":{"11":1}}],["语义分割等多种计算机视觉任务中有效应用",{"2":{"20":1}}],["语义分割等方面的积极影响",{"2":{"14":1}}],["时操作步骤相同",{"2":{"151":1}}],["时构建项目",{"2":{"51":1}}],["时",{"2":{"20":1,"181":1}}],["纹理和形状",{"2":{"20":1}}],["虽然这个实验不能产生确定性的结论",{"2":{"48":1}}],["虽然采用了分解和串联的策略",{"2":{"20":1}}],["虽然稀疏矩阵乘法是适用的",{"2":{"4":1}}],["保持了高效的图像处理能力",{"2":{"20":1}}],["保持效果",{"2":{"20":1}}],["保留每个节点的前k个连接",{"2":{"4":1}}],["横向扩展以下自己的知识库",{"2":{"23":1}}],["横向",{"2":{"20":1}}],["核分解",{"2":{"20":1}}],["核心思想是在粗粒度的区域级别上过滤掉最不相关的键",{"2":{"4":1}}],["中间",{"2":{"119":1}}],["中间使用relu激活函数",{"2":{"23":1}}],["中",{"2":{"51":1}}],["中的",{"2":{"51":1}}],["中的应用问题进行的改进",{"2":{"20":1}}],["中部分支",{"2":{"31":1}}],["中文环境启动页面",{"2":{"11":1}}],["中文语言环境配置",{"0":{"11":1}}],["80",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"148":3,"161":1,"165":1,"166":1,"169":1}}],["8左右",{"2":{"38":1}}],["8",{"0":{"95":1,"108":1,"121":1,"132":1,"142":1},"1":{"108":1,"121":1,"132":2,"142":2},"2":{"19":2,"45":1,"51":1,"52":2,"60":7,"86":4,"97":4,"99":5,"102":3,"106":4,"119":4,"133":4,"143":4,"161":4,"165":4,"166":4,"169":4}}],["68229632",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["68229648",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["67",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["650行左右",{"2":{"49":1}}],["640",{"2":{"148":1}}],["640x640",{"2":{"148":3}}],["64",{"2":{"45":2,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["6",{"0":{"32":1,"41":1,"51":1,"138":1},"1":{"41":1,"51":1},"2":{"19":8,"41":1,"45":8,"60":3,"86":3,"89":3,"97":3,"99":3,"106":3,"119":3,"133":3,"143":3,"161":3,"165":3,"166":3,"169":3}}],["6左右",{"2":{"3":1}}],[">非常",{"2":{"138":1}}],[">=",{"2":{"102":2}}],[">",{"2":{"19":3,"30":21,"41":4,"45":4,"51":4,"89":15,"92":2,"101":1,"102":9,"164":4}}],["y^",{"2":{"138":2}}],["yωω",{"2":{"138":2}}],["yaml文件二",{"2":{"149":1,"180":1}}],["yaml文件一",{"2":{"149":1,"180":1}}],["yaml文件一和二",{"2":{"110":1,"170":1}}],["yaml文件截图如下",{"2":{"126":1}}],["yaml",{"2":{"60":3,"71":1,"86":2,"97":2,"99":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["yet",{"2":{"30":2}}],["y4",{"2":{"19":2}}],["y3",{"2":{"19":2}}],["y2",{"2":{"19":2}}],["y1",{"2":{"19":3}}],["y",{"2":{"19":4,"45":2,"52":2,"61":8,"89":9,"101":9,"102":9,"138":2,"156":1,"158":1}}],["yolo",{"2":{"60":1,"61":1,"71":1,"86":1,"89":1,"97":1,"99":1,"101":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["yolov8官方推荐了一个名为roboflow的数据集网站",{"2":{"105":1}}],["yolov8的neck部分负责特征融合",{"2":{"98":1,"110":1,"146":1,"149":1,"170":1,"180":1}}],["yolov8x",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["yolov8l",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["yolov8m",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["yolov8s",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["yolov8n",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["yolov8",{"2":{"60":5,"86":4,"97":4,"99":4,"106":4,"119":4,"133":4,"143":4,"161":4,"165":4,"166":4,"169":4}}],["yolo感兴趣的话",{"2":{"52":1}}],["yolo了没啥区别了",{"2":{"52":1}}],["yolo我们只是用其中的rcs",{"2":{"52":1}}],["yolo主要由rcs",{"2":{"42":1}}],["yolo的yaml文件供大家参考",{"2":{"52":1}}],["yolo的整体架构",{"2":{"42":1}}],["yolo的核心组成部分",{"2":{"18":1}}],["yolo架构中的一个关键组成部分旨在通过一次性聚合来提高模型处理特征的能力",{"2":{"33":1}}],["yolo中还有一个repvgg模块",{"2":{"52":1}}],["yolo中",{"2":{"33":1,"42":1}}],["yolo中提出的一种结构",{"2":{"12":1}}],["yolo提出的rcs",{"2":{"3":1}}],["kk",{"2":{"102":4}}],["ksize",{"2":{"102":3}}],["ksize=9",{"2":{"102":1}}],["k2的1x1卷积",{"2":{"81":1}}],["k=1",{"2":{"101":1}}],["k=",{"2":{"61":2,"89":2,"101":2}}],["k=self",{"2":{"30":1}}],["ktv来改变计算顺序",{"2":{"46":1}}],["k^2",{"2":{"81":1}}],["k^",{"2":{"46":1}}],["kq",{"2":{"30":1}}],["kq+c",{"2":{"30":2}}],["kv=kv",{"2":{"30":1}}],["kv",{"2":{"30":99,"45":7,"89":9,"102":8}}],["kvgather",{"2":{"30":2}}],["keepdim=true",{"2":{"89":4}}],["keep",{"2":{"30":1,"45":3}}],["kenel",{"2":{"30":2}}],["keywords",{"2":{"45":1}}],["keybinding",{"2":{"41":3,"51":1,"164":1}}],["key",{"2":{"30":8,"45":5,"81":1,"92":2,"102":8}}],["kernels",{"2":{"61":1,"89":1,"101":1}}],["kernelid",{"2":{"52":2}}],["kernel1x1",{"2":{"52":5}}],["kernel3x3",{"2":{"52":2}}],["kernel=none",{"2":{"30":1}}],["kernel",{"2":{"19":33,"20":3,"27":24,"30":4,"45":1,"50":5,"52":17,"57":1,"68":2,"89":6,"90":2,"92":38,"101":10,"102":6}}],["k代表最大感受野",{"2":{"20":1}}],["kwargs",{"2":{"19":6,"45":1}}],["k",{"2":{"19":12,"27":9,"30":22,"45":7,"46":1,"61":2,"89":26,"92":11,"101":11,"102":8}}],["up",{"2":{"45":1,"52":2}}],["upscale=2",{"2":{"45":1}}],["upscale",{"2":{"45":5}}],["upsampler=",{"2":{"45":1}}],["upsampler",{"2":{"45":5}}],["upsample",{"2":{"45":8,"60":2,"86":2,"97":2,"99":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["util",{"2":{"45":1}}],["utils",{"2":{"45":1}}],["usage",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["using",{"2":{"30":1,"61":1,"89":1,"101":1}}],["usepackage",{"2":{"73":3}}],["used",{"2":{"45":1}}],["use",{"2":{"30":2,"45":14,"52":2,"102":6}}],["unembedding",{"2":{"45":1}}],["unembed",{"2":{"45":4}}],["unsqueeze",{"2":{"45":6,"50":2,"92":10,"102":4}}],["unit",{"2":{"30":1,"101":2}}],["unfold",{"2":{"19":4,"45":3,"92":9}}],["urban100和manga109",{"2":{"28":1}}],["u",{"2":{"27":2,"101":2}}],["ui界面设置",{"2":{"159":1}}],["ui",{"2":{"24":4}}],["ultralytics",{"1":{"107":1,"120":1,"131":1,"141":1,"150":1,"158":1,"163":1,"168":1,"172":1,"176":1,"179":1},"2":{"19":1,"27":1,"30":1,"39":2,"43":1,"45":1,"49":1,"53":1,"60":3,"66":2,"71":1,"85":1,"86":2,"96":1,"97":2,"99":2,"106":2,"119":2,"127":1,"133":2,"137":1,"143":2,"145":1,"161":2,"165":2,"166":2,"169":2}}],["0721",{"2":{"156":1}}],["05左右",{"2":{"86":1,"161":1}}],["08",{"2":{"73":1}}],["0n",{"2":{"60":2,"86":2,"97":2,"99":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["00",{"2":{"60":3,"86":3,"97":3,"99":3,"106":3,"119":3,"133":3,"143":3,"161":3,"165":3,"166":3,"169":3}}],["01",{"2":{"45":2,"50":1,"102":2}}],["02",{"2":{"19":1,"45":4,"73":1}}],["0",{"2":{"19":31,"27":24,"30":13,"45":105,"50":5,"52":4,"60":8,"61":2,"86":8,"89":14,"92":22,"97":8,"99":8,"101":3,"102":39,"106":8,"119":8,"133":8,"143":8,"156":3,"161":8,"165":8,"166":8,"169":8}}],["06左右",{"2":{"8":1}}],["quality",{"2":{"45":1}}],["queryselector",{"2":{"138":1}}],["query",{"2":{"30":7,"45":5,"81":1,"92":2}}],["quot",{"2":{"2":1,"3":4,"6":1,"8":2,"11":6,"17":6,"27":2,"49":2,"60":2,"142":4}}],["q",{"2":{"19":7,"30":18,"45":15,"46":1,"89":23,"92":11,"102":31}}],["qk+c",{"2":{"30":3}}],["qkvo",{"2":{"30":3}}],["qkvlinear",{"2":{"30":3}}],["qkv",{"2":{"19":25,"30":10,"45":28,"89":1}}],["qk",{"2":{"19":18,"30":42,"45":23,"89":3}}],["xetex",{"2":{"51":1}}],["xelatex",{"2":{"41":9,"51":14,"84":1,"164":9}}],["x1",{"2":{"45":2,"52":5}}],["x0",{"2":{"45":2}}],["xxxpool",{"2":{"30":1}}],["x4",{"2":{"28":1}}],["x3c",{"2":{"45":3,"138":6}}],["x3",{"2":{"28":1,"45":2,"52":2}}],["x26",{"2":{"45":1}}],["x2",{"2":{"28":1,"45":2,"52":5}}],["x",{"2":{"19":108,"23":2,"27":3,"30":17,"45":191,"50":41,"52":33,"60":1,"61":8,"86":1,"89":45,"92":12,"97":1,"99":1,"101":42,"102":30,"106":1,"119":1,"133":1,"143":1,"158":1,"161":1,"165":1,"166":1,"169":1}}],["=>",{"2":{"138":1}}],["==",{"2":{"19":9,"27":6,"30":15,"45":16,"52":3,"61":1,"89":3,"92":1,"101":2,"102":2}}],["=",{"2":{"19":147,"27":32,"30":85,"44":1,"45":285,"50":26,"52":75,"61":11,"77":1,"89":78,"92":55,"101":43,"102":94,"113":1,"138":35,"147":1,"156":1}}],["gz",{"2":{"142":2}}],["gfm",{"2":{"138":1}}],["gflop",{"2":{"99":1,"161":1,"166":1}}],["gflops",{"2":{"60":5,"86":5,"97":5,"99":4,"106":5,"119":5,"133":5,"143":5,"161":4,"165":5,"166":4,"169":5}}],["gpu",{"2":{"107":3}}],["g",{"2":{"61":1,"89":1,"101":1,"102":12,"132":1,"142":1,"156":1,"164":1}}],["g=self",{"2":{"102":2}}],["g=g",{"2":{"61":1,"89":1}}],["g=1",{"2":{"61":2,"89":2,"101":3}}],["given",{"2":{"61":1,"89":1,"101":2}}],["github",{"2":{"4":1,"45":2,"51":1,"73":1}}],["generating",{"2":{"92":1}}],["geometry",{"2":{"73":1}}],["get",{"2":{"52":1,"102":5}}],["gelu",{"2":{"19":11,"45":5,"101":1,"102":1}}],["gls",{"2":{"41":1,"51":1,"164":1}}],["glo",{"2":{"41":1,"51":1,"164":1}}],["global",{"2":{"23":2,"30":2}}],["globalstage",{"2":{"19":2}}],["globalblock",{"2":{"19":2}}],["globalattention",{"2":{"19":2}}],["glg",{"2":{"41":1,"51":1,"164":1}}],["grid=displacement",{"2":{"102":1}}],["grid=pos",{"2":{"102":1}}],["grid",{"2":{"102":9}}],["grad",{"2":{"102":3}}],["grad=true",{"2":{"92":1}}],["gradients",{"2":{"60":5,"86":5,"97":5,"99":5,"106":5,"119":5,"133":5,"143":5,"161":5,"165":5,"166":5,"169":5}}],["gradient",{"2":{"30":1}}],["groups",{"2":{"45":1,"52":6,"61":1,"89":1,"101":3,"102":15}}],["groups=g",{"2":{"101":1}}],["groups=groups",{"2":{"50":1,"52":4,"101":1}}],["groups=self",{"2":{"92":1,"102":2}}],["groups=head",{"2":{"89":1}}],["groups=1",{"2":{"50":1,"52":2,"102":1}}],["groups=out",{"2":{"19":1}}],["groups=dim",{"2":{"19":2,"27":24,"30":1,"101":2}}],["group",{"2":{"45":3,"52":2,"61":1,"89":1,"101":1,"102":12}}],["gating",{"2":{"101":2}}],["gather",{"2":{"30":6}}],["gamma",{"2":{"52":4}}],["gap",{"2":{"23":1}}],["gt",{"2":{"30":1,"53":1,"55":1,"57":1,"78":1,"84":2,"96":1,"113":1,"137":1}}],["gc",{"2":{"23":1}}],["gmp",{"2":{"23":1}}],["我没有进行尝试大家有兴趣的可以试试",{"2":{"180":1}}],["我仅在大目标检测层的输出添加了一个acmix模块",{"2":{"161":1}}],["我仅在大目标检测层的输出添加了一个msda模块",{"2":{"86":1}}],["我的对比实验是用这个版本跑出来的",{"2":{"133":1}}],["我知道的",{"2":{"112":1,"152":1}}],["我将其进行了解决",{"2":{"92":1}}],["我添加的位置只是随便添加的",{"2":{"82":1}}],["我不可每一种都做实验",{"2":{"75":1,"155":1}}],["我把三个biformer添加到了网络结构中的那个部位",{"2":{"60":1}}],["我这里建议添加到",{"2":{"60":1}}],["我这里起名字的dattention",{"2":{"45":1}}],["我这里起名为dilation然后粘贴进去",{"2":{"19":1}}],["我在官方的代码基础上做了一定的修改",{"2":{"55":1}}],["我后面也会提高rcs",{"2":{"52":1}}],["我只用了100张图片的数据集进行了100个epoch的训练",{"2":{"48":1}}],["我下面会出将其用在rt",{"2":{"46":1}}],["我进行了简单的实验",{"2":{"38":1}}],["我们经过等待之后",{"2":{"82":1}}],["我们直接就可以使用该代码了",{"2":{"77":1}}],["我们只保留字典里你需要的dat就行",{"2":{"77":1}}],["我们找到如下ultralytics",{"2":{"125":1}}],["我们找到如下的地方",{"2":{"64":1,"109":1,"147":1}}],["我们找到七百多行的代码",{"2":{"77":1}}],["我们找到parse",{"2":{"64":1,"109":1,"147":1}}],["我们找到该方法对其进行修改",{"2":{"49":1}}],["我们找到该文件",{"2":{"39":1}}],["我们可以对原始上传图像进行多个版本的预处理并同时保存",{"2":{"184":1}}],["我们可以对原始上传图像进行多个版本的数据增强操作并同时保存",{"2":{"179":1}}],["我们可以开始进行训练了",{"2":{"71":1}}],["我们可以在某一层中添加biformer注意力机制",{"2":{"60":1}}],["我们可以将主要原理概括如下",{"2":{"12":1}}],["我们需要找到如下文件进行修改",{"2":{"60":1}}],["我们需要改动的地方有三处",{"2":{"22":1}}],["我们以后在想导入其它的注意力机制就可以重复步骤一和步骤二",{"2":{"49":1}}],["我们在控制台输入",{"2":{"71":1}}],["我们在步骤二的文件中",{"2":{"49":1}}],["我们在其中复制如下代码即可",{"2":{"30":1}}],["我们在其中创建一个名字为biformer的py文件如图所示",{"2":{"30":1}}],["我们的方法",{"2":{"23":1,"81":1}}],["我们通过下图来看一下biformer的网络结构",{"2":{"15":1}}],["我们介绍将这一机制整合到yolov8的方法",{"2":{"14":1}}],["我们介绍lskattention机制的基本原理",{"2":{"14":1}}],["我们将其复制导",{"2":{"19":1}}],["我们将讲解如何将lskattention大核注意力机制应用于yolov8",{"2":{"14":1}}],["我们将这种方法称为双层路由注意力",{"2":{"4":1}}],["我们提出了一种简单的解决方案",{"2":{"4":1}}],["我们先来看一下不同注意力机制的效果",{"2":{"4":1}}],["目标检测",{"2":{"179":1,"184":1}}],["目标检测和语义分割在内的各种计算机视觉任务上的实验结果表明",{"2":{"4":1}}],["目前",{"2":{"148":1}}],["目录下创建一个py文件复制粘贴进去然后按照章节四进行添加即可",{"2":{"27":1}}],["目录下",{"2":{"19":1}}],["基于通道shuffle的重参数化卷积",{"2":{"18":1,"25":1,"33":1}}],["基本更改",{"2":{"2":1}}],["弹窗",{"2":{"17":1}}],["页面定位到代码相应位置",{"2":{"84":1}}],["页面相应位置",{"2":{"84":1}}],["页面",{"2":{"84":1}}],["页面右下角跳出如下弹窗",{"2":{"17":1}}],["页面和笔者所用图片中展示的页面有略微不同",{"2":{"0":1}}],["没有进行旋转",{"2":{"16":1}}],["没有详细的介绍说明",{"2":{"0":1}}],["分类等可以显示更多",{"2":{"179":1,"184":1}}],["分类",{"2":{"167":1}}],["分散图像中最常用的强度值",{"2":{"162":1}}],["分屏查看",{"2":{"151":1}}],["分解卷积和自注意力",{"2":{"92":1}}],["分别重用和聚合这些中间特征",{"2":{"59":1,"70":1}}],["分别代表查询",{"2":{"46":1}}],["分别关注图像的不同维度",{"2":{"5":1}}],["分为训练阶段",{"2":{"25":1}}],["分为三个分支",{"2":{"23":1}}],["分支",{"2":{"16":3}}],["展示了特征图的转换过程",{"2":{"92":1}}],["展示了自注意力机制",{"2":{"81":1}}],["展示了标准卷积操作",{"2":{"81":1}}],["展示了偏移生成网络的详细结构",{"2":{"80":1}}],["展示了可变形注意力的信息流",{"2":{"80":1}}],["展示了cswin",{"2":{"67":1}}],["展示了pvt",{"2":{"67":1}}],["展示了三个分支如何捕获跨维度交互",{"2":{"16":1}}],["展示这种改进对目标检测",{"2":{"14":1}}],["捕获跨维度依赖性的重要性",{"2":{"16":1}}],["维度间依赖性的重要性",{"2":{"16":1}}],["旋转操作和残差变换",{"2":{"16":1}}],["高达",{"2":{"168":1}}],["高度",{"2":{"16":1,"89":1}}],["高效的计算性能",{"2":{"9":1}}],["跨维度的注意力权重计算",{"2":{"16":1}}],["再接一个7x7卷积",{"2":{"23":1}}],["再通过一个卷积层和relu激活函数",{"2":{"23":1}}],["再变换回原来的输入形状",{"2":{"16":1}}],["再点击安装即可",{"2":{"2":1}}],["再点击安装",{"2":{"2":1}}],["null",{"2":{"181":1}}],["numpy",{"2":{"52":2,"102":1}}],["number",{"2":{"30":4,"45":19,"60":1,"61":1,"86":1,"89":1,"97":1,"99":1,"101":1,"106":1,"119":1,"133":1,"138":3,"143":1,"161":1,"165":1,"166":1,"169":1}}],["num",{"2":{"19":56,"30":9,"45":74,"52":4,"89":12}}],["ns",{"2":{"102":2}}],["np",{"2":{"52":2,"102":2}}],["n=1",{"2":{"52":1,"61":1,"89":1,"101":1}}],["n=196",{"2":{"46":1}}],["n=49",{"2":{"46":1}}],["nd^2",{"2":{"46":1}}],["nd2",{"2":{"46":2}}],["ndim",{"2":{"45":1}}],["n^2",{"2":{"46":1}}],["n×d",{"2":{"46":1}}],["nq",{"2":{"45":4}}],["nc=2",{"2":{"45":1}}],["nc",{"2":{"45":2,"60":2,"86":2,"97":2,"99":2,"102":13,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["nw",{"2":{"45":16}}],["nh",{"2":{"45":9}}],["nhwc",{"2":{"30":2}}],["n代表hadamard乘积",{"2":{"20":1}}],["name",{"2":{"19":1,"41":10,"51":10,"52":1,"92":1,"101":1,"164":10}}],["n",{"2":{"19":4,"30":91,"42":1,"45":13,"46":1,"52":4,"60":2,"61":2,"86":2,"89":8,"97":2,"99":2,"101":2,"102":66,"106":2,"119":2,"133":2,"138":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["no",{"2":{"19":1,"30":2,"45":3,"50":5,"102":11}}],["nonlinearity",{"2":{"52":5}}],["non",{"2":{"30":1,"45":3}}],["none",{"2":{"19":1,"30":12,"45":30,"50":4,"52":6,"60":2,"86":2,"92":2,"97":2,"99":2,"101":1,"102":5,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["nonoverlaping",{"2":{"19":2}}],["note",{"2":{"30":4,"138":1}}],["nothing",{"2":{"30":1}}],["notimplementederror",{"2":{"30":3}}],["not",{"2":{"19":2,"30":13,"45":10,"50":4,"52":1,"92":2,"102":3}}],["norm=true",{"2":{"45":1}}],["norm2",{"2":{"19":4,"45":4}}],["norm1",{"2":{"19":4,"45":4}}],["norm",{"2":{"19":23,"30":1,"45":45,"89":10,"102":2}}],["normalization",{"2":{"45":8,"101":1}}],["normal",{"2":{"19":2,"30":1,"45":5,"102":3}}],["now",{"2":{"11":1}}],["nn",{"2":{"19":79,"27":29,"30":23,"39":2,"43":1,"45":82,"49":1,"50":7,"52":22,"53":1,"60":2,"61":3,"66":2,"85":1,"86":2,"89":20,"92":15,"96":1,"97":2,"99":2,"101":19,"102":27,"106":2,"119":2,"125":1,"127":1,"133":2,"137":1,"143":2,"145":1,"161":2,"165":2,"166":2,"169":2}}],["neat",{"2":{"138":1}}],["nearest",{"2":{"52":1,"60":2,"86":2,"97":2,"99":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["nearest+conv",{"2":{"45":1}}],["net",{"2":{"101":2}}],["network在网络的代码中需要控制可添加可不添加",{"2":{"80":1}}],["networks",{"2":{"20":1}}],["network",{"2":{"15":1,"67":1}}],["neck部分",{"2":{"98":1,"110":1,"146":1,"149":1,"170":1,"180":1}}],["neck层",{"2":{"60":1}}],["neurons=out",{"2":{"52":1}}],["neurons",{"2":{"52":3}}],["neural",{"2":{"15":1}}],["never",{"2":{"41":1,"51":3,"164":1}}],["need",{"2":{"30":4}}],["由内转外操作相同",{"2":{"159":1}}],["由编辑器根据情况自动设置",{"2":{"142":1}}],["由此可以证明其是一种十分有效的改进机制",{"2":{"48":1}}],["由多个子层组成",{"2":{"15":1}}],["由于增强是受",{"2":{"107":1}}],["由于想要看到",{"2":{"95":1}}],["由于进行测试的文件中涉及参考文献的引用",{"2":{"84":1}}],["由于在现代视觉transformer设计中通道维度",{"2":{"46":1}}],["由于分解后的1d卷积核大大减少了参数的数量",{"2":{"20":1}}],["由于biformer采用了稀疏注意力机制",{"2":{"9":1}}],["由于注意力在所有空间位置上计算令牌之间的关联性",{"2":{"4":1}}],["由于",{"2":{"2":1,"51":1}}],["右方向",{"2":{"131":1}}],["右图显示了acmix模块的流程",{"2":{"92":1}}],["右边为设置true情况",{"2":{"51":1}}],["右侧是2d",{"2":{"90":1}}],["右侧就会跳转到相应行",{"2":{"84":1}}],["右侧的表格详细列出了不同模型的分辨率",{"2":{"67":1}}],["右侧",{"2":{"15":1,"90":1}}],["右键菜单",{"2":{"164":1}}],["右键以管理员身份运行",{"2":{"2":1}}],["右键",{"2":{"2":1}}],["四",{"0":{"15":1,"26":1,"35":1,"55":1,"63":1,"72":1,"89":1,"103":1,"114":1,"115":1},"1":{"34":1,"43":1,"44":1,"53":1,"54":1,"64":1,"65":1,"66":1,"74":1,"75":1,"76":1,"77":1,"83":1,"85":1,"86":1,"94":1,"96":1,"97":1,"106":1,"109":1,"110":1,"116":1,"119":1,"122":1,"123":1,"125":1,"126":1,"127":1,"130":1,"133":1,"135":1,"137":1,"143":1,"145":1,"147":1,"152":1,"153":1,"160":1,"165":1,"169":1,"173":1}}],["也可以由多个段落组成",{"2":{"138":1}}],["也可以用在残差中也就是下面这个代码具体那种看你自己选择",{"2":{"61":1}}],["也是我实验跑出来的版本",{"2":{"99":1}}],["也融入了自注意力的全局信息聚合功能",{"2":{"92":1}}],["也就是我们的特征融合层",{"2":{"60":1}}],["也就是出现在工具栏中的链名称",{"2":{"51":1}}],["也就是上图所完成的功能",{"2":{"2":1}}],["也能够感知到更广泛区域的上下文信息",{"2":{"13":1}}],["模型的网络架构",{"2":{"90":1}}],["模型的训练过程时间比较长",{"2":{"82":1}}],["模型能够在不同的尺度上捕捉图像特征",{"2":{"13":1}}],["模仿我添加即可",{"2":{"64":1,"147":1}}],["模仿自我关注机制的感受野",{"2":{"57":1}}],["模块化设计",{"2":{"81":1}}],["模块的架构",{"2":{"68":1}}],["模块的主要改进机制包括以下几点",{"2":{"13":1}}],["模块中",{"2":{"25":1,"42":1}}],["模块相当的性能的同时",{"2":{"20":1}}],["模块",{"2":{"20":1,"56":1}}],["模块在视觉注意网络",{"2":{"20":1}}],["模块是为了利用自注意机制在不同尺度上的稀疏性",{"2":{"13":1}}],["红色框内的区域",{"2":{"13":1}}],["块的注意力图的可视化",{"2":{"13":1}}],["得到更丰富的特征表示",{"2":{"13":1}}],["52",{"2":{"148":3}}],["512",{"2":{"60":7,"86":7,"97":7,"99":7,"106":7,"119":7,"133":7,"143":7,"161":7,"165":7,"166":7,"169":7}}],["50",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["53",{"2":{"27":1,"65":1}}],["56x56",{"2":{"19":3}}],["5x5",{"2":{"13":1}}],["5",{"0":{"24":1,"42":1,"98":1,"99":1,"111":1,"112":1,"113":1,"124":1,"128":1,"134":1,"144":1,"146":1,"149":1,"154":1,"157":1,"161":1,"166":1,"170":1,"174":1,"180":1,"182":1},"1":{"134":1,"138":1,"144":1},"2":{"13":1,"19":5,"24":1,"27":18,"30":2,"45":10,"50":1,"52":1,"60":3,"61":2,"86":3,"89":3,"92":2,"97":3,"99":3,"101":4,"102":6,"106":3,"119":3,"133":3,"143":3,"161":3,"165":3,"166":3,"169":3}}],["头部通道分离",{"2":{"13":1}}],["头秃",{"2":{"0":1}}],["降低了计算的冗余",{"2":{"13":1}}],["稀疏性利用",{"2":{"13":1}}],["稀疏注意力",{"2":{"4":1}}],["多尺度特征提取",{"2":{"13":1}}],["多尺度扩张注意力",{"2":{"13":2}}],["多尺度空洞注意力",{"1":{"8":1,"13":1,"19":1,"26":1,"34":1,"43":1,"53":1,"64":1,"75":1,"86":1,"97":1,"110":1,"123":1},"2":{"8":1}}],["​​​​",{"2":{"173":1,"182":1}}],["​​​​​",{"2":{"130":1,"157":1}}],["​​",{"2":{"137":1,"147":1,"174":1}}],["​",{"2":{"13":2,"47":2,"53":1,"59":2,"64":1,"81":1,"92":1,"112":1,"123":2,"138":1,"152":1,"168":1,"171":1,"175":1,"178":1,"181":1,"183":1}}],["确定应用于图像的噪声量",{"2":{"163":1}}],["确定了关注的区域后",{"2":{"4":1}}],["确保特征的复用并加强不同层之间的信息流动",{"2":{"12":1}}],["特别是对于适合小数据集的模型",{"2":{"176":1}}],["特别是当处理大规模数据时",{"2":{"46":1}}],["特别是在医学图像中常见的不规则和可变形的器官",{"2":{"79":1}}],["特别是在rcs",{"2":{"42":1}}],["特别是在复杂背景或不同光照条件下",{"2":{"38":1}}],["特别是在urban100数据集上",{"2":{"28":1}}],["特别是公式比较多的数学专业",{"2":{"0":1}}],["特征金字塔",{"2":{"98":1,"146":1}}],["特征融合",{"2":{"81":1}}],["特征分解",{"2":{"81":1}}],["特征多样性",{"2":{"56":1}}],["特征图的通道首先被分割成不同的头部",{"2":{"13":1}}],["特征聚合",{"2":{"13":1}}],["特征级联的目的是为了减轻网络计算负担并降低内存占用",{"2":{"42":1}}],["特征级联",{"0":{"42":1},"2":{"12":1,"42":1}}],["48",{"2":{"148":6}}],["4gfops",{"2":{"133":1}}],["4gflops",{"2":{"48":1}}],["43691504",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["43691520",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["4371",{"2":{"45":1}}],["4040",{"2":{"45":1}}],["4488",{"2":{"45":1}}],["416",{"2":{"148":6}}],["416x416",{"2":{"148":3}}],["41",{"2":{"27":1,"65":1}}],["4",{"0":{"17":1,"33":1,"34":1,"43":1,"44":1,"53":1,"54":1,"64":1,"65":1,"74":1,"75":1,"76":1,"83":1,"85":1,"86":1,"90":1,"94":1,"96":1,"97":1,"106":1,"109":1,"110":1,"116":1,"117":1,"119":1,"122":1,"123":2,"125":1,"126":1,"127":1,"130":1,"133":1,"135":1,"137":1,"143":1,"145":1,"147":1,"152":1,"153":2,"160":1,"165":1,"169":1,"173":1,"174":1},"1":{"43":1,"53":1,"64":1,"65":1,"76":1,"85":1,"86":1,"96":1,"97":1,"106":1,"109":1,"119":1,"125":1,"127":1,"128":1,"130":1,"133":1,"135":1,"137":1,"138":1,"143":1,"145":1,"147":1,"152":1,"153":1,"165":1,"169":1,"173":1},"2":{"12":1,"13":1,"19":15,"23":1,"24":1,"27":2,"45":14,"60":2,"67":1,"68":1,"86":2,"97":2,"99":2,"102":1,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["完成中文环境配置",{"2":{"11":1}}],["等功能",{"2":{"73":1}}],["等待安装完成",{"2":{"11":1,"17":1}}],["等会儿会消失",{"2":{"2":1}}],["需要根据具体应用场景和数据类型选择适合的数据增强技术",{"2":{"120":1}}],["需要清除辅助文件了",{"2":{"51":1}}],["需要注意的是这里卷积核越大计算量就会变得越大",{"2":{"65":1}}],["需要注意的是本文的task",{"2":{"44":1,"113":1}}],["需要注意的是一个flagflops从8",{"2":{"29":1}}],["需要按照有参数的注意力机制添加",{"2":{"27":1}}],["需要在具体任务和数据集上进行适当的实验和调整",{"2":{"9":1}}],["需要进行适当的调整和优化",{"2":{"9":1}}],["需要进行路径的更改",{"2":{"2":1}}],["总之",{"2":{"105":1}}],["总体而言",{"2":{"9":1}}],["总结",{"2":{"4":1,"16":1,"20":1,"42":1,"46":1,"56":1,"69":1}}],["劣势",{"2":{"9":1}}],["提示内容",{"2":{"138":1}}],["提示",{"2":{"52":1,"138":2,"147":1}}],["提出的lska设计",{"2":{"20":1}}],["提出了一种创新的大型可分离核注意力",{"2":{"20":1}}],["提出了一种区域到区域的路由方法",{"2":{"4":1}}],["提出了一个通用的视觉transformer模型",{"2":{"4":1}}],["提高运算效率",{"2":{"92":1}}],["提高模型的性能",{"2":{"59":1,"70":1}}],["提高模型的语义信息提取能力",{"2":{"42":1}}],["提高模型对特征的理解能力",{"2":{"16":1}}],["提高重建图像的质量和精度",{"2":{"36":1}}],["提高效率",{"2":{"33":1}}],["提高特征表示的多样性",{"2":{"33":1}}],["提高了运算效率",{"2":{"70":1,"92":1}}],["提高了transformer架构的图像识别准确率",{"2":{"67":1}}],["提高了大概0",{"2":{"38":1}}],["提高了模型对目标形状和尺寸的适应性",{"2":{"38":1}}],["提高了模型的可重复性",{"2":{"107":1}}],["提高了模型的聚焦能力和特征表达的多样性",{"2":{"29":1,"56":1}}],["提高了模型的表达能力和性能",{"2":{"9":1}}],["提高了自注意力机制的效率和效果",{"2":{"13":1}}],["提高计算效率",{"2":{"12":1,"46":1}}],["避免了在最不相关的区域进行冗余计算",{"2":{"9":1}}],["只有带有",{"2":{"183":1}}],["只有与查询相关的键",{"2":{"9":1}}],["只保留了三个特征级联",{"2":{"42":1}}],["只是提醒该插件已经更新到了8",{"2":{"17":1}}],["只关注最相关的键",{"2":{"9":1}}],["只关注与查询相关的前k个窗口",{"2":{"9":1}}],["只进行适用于gpu的密集矩阵乘法运算",{"2":{"9":1}}],["只需将此变量设置为true即可恢复菜单",{"2":{"51":1}}],["只需要更改下图框选出的部分即可",{"2":{"2":1}}],["只需按照图片中所指向图标进行配置即可",{"2":{"0":1}}],["利用maxvit块作为编码器组件",{"2":{"90":1}}],["利用多分支结构学习丰富的特征表示",{"2":{"12":1}}],["利用稀疏性跳过最不相关区域的计算过程",{"2":{"9":1}}],["利用双层路由注意力作为基本构建模块",{"2":{"4":1}}],["上传你自己想要处理的数据集即可",{"2":{"179":1,"184":1}}],["上查看",{"2":{"151":1}}],["上面介绍了roboflow具有的数据增强功能有哪些",{"2":{"179":1}}],["上面代码串中记得进行",{"2":{"142":1}}],["上面的实验结果是用这个方法跑出来的",{"2":{"165":1}}],["上面的实验结果图三是用这个方法跑出来的",{"2":{"106":1}}],["上面的图片显示了多个视觉transformer模型的性能和计算复杂度的比较",{"2":{"67":1}}],["上面的图片是关于比较softmax注意力和线性注意力的差异",{"2":{"46":1}}],["上下颠倒",{"2":{"141":4}}],["上的",{"2":{"139":1}}],["上的性能对比",{"2":{"28":1}}],["上进行训练并即时进行增强时",{"2":{"107":1}}],["上进行数据增强",{"0":{"107":1}}],["上",{"2":{"84":1}}],["上部分支",{"2":{"31":1}}],["上图为变形大核注意力",{"2":{"68":1}}],["上图为大家展示了rcs的结构",{"2":{"25":1}}],["上图展示了3d和2d",{"2":{"90":1}}],["上图展示了大核注意力模块不同设计的比较",{"2":{"20":1}}],["上图展示了在不同大核分解方法和核大小下的速度",{"2":{"20":1}}],["上图展示了biformer的整体架构和一个biformer块的详细信息",{"2":{"15":1}}],["上图展示了通过收集前k个相关窗口中的键",{"2":{"9":1}}],["上层路由器通过全局自注意力机制对所有图像块进行交互",{"2":{"1":1}}],["上层路由器负责捕捉全局上下文信息",{"2":{"1":1}}],["优势",{"2":{"9":1}}],["三个分支的结果通过平均池化聚合起来生成最终的注意力权重",{"2":{"23":1}}],["三重注意力模型能够有效地捕获输入张量中的空间和通道维度之间的交互关系",{"2":{"16":1}}],["三重注意力由三个分支组成",{"2":{"16":1}}],["三重注意力",{"2":{"16":2}}],["三重注意力机制的主要思想是在网络中引入了一种新的注意力模块",{"2":{"5":1}}],["三",{"0":{"9":1,"19":1,"27":1,"40":1,"45":1,"52":1,"78":1,"101":1,"102":1},"1":{"50":1,"61":1},"2":{"92":1}}],["将适当的图像指定为空注释",{"2":{"181":1}}],["将随机的盐和胡椒噪声注入图像",{"2":{"172":1}}],["将synctex转发到外部查看器时要执行的命令",{"2":{"164":1}}],["将高斯噪声引入图像",{"2":{"163":1}}],["将具有",{"2":{"156":1}}],["将完整代码复制到自己的",{"2":{"151":1}}],["将缩放为",{"2":{"148":8}}],["将图像的伽玛曝光调整为更亮或更暗",{"2":{"168":1}}],["将图像拉伸到首选的逐像素尺寸",{"2":{"148":1}}],["将图像旋转",{"2":{"141":2}}],["将图像逆时针旋转",{"2":{"141":2}}],["将图像顺时针旋转",{"2":{"141":2}}],["将图像随机旋转",{"2":{"141":2}}],["将分解后的卷积和自注意力运算重构成一个统一的混合模块",{"2":{"92":1}}],["将标准的卷积核分解成多个1×1卷积核",{"2":{"92":1}}],["将之下载后",{"2":{"73":1}}],["将之添加到环境变量",{"2":{"2":1}}],["将自注意力和卷积技术融合",{"2":{"70":1}}],["将编译方式",{"2":{"51":1}}],["将在下文提及",{"2":{"51":1}}],["将下面的代码复制粘贴到",{"2":{"45":1}}],["将下面的代码在",{"2":{"27":1}}],["将lka的前两层分解为四层",{"2":{"20":1}}],["将特征图的通道分成n个不同的头部",{"2":{"8":1,"13":1}}],["算是国内计算机领域的最高期刊了",{"2":{"8":1}}],["发表于今年的中科院一区",{"2":{"8":1}}],["官方的代码中存在许多bug而且参数都未定义",{"2":{"102":1}}],["官方代码的地址",{"2":{"58":1}}],["官方代码地址点击即可跳转",{"2":{"13":1}}],["官方代码地址",{"2":{"7":1,"10":1,"20":1,"28":2,"37":1,"47":1,"59":2}}],["官方地址",{"2":{"58":1}}],["官方论文地址点击即可跳转",{"2":{"13":1}}],["官方论文地址",{"2":{"7":1,"10":1,"20":1,"28":2,"37":1,"47":1,"59":2}}],["官网下载",{"2":{"6":1,"108":1}}],["自适应均衡",{"2":{"162":1}}],["自动调整对比度",{"0":{"162":1},"2":{"129":1,"184":1}}],["自动定向会去除图像的",{"2":{"139":1}}],["自动定向",{"0":{"139":1},"2":{"129":1,"184":1}}],["自注意力",{"2":{"81":1,"92":1}}],["自注意力和acmix各自的结构和计算复杂度",{"2":{"81":1}}],["自注意力和卷积的整合通过以下方式实现",{"2":{"81":1}}],["自注意力和卷积的整合",{"0":{"81":1},"2":{"70":1}}],["自注意力机制的查询",{"2":{"81":1}}],["自注意力子层使用双层路由注意力机制",{"2":{"15":1}}],["自行选择",{"2":{"6":1}}],["自带的",{"2":{"2":1}}],["能添加的位置很多",{"2":{"110":1}}],["能否编译参考文献",{"2":{"73":1}}],["能否编译目录",{"2":{"73":1}}],["能否进行引用",{"2":{"73":1}}],["能否插入图片",{"2":{"73":1}}],["能够综合不同维度上的信息",{"2":{"31":1}}],["能够在拥有这些优势的同时",{"2":{"95":1}}],["能够在",{"2":{"51":1}}],["能够在你自己的网络结构中进行添加",{"2":{"29":1}}],["能够在不同的计算机视觉任务中发挥优异的性能",{"2":{"15":1}}],["能够有效降低内存占用和计算成本",{"2":{"20":1}}],["能够看到图片的立体效果一样",{"2":{"5":1}}],["能省很多麻烦",{"2":{"6":1}}],["根据变形点从采样特征中投影出变形的键和值",{"2":{"80":1}}],["根据",{"2":{"41":1}}],["根据查询自适应地关注最相关的键",{"2":{"15":1}}],["根据个人想法可以选择是否在开始菜单文件夹创建",{"2":{"6":1}}],["根据您的需要进行相应的更改",{"2":{"2":1}}],["点进去之后就可以进行下载了",{"2":{"6":1}}],["点击之后会弹出新的界面如下所示",{"2":{"179":1,"184":1}}],["点击编辑页面任意位置来选中",{"2":{"151":1}}],["点击选中",{"2":{"84":1}}],["点击下图",{"2":{"24":1}}],["点击设置",{"2":{"24":1}}],["点击设置图标",{"2":{"24":1}}],["点击页面右下角跳出窗口中的",{"2":{"11":1}}],["点击拓展图标",{"2":{"11":1,"17":1}}],["点击关闭即可",{"2":{"2":1}}],["点击",{"2":{"2":1,"11":1,"17":2}}],["点击红框圈画链接进行",{"2":{"2":1}}],["点击图示红框圈画位置进入随机的镜像网站",{"2":{"2":1}}],["h1>",{"2":{"138":1}}],["h1>hello",{"2":{"138":1}}],["home",{"2":{"138":1}}],["h2o",{"2":{"138":1}}],["hk",{"2":{"102":7}}],["hg",{"2":{"102":2}}],["h=num",{"2":{"89":1}}],["h=self",{"2":{"89":2,"102":1}}],["h=h",{"2":{"30":1,"89":1}}],["hw",{"2":{"50":2,"102":2}}],["hc",{"2":{"50":2}}],["hr",{"2":{"36":1}}],["half",{"2":{"92":3}}],["hasattr",{"2":{"52":2}}],["has",{"2":{"45":2}}],["happy",{"2":{"45":1}}],["hard",{"2":{"30":6}}],["hab利用通道注意力块",{"2":{"28":1}}],["hab",{"2":{"28":1,"45":2}}],["hattention的训练过程截图",{"0":{"112":1}}],["hattention的yaml文件一",{"0":{"99":1}}],["hattention的yaml文件",{"0":{"88":1},"1":{"99":1,"112":1}}],["hattention的核心代码",{"0":{"45":1}}],["hattention框架原理",{"0":{"28":1},"1":{"36":1}}],["hat显示了最强的像素利用和最高的psnr",{"2":{"36":1}}],["hat包括浅层特征提取",{"2":{"28":1}}],["hat的改进幅度介于0",{"2":{"28":1}}],["hat在psnr",{"2":{"28":1}}],["hat模型与其他最先进模型",{"2":{"28":1}}],["hat结合了通道注意力和自注意力",{"2":{"28":1}}],["hat利用这两种注意力机制",{"2":{"21":1,"36":1}}],["hat",{"0":{"36":1},"2":{"21":1,"28":5,"30":4,"36":2,"45":2,"77":1,"99":1}}],["hybrid",{"2":{"28":1,"45":4}}],["h是高度",{"2":{"23":1}}],["high",{"2":{"45":1}}],["hidden",{"2":{"19":30,"45":15,"61":2,"89":2,"101":2}}],["hi​进行连接后送入一个线性层进行特征聚合",{"2":{"13":1}}],["hello",{"2":{"73":1}}],["heiti",{"2":{"73":1}}],["height",{"2":{"45":2,"52":3}}],["head=4",{"2":{"92":1}}],["heads=",{"2":{"19":4,"45":1}}],["heads=num",{"2":{"19":6,"45":5}}],["heads=8",{"2":{"19":2,"30":1,"89":1,"102":1}}],["heads",{"2":{"19":23,"30":8,"45":38,"89":8,"102":16}}],["head",{"2":{"13":1,"19":17,"45":10,"60":4,"86":4,"89":1,"92":34,"97":4,"99":4,"102":10,"106":4,"119":4,"133":4,"143":4,"161":4,"165":4,"166":4,"169":4}}],["here",{"2":{"6":1,"30":1,"51":1,"73":1,"108":1}}],["h",{"2":{"13":1,"16":1,"19":27,"23":1,"27":7,"30":34,"45":50,"89":15,"92":28,"102":45}}],["http",{"2":{"2":1}}],["https",{"2":{"2":1,"4":1,"45":2,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["html",{"2":{"2":2}}],["就涨点了0",{"2":{"86":1,"161":1}}],["就要找失败原因了",{"2":{"84":1}}],["就需要进行多次不同命令的转换编译",{"2":{"51":1}}],["就像是得到了一副三维眼镜",{"2":{"5":1}}],["就好比三个人从不同的角度来观察同一幅画",{"2":{"5":1}}],["即噪声处理的内核大小",{"2":{"163":1}}],["即使在比大多数图像更暗或更亮的区域",{"2":{"162":1}}],["即使图像在磁盘上的存储方向不同也是如此",{"2":{"139":1}}],["即能够在多个层面上分析和识别图像特征",{"2":{"90":1}}],["即插即用",{"2":{"69":1}}],["即flatten模型",{"2":{"67":1}}],["即自注意力和卷积方式",{"2":{"59":1,"70":1}}],["即从",{"2":{"84":1}}],["即从代码定位到",{"2":{"84":1}}],["即从代码定位到编译出来的",{"2":{"51":1}}],["即从编译出的",{"2":{"51":1}}],["即此命令设置是否将编译文档的选项出现在鼠标右键的菜单中",{"2":{"51":1}}],["即变量设置为false",{"2":{"51":1}}],["即变为",{"2":{"41":1}}],["即需编写者手动编译文档",{"2":{"51":1}}],["即当检测到代码被更改时就自动编译tex文件",{"2":{"51":1}}],["即什么时候自动进行代码的编译",{"2":{"51":1}}],["即不改变输入",{"2":{"31":1}}],["即在不牺牲性能的情况下提高计算效率",{"2":{"25":1}}],["即可跳转新的界面如下所示",{"2":{"179":1,"184":1}}],["即可使用",{"2":{"151":1}}],["即可完成",{"2":{"41":1}}],["即可在yolov8模型中添加biformer注意力机制",{"2":{"22":1}}],["即可",{"2":{"17":1}}],["即色彩和纹理等特征",{"2":{"5":1}}],["即一次访问几十个连续字节的块",{"2":{"4":1}}],["值得注意的是",{"2":{"148":1}}],["值",{"2":{"81":1}}],["值标记来处理",{"2":{"4":1}}],["值对参与到密集矩阵乘法运算中",{"2":{"9":1}}],["值对进行全局的计算",{"2":{"9":1}}],["值对进行关注",{"2":{"4":1}}],["值对在空间上是分散的",{"2":{"4":1}}],["值对",{"2":{"4":2,"9":4,"15":1}}],["值对数量",{"2":{"4":1}}],["相关信息",{"2":{"138":1}}],["相关区域",{"2":{"4":1}}],["相对位置偏差也通过变形点计算",{"2":{"80":1}}],["相比于edsr",{"2":{"36":1}}],["相比之下",{"2":{"20":1}}],["相结合",{"2":{"33":1}}],["相反",{"2":{"4":1,"84":1}}],["因为具体的效果还要看你的数据集和实验环境所影响",{"2":{"78":1}}],["因为如果涉及到",{"2":{"51":1}}],["因为毕竟涉及到代码",{"2":{"51":1}}],["因为这些错误和警告信息能够从终端中获取",{"2":{"51":1}}],["因为它们比同等权重更好地代表人类对红色",{"2":{"156":1}}],["因为它可以通过新的",{"2":{"51":1}}],["因为它包含了一个区域级别的路由步骤和一个标记级别的注意力步骤",{"2":{"4":1}}],["因为资源有限我发的文章都要做对比实验所以本次实验我只用了一百张图片检测的是安全帽训练了一百个epoch",{"2":{"78":1}}],["因为资源有限",{"2":{"48":1}}],["因为专栏内容有许多",{"2":{"44":1,"83":1}}],["因为不同的yolov8模型版本可能目录结构不同",{"2":{"22":1}}],["因为现代gpu依赖于连续内存操作",{"2":{"4":1}}],["因为现在假设键",{"2":{"4":1}}],["因此需要根据问题进行合理的调整和选择",{"2":{"120":1}}],["因此租用的昂贵",{"2":{"107":1}}],["因此您应该收集更多低光训练数据",{"2":{"107":1}}],["因此",{"2":{"4":1,"162":1}}],["首先安装以上教程注册登录以后的界面如下所示",{"2":{"184":1}}],["首先登录roboflow如果大家不会可以看我的另一篇教程里面有从注册到导出你想要的数据格式文件的详细教程",{"2":{"184":1}}],["首先按照以上教程注册登录以后的界面如下所示",{"2":{"179":1}}],["首先需要登录roboflow如果大家不会可以看我的另一篇教程里面有从注册到导出你想要的数据格式文件的详细教程",{"2":{"179":1}}],["首先我们需要在文件的开头导入我们的acmix模块",{"2":{"137":1}}],["首先我们需要在文件的开头导入我们的rcs",{"2":{"96":1}}],["首先我们需要在文件的开头导入我们的msda模块",{"2":{"53":1}}],["首先我们找到如下的目录",{"2":{"43":1,"85":1,"127":1}}],["首先我们找到该目录",{"2":{"30":1}}],["首先使用全局平均池化和全局最大池化",{"2":{"23":1}}],["首先",{"2":{"4":1,"14":1,"20":1}}],["首先确定了前k个",{"2":{"4":1}}],["然而",{"2":{"4":1,"9":1}}],["然后我们按照步骤一和步骤二进行操作之后就可以进行添加数据增强操作了",{"2":{"179":1}}],["然后还有许多融合模块",{"2":{"110":1}}],["然后按ctrl+alt+v",{"2":{"84":1}}],["然后按下该快捷键",{"2":{"84":1}}],["然后进行图示操作",{"2":{"84":1}}],["然后进行残差变换",{"2":{"16":1}}],["然后根据不同的范式",{"2":{"59":1,"70":1}}],["然后在其内部导入我们的检测头如下图所示",{"2":{"135":1}}],["然后在其内部建立一个新的py文件将核心代码复制粘贴进去即可",{"2":{"125":1}}],["然后在步骤三这里定义的字典中添加你导入的注意力机制名字即可",{"2":{"49":1}}],["然后在这个目录下创建一个py文件",{"2":{"43":1,"85":1,"127":1}}],["然后将acmix添加进去即可",{"2":{"147":1}}],["然后将acmix的核心代码复制进去",{"2":{"127":1}}],["然后将rcs",{"2":{"85":1,"109":1}}],["然后将msda添加进去即可",{"2":{"64":1}}],["然后将msda的核心代码复制进去",{"2":{"43":1}}],["然后将三个分支的输出进行平均聚合",{"2":{"31":1}}],["然后同样通过sigmoid函数生成注意力权重",{"2":{"31":1}}],["然后是批量归一化和sigmoid函数",{"2":{"23":1}}],["然后使用layernorm和最终的1x1卷积",{"2":{"23":1}}],["然后使用另一个1d核进行垂直方向上的卷积",{"2":{"20":1}}],["然后通过一个卷积层",{"2":{"31":1}}],["然后通过1x1卷积和3x3卷积处理repvgg块的输出",{"2":{"25":1}}],["然后通过残差变换来提取特征",{"2":{"16":1}}],["然后通过z池操作和一个大小为k×k的卷积层",{"2":{"16":1}}],["然后应用于排列变换后的输入张量",{"2":{"16":1}}],["然后每个头部内部使用不同的扩张率",{"2":{"13":1}}],["然后",{"2":{"8":1,"13":1,"80":1}}],["然后共同决定哪些部分最值得注意",{"2":{"5":1}}],["然后对其进行修剪",{"2":{"4":1}}],["然后关注它们的并集",{"2":{"4":1}}],["然后输入命令xelatex",{"2":{"2":1}}],["然后手动选择某一镜像网站进行下载",{"2":{"2":1}}],["使注意力权重更加明显",{"2":{"56":1}}],["使其能够处理三维数据集",{"2":{"90":1}}],["使其在不同场景下更具鲁棒性",{"2":{"120":1}}],["使其在多种视觉任务中都能有效工作",{"2":{"69":1}}],["使其在处理复杂的视觉任务时更加高效和准确",{"2":{"69":1}}],["使其在处理不同深度的数据时表现出色",{"2":{"57":1}}],["使其在处理视觉任务时更加高效和有效",{"2":{"29":1,"56":1}}],["使其成为一个强大的视觉模型",{"2":{"9":1}}],["使用上次的recipe编译组合",{"2":{"164":1}}],["使用中心裁剪",{"2":{"148":1}}],["使用vscode内置pdf查看器或使用电脑默认浏览器进行pdf查看",{"2":{"142":1}}],["使用外部pdf查看器查看",{"2":{"142":1}}],["使用外部查看器时",{"2":{"164":1}}],["使用外部查看器时要执行的命令",{"2":{"142":1,"164":1}}],["使用外部查看器",{"2":{"142":1}}],["使用外部",{"2":{"142":1}}],["使用电脑默认浏览器进行",{"2":{"142":1}}],["使用此数据以特定方向显示图像",{"2":{"139":1}}],["使用sumatrapdf查看的代码配置",{"0":{"121":1},"1":{"132":1,"142":1}}],["使用方法看章节四",{"2":{"101":1}}],["使用内置查看器已无法满足需求",{"2":{"95":1}}],["使用1x1卷积实现",{"2":{"92":1}}],["使用快捷键",{"2":{"84":1}}],["使用右键菜单",{"2":{"84":1}}],["使用侧边工具栏",{"2":{"84":1}}],["使用大卷积核来捕捉图像的广泛上下文信息",{"2":{"57":1}}],["使用鼠标左键双击",{"2":{"51":1}}],["使用ctrl",{"2":{"51":1}}],["使用最近一次编译所用的编译链",{"2":{"51":1}}],["使用latex",{"2":{"51":1}}],["使用的是tex的标准字体",{"2":{"51":1}}],["使用的括号就比较多",{"2":{"0":1}}],["使用",{"2":{"51":1,"107":1,"142":1,"164":1}}],["使用了不同的标记来代表不同的核大小",{"2":{"20":1}}],["使得字体变大",{"2":{"95":1}}],["使得模型能够更好地适应不同的数据模式",{"2":{"57":1}}],["使得biformer在相同计算预算下能够实现更高的计算性能",{"2":{"9":1}}],["使得视觉transformer能够捕捉长距离依赖关系",{"2":{"4":1}}],["所有内核大小都是奇数",{"2":{"163":1}}],["所有图像的大小相同",{"2":{"129":1}}],["所提出的biformer在相似的模型大小下显著优于基准模型的性能",{"2":{"4":1}}],["所提出的方法通过双层路由实现了动态的",{"2":{"4":1}}],["所以大家可以在中等和小目标检测层都添加acmix模块进行尝试",{"2":{"161":1}}],["所以大家可以在中等和小目标检测层都添加msda模块进行尝试",{"2":{"86":1}}],["所以如果能够帮助到大家希望大家能给点个赞和关注支持一下",{"2":{"89":1}}],["所以我这里进行了挺多的改动的",{"2":{"89":1}}],["所以我下面推荐几个添加的位",{"2":{"98":1,"110":1,"146":1,"149":1,"170":1,"180":1}}],["所以我下面推荐了几种我自己认为可能有效果的配合方式",{"2":{"75":1,"155":1}}],["所以我下面的改进和这篇文章只用了rcs",{"2":{"52":1}}],["所以没啥效果",{"2":{"88":1}}],["所以希望大家给博主点点赞收藏以下",{"2":{"55":1}}],["所以生成pdf时",{"2":{"51":1}}],["所以在看第四章添加教程的时候需要按照无参数的注意力机制进行添加",{"2":{"50":1}}],["所以非常推荐大家使用",{"2":{"38":1}}],["所以效率并不高",{"2":{"4":1}}],["所以它具有transformer模型的特性",{"2":{"4":1}}],["本例中k=3",{"2":{"4":1}}],["本文的讲解主要包含三方面",{"2":{"48":1}}],["本文给大家带来的是yolov8改进dat",{"2":{"48":1}}],["本文给大家带来的改进内容是deformable",{"2":{"38":1}}],["本文给大家带来的改进机制是acmix自注意力机制的改进版本",{"2":{"59":1}}],["本文给大家带来的改进机制是focused",{"2":{"29":1}}],["本文给大家带来的改进机制是hattention注意力机制",{"2":{"21":1}}],["本文给大家带来的改进机制是msda",{"2":{"8":1}}],["本文给大家带来的改进机制是rcs",{"2":{"3":1}}],["本文给大家带来的改进是triplet",{"2":{"5":1}}],["本文还将提供代码实现细节和使用方法",{"2":{"14":1}}],["本文介绍",{"0":{"1":1,"3":1,"5":1,"8":1,"14":1,"21":1,"29":1,"38":1,"48":1,"59":1},"1":{"70":1,"81":1,"92":1}}],["本文使用图片均为笔者自身编辑器截图或笔者朋友的编辑器截图",{"2":{"0":1}}],["fpn",{"2":{"61":1,"89":1,"101":1}}],["fusevggforward",{"2":{"52":1}}],["fuse",{"2":{"52":4,"101":1}}],["function",{"2":{"89":3,"138":2}}],["functional",{"2":{"30":1,"52":2,"89":1,"102":1}}],["functools",{"2":{"19":1}}],["ffn",{"2":{"45":1}}],["fdb",{"2":{"41":1,"51":1,"164":1}}],["fla",{"2":{"89":5}}],["flattention",{"2":{"113":2}}],["flatten",{"2":{"19":2,"30":2,"45":11}}],["flops",{"2":{"67":2}}],["floor",{"2":{"45":1}}],["float16",{"2":{"89":3}}],["float32",{"2":{"52":1}}],["float",{"2":{"45":28,"89":3,"92":1,"102":4}}],["fls",{"2":{"41":1,"51":1,"164":1}}],["faster",{"2":{"61":1,"89":1,"101":1}}],["factor=",{"2":{"102":1}}],["factor=3",{"2":{"89":1}}],["factor=30",{"2":{"45":3}}],["factor=squeeze",{"2":{"45":4}}],["factor=16",{"2":{"45":1}}],["factor",{"2":{"30":1,"45":13,"89":6,"102":5}}],["false",{"2":{"19":3,"41":2,"45":5,"51":2,"89":1,"102":1,"164":2}}],["frac",{"2":{"138":4}}],["fracpool",{"2":{"30":3}}],["free",{"2":{"30":2}}],["from",{"2":{"19":4,"30":3,"39":1,"45":7,"52":1,"60":1,"86":1,"89":1,"97":1,"99":1,"102":2,"106":1,"113":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["fixed",{"2":{"102":5}}],["fixme",{"2":{"19":1,"30":1}}],["field",{"2":{"68":1}}],["first",{"2":{"45":2,"51":1}}],["fill",{"2":{"45":2,"92":2,"102":1}}],["filetypes",{"2":{"41":1,"51":1,"164":1}}],["file",{"2":{"41":3,"51":3,"164":3}}],["filtering",{"2":{"30":1}}],["foo",{"2":{"138":2}}],["focuslinearattention",{"2":{"113":1}}],["focusing",{"2":{"89":7}}],["focusedlinearattention",{"2":{"89":2,"113":1}}],["focusedlinearattention代码",{"0":{"89":1}}],["focused",{"0":{"37":1,"56":1,"113":1,"124":1,"134":1,"144":1},"1":{"46":1,"56":1,"67":1,"134":1,"144":1},"2":{"29":2,"56":5}}],["forward",{"2":{"15":1,"19":13,"27":1,"30":4,"45":15,"50":4,"52":4,"61":6,"89":7,"92":1,"101":11,"102":2,"132":1,"142":1,"164":1}}],["for",{"2":{"8":1,"11":1,"19":11,"30":8,"45":19,"51":1,"52":3,"60":1,"61":3,"73":2,"86":1,"89":4,"92":1,"97":1,"99":1,"101":5,"102":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["fc",{"2":{"92":2}}],["fc2",{"2":{"19":2,"45":2}}],["fc1",{"2":{"19":2,"45":2}}],["feat=dim",{"2":{"45":1}}],["feat",{"2":{"45":22}}],["feature",{"2":{"30":1,"42":1,"45":6,"89":4}}],["features=in",{"2":{"52":1}}],["features=out",{"2":{"52":1}}],["features=mlp",{"2":{"19":2,"45":2}}],["features=dim",{"2":{"19":2,"45":2}}],["features=none",{"2":{"19":2,"45":2}}],["features",{"2":{"19":16,"45":18}}],["feed",{"2":{"15":1}}],["f",{"2":{"4":1,"19":2,"30":4,"44":1,"45":2,"52":3,"77":1,"89":1,"92":4,"102":6,"113":1,"132":4,"142":4,"147":2,"164":4}}],["f分别是",{"2":{"4":1}}],["einsum",{"2":{"89":5,"102":2}}],["einops",{"2":{"30":1,"45":1,"89":1,"102":6}}],["efficient",{"2":{"67":1}}],["e=1",{"2":{"61":1,"89":1,"101":1}}],["e=0",{"2":{"52":1,"61":2,"89":2,"101":2}}],["eps",{"2":{"52":5}}],["eps=1e",{"2":{"19":2,"50":1}}],["equivalent",{"2":{"52":1}}],["each",{"2":{"45":1}}],["encoding",{"2":{"89":3,"92":1}}],["end",{"2":{"45":2,"52":1,"73":2}}],["enabled",{"2":{"41":1,"51":1,"164":1}}],["even",{"2":{"45":1}}],["error",{"2":{"41":4,"51":4,"164":4}}],["emb",{"2":{"30":3}}],["embedding",{"2":{"19":3,"45":10}}],["embed",{"2":{"19":23,"45":34}}],["exif数据确定给定图像的方向",{"2":{"139":1}}],["exif",{"2":{"139":1}}],["exist",{"2":{"19":2}}],["exe文件所在位置",{"2":{"142":1}}],["exe",{"2":{"132":2,"142":3,"164":2}}],["expansion",{"2":{"61":2,"89":2,"101":2}}],["expanding",{"2":{"90":1}}],["expand",{"2":{"30":2,"102":4}}],["examples",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["external",{"2":{"132":5,"142":10,"164":7}}],["extend",{"2":{"61":2,"89":2,"101":2}}],["ext",{"2":{"45":10}}],["extraction",{"2":{"45":3}}],["extra",{"2":{"30":1}}],["excitation",{"2":{"23":1}}],["elif",{"2":{"19":4,"27":5,"30":9,"44":1,"45":4,"77":1,"102":4,"113":1,"147":1}}],["else",{"2":{"19":10,"30":10,"45":12,"50":3,"52":7,"61":1,"89":3,"92":2,"101":5,"102":6}}],["e",{"2":{"4":1,"30":1,"52":1,"60":1,"61":2,"86":1,"89":2,"97":1,"99":1,"101":2,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["减少网络计算负担",{"2":{"12":1}}],["减少内存消耗",{"2":{"12":1}}],["减少了重复的计算量",{"2":{"81":1}}],["减少了计算复杂性和内存占用",{"2":{"14":1}}],["减少了计算量和内存占用",{"2":{"9":1}}],["减少了考虑的键",{"2":{"4":1}}],["减少通道的空间对象注意力",{"2":{"3":1}}],["d=1",{"2":{"101":2}}],["dlka",{"2":{"101":4,"165":3}}],["dat可以是一种即插即用的注意力机制",{"2":{"146":1}}],["dat可添加的位置",{"0":{"136":1},"1":{"146":1,"154":1}}],["dattentionbaseline",{"2":{"102":1}}],["dattention的代码复现",{"2":{"48":1}}],["dat即插即用的代码块",{"0":{"102":1}}],["dat与其他视觉transformer模型和cnn模型中的dcn",{"2":{"91":1}}],["dat和其他机制的对比",{"0":{"91":1}}],["date",{"2":{"73":1}}],["dat通过引入可变形注意力机制",{"2":{"69":1}}],["dat动态地选择采样点",{"2":{"69":1}}],["dat的yaml文件和训练过程",{"0":{"126":1}}],["dat的网络结构图",{"0":{"80":1}}],["dat的网络结构思想",{"0":{"58":1},"1":{"69":1,"80":1,"91":1},"2":{"48":1}}],["dat的设计允许它适应不同的图像大小和内容",{"2":{"69":1}}],["dat的核心思想主要包括以下几个方面",{"2":{"69":1}}],["dat的主要思想和改进",{"0":{"69":1}}],["dat论文地址",{"2":{"58":1}}],["data=kernel",{"2":{"92":1}}],["data",{"2":{"52":1,"61":1,"67":1,"89":1,"92":2,"101":2}}],["dat",{"1":{"48":1,"58":1,"69":1,"80":1,"91":1,"102":1,"115":1,"126":1,"136":1,"146":1,"154":1},"2":{"67":1,"69":1}}],["dtype=dtype",{"2":{"102":4}}],["dtype=np",{"2":{"52":1}}],["dtype=x",{"2":{"45":1}}],["dtype",{"2":{"45":1,"89":3,"92":1,"102":7}}],["ddp",{"2":{"30":1}}],["d代表扩张率​​",{"2":{"20":1}}],["dwc",{"2":{"56":1,"89":2,"102":6}}],["dwconv",{"2":{"30":5}}],["dwconv=3",{"2":{"30":1}}],["dw",{"2":{"20":3,"68":1}}],["dpr",{"2":{"19":1,"45":1}}],["demo",{"2":{"138":1}}],["deit",{"2":{"67":1}}],["dense",{"2":{"52":4}}],["denoising",{"2":{"45":1}}],["deep",{"2":{"45":2,"138":3}}],["device=device",{"2":{"89":1,"102":5}}],["device=x",{"2":{"45":1}}],["device",{"2":{"45":2,"52":1,"89":2,"102":7}}],["detect",{"2":{"60":3,"86":3,"97":3,"99":3,"106":3,"119":3,"133":3,"143":3,"161":3,"165":3,"166":3,"169":3}}],["detection",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["detecthead",{"2":{"44":1,"83":1}}],["details",{"2":{"51":1}}],["detach",{"2":{"30":3}}],["detr的模型上看看效果",{"2":{"46":1}}],["dep",{"2":{"92":5}}],["deploy",{"2":{"52":3}}],["deploy=false",{"2":{"52":1}}],["dependent",{"2":{"30":2}}],["depth=depth",{"2":{"45":1}}],["depth=depths",{"2":{"19":2,"45":1}}],["depths",{"2":{"19":6,"45":5}}],["depths=",{"2":{"19":4,"45":1}}],["depth",{"2":{"19":4,"45":16,"60":1,"68":2,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["decay",{"2":{"19":1,"45":3}}],["deformconv2d",{"2":{"101":1}}],["deformconv",{"2":{"101":4}}],["deform",{"2":{"68":1,"101":2}}],["deformable",{"0":{"47":1,"57":1},"1":{"57":1,"68":1,"79":1,"90":1},"2":{"38":3,"48":1,"57":1,"67":1,"68":2,"69":2,"79":1,"90":1,"101":6,"169":3}}],["define",{"2":{"45":2}}],["default",{"2":{"19":3,"41":1,"45":55,"51":1,"71":1,"101":3,"164":1}}],["def",{"2":{"19":28,"27":2,"30":8,"45":37,"50":7,"52":15,"61":5,"89":7,"92":7,"101":15,"102":6}}],["document",{"2":{"73":2,"138":1}}],["documentclass",{"2":{"73":1}}],["docs",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["doc表明编译器访问的是没有扩展名的根文件完整路径",{"2":{"51":1}}],["doc",{"2":{"51":1}}],["docfile仅是因为之前使用",{"2":{"51":1}}],["docfile可以将文件所在路径设置为中文",{"2":{"51":1}}],["docfile表明编译器访问没有扩展名的根文件名",{"2":{"51":1}}],["docfile更改为",{"2":{"51":1}}],["docfile",{"2":{"41":4,"51":4,"164":4}}],["don",{"2":{"45":1}}],["double",{"2":{"41":3,"51":2,"164":1}}],["do",{"2":{"30":2}}],["downsaple",{"2":{"30":1}}],["downsampling",{"2":{"30":1}}],["downsample=downsample",{"2":{"45":1}}],["downsample=downsamples",{"2":{"19":2}}],["downsample=none",{"2":{"45":3}}],["downsample=true",{"2":{"19":2}}],["downsamples=",{"2":{"19":1}}],["downsample",{"2":{"19":6,"30":26,"45":10}}],["down",{"2":{"30":7,"52":2}}],["download",{"2":{"6":1,"73":1,"108":1}}],["doesn",{"2":{"19":1}}],["drop=drop",{"2":{"19":6,"45":5}}],["drop=attn",{"2":{"19":6,"45":4}}],["drop=0",{"2":{"19":16,"45":9,"89":2,"102":2}}],["dropout",{"2":{"19":5,"45":14,"89":2,"102":2}}],["drop",{"2":{"19":47,"45":60,"89":5,"102":6}}],["droppath",{"2":{"19":3,"45":3}}],["displacement",{"2":{"102":6}}],["disable",{"2":{"17":1}}],["divided",{"2":{"89":1}}],["divisor",{"2":{"52":7}}],["divisible",{"2":{"30":1,"52":3}}],["div",{"2":{"45":1,"102":4}}],["di",{"2":{"36":1}}],["different",{"2":{"45":1}}],["differentiable",{"2":{"30":6}}],["diffrentiable",{"2":{"30":1}}],["diff",{"2":{"30":14,"45":1}}],["dims=",{"2":{"45":2}}],["dimension",{"2":{"30":1,"45":1}}],["dim=1",{"2":{"45":1,"50":1,"52":2,"89":1,"92":1}}],["dim=16",{"2":{"19":1}}],["dim=self",{"2":{"30":1}}],["dim=none",{"2":{"30":1}}],["dim=2",{"2":{"30":1,"102":1}}],["dim=72",{"2":{"19":2}}],["dim=int",{"2":{"19":2}}],["dim=embed",{"2":{"19":1,"45":3}}],["dim=dim",{"2":{"19":2,"45":6}}],["dim=96",{"2":{"19":3,"45":3}}],["dim=",{"2":{"19":2,"30":9,"45":2,"89":4}}],["dim",{"2":{"19":82,"27":51,"30":47,"45":93,"52":3,"89":23,"92":18,"101":5,"102":2}}],["dilation=d",{"2":{"101":1}}],["dilation=dilation",{"2":{"19":3,"50":1,"52":1,"101":2}}],["dilation=3",{"2":{"27":8,"101":1}}],["dilation=2",{"2":{"27":4}}],["dilation=",{"2":{"19":3}}],["dilation=1",{"2":{"19":1,"50":1,"52":1,"92":1,"101":1}}],["dilation",{"2":{"13":1,"19":24,"92":3,"101":2}}],["dilatestage",{"2":{"19":2}}],["dilateblock",{"2":{"19":2}}],["dilate",{"2":{"19":8}}],["dilateattention",{"2":{"19":2}}],["dilated",{"2":{"8":1,"68":1}}],["dilateformer",{"2":{"8":1,"19":8}}],["d",{"0":{"101":2,"130":1,"160":1,"165":1,"169":1,"173":1,"177":1},"1":{"165":1,"169":1,"173":1,"180":1,"182":1},"2":{"4":1,"19":8,"20":1,"45":7,"46":2,"57":4,"68":1,"89":9,"90":10,"101":10,"102":2,"165":1,"180":2}}],["browser",{"2":{"142":1}}],["branch",{"2":{"52":16}}],["bn",{"2":{"50":4,"52":13,"101":2}}],["bn=true",{"2":{"50":1}}],["buffer",{"2":{"45":2}}],["build",{"2":{"19":2,"45":3,"52":1}}],["bbl",{"2":{"41":1,"51":1,"164":1}}],["bmlc",{"2":{"30":3}}],["borrowed",{"2":{"102":1}}],["body",{"2":{"45":3}}],["bottleneck",{"2":{"44":1,"61":6,"83":1,"89":6,"101":6}}],["both",{"2":{"30":2,"45":1}}],["bool",{"2":{"30":3,"45":11,"89":3}}],["by",{"2":{"30":4,"52":1,"89":1}}],["b部分",{"2":{"25":1}}],["blob",{"2":{"45":2}}],["block=true",{"2":{"19":1}}],["block=cpe",{"2":{"19":4}}],["block=false",{"2":{"19":4}}],["blocks",{"2":{"19":6,"45":8}}],["block",{"2":{"19":13,"23":1,"45":6,"52":3}}],["blg",{"2":{"41":1,"51":1,"164":1}}],["blk",{"2":{"19":4,"45":2}}],["badge",{"2":{"138":1}}],["backbone",{"2":{"60":4,"86":4,"97":4,"99":4,"106":4,"110":1,"119":4,"133":4,"143":4,"161":4,"165":4,"166":4,"169":4,"170":1}}],["batch",{"2":{"101":1}}],["batchsize",{"2":{"52":3}}],["batchnorm2d",{"2":{"19":7,"50":1,"52":3,"101":1}}],["base",{"2":{"19":1}}],["based",{"2":{"12":1,"42":1,"45":2}}],["basicconv",{"2":{"50":3}}],["basicsr",{"2":{"45":2}}],["basic",{"2":{"19":2}}],["begin",{"2":{"73":2}}],["beta",{"2":{"52":3}}],["before",{"2":{"30":1,"45":4}}],["be",{"2":{"19":1,"30":3,"45":1,"89":1}}],["bilinear",{"2":{"102":2}}],["bilevelroutingattention",{"2":{"30":2,"39":1,"60":3}}],["bib的编译",{"2":{"84":1}}],["bib",{"2":{"51":1}}],["bibtex",{"2":{"41":8,"51":8,"84":1,"164":8}}],["binarize",{"2":{"45":1}}],["biasid",{"2":{"52":2}}],["bias1x1",{"2":{"52":2}}],["bias3x3",{"2":{"52":2}}],["bias",{"2":{"19":11,"45":38,"52":3,"89":2,"92":2,"102":14}}],["bias=bias",{"2":{"30":1,"50":1}}],["bias=false",{"2":{"19":11,"45":1,"50":1,"52":1,"92":1,"101":2,"102":2}}],["bias=qkv",{"2":{"19":8,"45":7,"89":2}}],["bias=true",{"2":{"19":4,"30":1,"45":6,"52":3,"89":1,"92":1,"101":2,"102":1}}],["bi",{"2":{"4":1,"30":1}}],["biformer能够有效地利用双层路由注意力机制",{"2":{"15":1}}],["biformer能够同时捕捉全局和局部的特征信息",{"2":{"1":1}}],["biformer块是biformer的基本构建单元",{"2":{"15":1}}],["biformer块的详细信息",{"2":{"15":1}}],["biformer通过引入双层路由注意力机制",{"2":{"15":1}}],["biformer利用双层路由注意力机制",{"2":{"9":1}}],["biformer注意力机制的优势和劣势如下",{"2":{"9":1}}],["biformer的整体架构",{"2":{"15":1}}],["biformer的结构",{"0":{"15":1}}],["biformer的注意力机制具有高效的计算性能和查询感知的自适应性",{"2":{"9":1}}],["biformer的双层路由注意力机制引入了额外的参数和超参数",{"2":{"9":1}}],["biformer的双层路由注意力机制允许模型根据每个查询自适应地关注最相关的键",{"2":{"9":1}}],["biformer的优劣势",{"0":{"9":1}}],["biformer的作用机制",{"0":{"4":1}}],["biformer论文地址csdn",{"2":{"4":1}}],["biformer模型的核心思想是引入了双层路由注意力机制",{"2":{"1":1}}],["biformer是一种结合了bi",{"2":{"1":1}}],["biformer",{"1":{"1":1,"4":1,"9":1,"15":1,"22":1,"30":1,"39":1,"49":1,"60":1,"71":1,"82":1},"2":{"4":1,"39":1}}],["b",{"2":{"4":1,"16":1,"19":27,"30":3,"45":57,"80":1,"81":1,"84":2,"89":34,"92":17,"102":51,"138":21,"156":1}}],["从使用的包中自动补全命令和环境",{"2":{"164":1}}],["从下面官方获取的图片上来看yolov8官方指定的数据集获取网站就是roboflow",{"2":{"105":1}}],["从不自动编译",{"2":{"51":1}}],["从上文整个代码块儿可以看出此规则",{"2":{"41":1}}],["从一个1x1卷积层开始",{"2":{"23":1}}],["从图中可以看出",{"2":{"20":1,"68":1}}],["从a",{"2":{"4":1}}],["从而允许卷积核动态地适应图像的内容",{"2":{"79":1}}],["从而在保持较低计算成本的同时",{"2":{"59":1,"70":1}}],["从而在各种视觉任务中提高性能",{"2":{"23":1}}],["从而补全正在编写的代码",{"2":{"51":1}}],["从而将复杂度降低到",{"2":{"46":1}}],["从而将之配置为高度个性化的编辑器",{"2":{"0":1}}],["从而可以对",{"2":{"41":1}}],["从而克服了densenet中密集连接的低效率问题",{"2":{"33":1}}],["从而直接完成相应设置",{"2":{"24":1}}],["从而提供更为精确的上采样结果",{"2":{"36":1}}],["从而提供更为精确的结果",{"2":{"21":1}}],["从而提高检测的效率",{"2":{"80":1}}],["从而提高对图像内容的整体理解",{"2":{"13":1}}],["从而提高了网络的计算和能源效率",{"2":{"33":1}}],["从而提高了计算性能和任务表现",{"2":{"15":1}}],["从而提高了计算效率",{"2":{"9":1}}],["从而提高了模型在视觉任务中的性能",{"2":{"1":1}}],["从而计算注意力权重",{"2":{"16":1}}],["从而能更加全面地捕捉图像中的信息",{"2":{"13":1}}],["从而实现了与原始大尺寸2d核相似的效果",{"2":{"20":1}}],["从而实现稀疏性",{"2":{"9":1}}],["从而实现这一点",{"2":{"4":1}}],["从而实现高效的计算",{"2":{"4":1}}],["二",{"0":{"4":1,"7":1,"10":1,"13":1,"20":1,"28":1,"37":1,"47":1,"58":1},"1":{"12":1,"16":1,"18":1,"23":1,"25":1,"31":1,"33":1,"36":1,"42":1,"46":1,"56":1,"57":1,"67":1,"68":1,"69":1,"79":1,"80":1,"90":1,"91":1},"2":{"59":1}}],["mvitv2",{"2":{"67":1}}],["mobilenet",{"2":{"92":2}}],["momentum=0",{"2":{"50":1}}],["more",{"2":{"45":1,"51":1}}],["mode",{"2":{"30":12,"52":1}}],["mode=padding",{"2":{"52":1}}],["mode=",{"2":{"30":2,"52":1,"89":1,"102":2}}],["model里添加即可",{"2":{"153":1}}],["model这个方法",{"2":{"64":1,"109":1,"147":1}}],["model=yolov8n",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["model",{"2":{"19":14,"49":1,"60":2,"86":2,"92":1,"97":2,"99":2,"101":8,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["models",{"2":{"19":3,"45":4,"60":1,"102":1}}],["modulelist",{"2":{"19":4,"45":2,"61":1,"89":1,"101":1}}],["module",{"2":{"19":11,"23":3,"27":1,"30":4,"45":26,"50":4,"52":6,"60":1,"61":3,"86":1,"89":4,"92":1,"97":1,"99":1,"101":8,"102":2,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["modules文件夹下建立一个目录名字呢就是",{"2":{"125":1}}],["modules",{"2":{"19":1,"27":1,"30":2,"39":1,"43":1,"45":1,"66":1,"85":1,"113":1,"127":1}}],["m=self",{"2":{"30":3}}],["msa",{"2":{"28":1,"45":5}}],["msda是一种即插即用的可替换卷积的模块",{"2":{"110":1}}],["msda添加步骤",{"0":{"34":1},"1":{"43":1,"53":1,"64":1}}],["msda核心代码",{"0":{"19":1}}],["msda不仅可以捕捉局部细节",{"2":{"13":1}}],["msda的训练过程截图",{"0":{"123":1}}],["msda的yaml版本二",{"0":{"97":1}}],["msda的yaml版本一",{"0":{"86":1}}],["msda的yaml文件和训练截图",{"0":{"75":1},"1":{"86":1,"97":1}}],["msda的输出通过连接操作合并",{"2":{"13":1}}],["msda的主要思想是通过线性投影得到特征图x的相应查询",{"2":{"8":1}}],["msda将特征图的通道分离成多个头部",{"2":{"13":1}}],["msda利用了自注意力机制在不同尺度的稀疏性",{"2":{"13":1}}],["msda能够在各个头部关注不同尺度的特征",{"2":{"13":1}}],["msda能够在被关注的接受域内有效地聚合不同尺度的语义信息",{"2":{"13":1}}],["msda能够捕捉到多尺度的语义信息",{"2":{"13":1}}],["msda被公式化如下",{"2":{"13":1}}],["msda通过线性投影得到特征图x的相应查询",{"2":{"13":1}}],["msda",{"2":{"13":3}}],["msda框架原理",{"0":{"13":1}}],["m",{"2":{"19":11,"30":20,"44":1,"45":15,"52":2,"60":1,"61":7,"77":1,"86":1,"89":7,"97":1,"99":1,"101":7,"102":8,"106":1,"113":1,"119":1,"133":1,"143":1,"147":1,"161":1,"165":1,"166":1,"169":1}}],["medium",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["meshgrid",{"2":{"45":3,"102":2}}],["message",{"2":{"17":1,"41":2,"51":2,"164":2}}],["merge",{"2":{"45":3}}],["merging",{"2":{"19":16,"45":2}}],["mean",{"2":{"30":2,"45":8,"50":1,"52":5}}],["mem",{"2":{"30":1}}],["memory",{"2":{"30":2,"45":3}}],["mac",{"2":{"139":1}}],["markdown",{"1":{"93":1,"104":1,"117":1,"128":1,"138":1}}],["margin=1in",{"2":{"73":1}}],["max",{"2":{"50":1,"52":1,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["maxpool2d",{"2":{"30":1}}],["maxpool",{"2":{"30":2}}],["master",{"2":{"45":2}}],["masked",{"2":{"45":2}}],["mask=attn",{"2":{"45":1}}],["mask=none",{"2":{"45":1}}],["mask=false",{"2":{"30":1}}],["mask",{"2":{"30":1,"45":32}}],["math",{"2":{"45":2,"52":2}}],["match",{"2":{"19":1}}],["map",{"2":{"89":4}}],["mapping",{"2":{"30":1}}],["map直接涨了大概有0",{"2":{"3":1,"8":1}}],["maketitle",{"2":{"73":1}}],["make",{"2":{"30":2,"45":1,"52":2}}],["main",{"2":{"19":1,"45":2,"52":1,"92":1,"101":1,"138":1}}],["much",{"2":{"30":1}}],["mul",{"2":{"30":10,"102":9}}],["multihead",{"2":{"30":1}}],["multiple",{"2":{"45":1}}],["multiplied",{"2":{"30":1}}],["multiply",{"2":{"30":2}}],["multidilatelocalattention",{"2":{"19":2,"86":1,"97":3}}],["multi",{"2":{"8":1,"13":1,"45":1}}],["must",{"2":{"19":1,"30":1,"45":1}}],["mlp",{"2":{"19":26,"45":33}}],["mhsa",{"2":{"13":1}}],["microsoft",{"2":{"132":1,"142":2,"164":1}}],["min",{"2":{"45":2}}],["mirror",{"2":{"2":2}}],["miktex",{"2":{"2":1}}],["亲测在小目标检测和大尺度目标检测的数据集上都有大幅度的涨点效果",{"2":{"3":1,"8":1}}],["来提高模型的处理效率和检测精度",{"2":{"3":1}}],["意即",{"2":{"3":1}}],["obj",{"2":{"138":1}}],["object",{"2":{"3":1,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["omega^i",{"2":{"138":1}}],["omega^r",{"2":{"138":1}}],["omega",{"2":{"138":4}}],["ops",{"2":{"101":1}}],["option",{"2":{"61":1,"89":1,"101":1}}],["optional",{"2":{"30":1,"45":28,"61":1,"89":1,"101":1}}],["ours",{"2":{"67":1}}],["out21",{"2":{"50":3}}],["out2",{"2":{"50":2}}],["out11",{"2":{"50":3}}],["out1",{"2":{"50":2}}],["outdir",{"2":{"41":1,"51":1,"164":1}}],["outdir=",{"2":{"41":1,"51":1,"164":1}}],["outputs",{"2":{"60":1,"86":1,"97":1,"99":1,"101":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["output",{"2":{"30":2,"45":5,"61":1,"89":1,"101":1}}],["out",{"2":{"19":15,"30":11,"41":1,"45":6,"50":12,"51":1,"52":17,"61":1,"89":2,"92":38,"101":6,"102":8,"132":1,"142":1,"164":2}}],["oca",{"2":{"45":9}}],["ocab进一步增强了不同窗口间特征的交互",{"2":{"28":1}}],["ocab",{"2":{"28":1,"45":3}}],["ow",{"2":{"45":4}}],["oww=self",{"2":{"45":1}}],["oww",{"2":{"45":2}}],["owh=self",{"2":{"45":1}}],["owh",{"2":{"45":2}}],["overlap",{"2":{"45":23}}],["overlapping",{"2":{"45":3}}],["overlaping",{"2":{"19":3}}],["override",{"2":{"45":5}}],["o",{"2":{"30":1,"46":2}}],["off",{"2":{"102":10}}],["off=false",{"2":{"102":1}}],["offset",{"2":{"101":2,"102":22}}],["offsets",{"2":{"68":1,"101":2}}],["of",{"2":{"19":6,"30":5,"33":1,"45":47,"60":1,"61":2,"86":1,"89":2,"97":1,"99":1,"101":3,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["original",{"2":{"45":1}}],["ori",{"2":{"45":10}}],["or",{"2":{"19":6,"30":5,"45":7}}],["org",{"2":{"2":1}}],["onbuilt",{"2":{"51":1}}],["onsave",{"2":{"51":1}}],["onfilechange",{"2":{"51":1}}],["onfailed",{"2":{"41":1,"51":2,"164":1}}],["only",{"2":{"30":1}}],["on",{"2":{"12":1,"45":3,"142":1,"164":1}}],["one",{"2":{"12":2,"19":2,"30":1,"33":2,"42":2,"45":1}}],["osa添加进去即可",{"2":{"109":1}}],["osa添加步骤",{"0":{"74":1},"1":{"85":1,"96":1,"109":1}}],["osa的训练截图",{"2":{"152":1}}],["osa的训练过程截图",{"0":{"152":1}}],["osa的位置",{"2":{"133":1}}],["osa的yaml版本二",{"0":{"143":1}}],["osa的yaml版本一",{"0":{"133":1}}],["osa的yaml文件和训练截图",{"0":{"122":1},"1":{"133":1,"143":1,"152":1}}],["osa的核心代码复制进去",{"2":{"85":1}}],["osa的基本原理",{"0":{"12":1}}],["osa核心代码",{"0":{"52":1}}],["osa在模型中用于堆叠rcs模块",{"2":{"42":1}}],["osa减少了重复的特征计算和存储需求",{"2":{"33":1}}],["osa通过聚合具有不同感受野的特征来增加网络对于不同尺度的敏感性",{"2":{"33":1}}],["osa模块来替换c2f",{"2":{"52":1}}],["osa模块来替换我们yolov8中的c2f模块",{"2":{"52":1}}],["osa模块中",{"2":{"33":1}}],["osa模块被进一步与rcs",{"2":{"33":1}}],["osa模块的排列和组合反映了它们如何一起工作以优化特征传递和提高检测性能",{"2":{"42":1}}],["osa模块的使用有两个主要目的",{"2":{"33":1}}],["osa模块的框架原理进行了详细的分析",{"2":{"3":1}}],["osa模块通过表示具有多个感受野的多样化特征",{"2":{"33":1}}],["osa模块通过堆叠rcs",{"2":{"12":1}}],["osa模块原理",{"0":{"7":1},"1":{"12":1,"18":1,"25":1,"33":1,"42":1}}],["osa模块到网络结构中",{"2":{"3":1}}],["osa模块",{"0":{"63":1},"1":{"74":1,"85":1,"96":1,"109":1,"122":1,"133":1,"143":1,"152":1},"2":{"3":1,"33":1,"42":1,"96":2}}],["osa",{"0":{"33":1},"1":{"3":1,"7":1,"12":1,"18":1,"25":1,"33":1,"42":1,"52":1,"63":1,"74":1,"85":1,"96":1,"109":1,"122":1,"133":1,"143":1,"152":1},"2":{"12":1,"33":2,"42":2}}],["若使用笔者的代码",{"2":{"84":1}}],["若未选中",{"2":{"84":1}}],["若因网络原因无法连接到github导致无法下载",{"2":{"73":1}}],["若无特殊需求",{"2":{"51":1}}],["若不想了解",{"2":{"17":1}}],["若您想要更改",{"2":{"84":1}}],["若您想要了解新版本增加的功能",{"2":{"17":1}}],["若您不想要配置外部查看器以及了解内部查看和外部查看之间切换操作",{"2":{"41":1}}],["若您的",{"2":{"0":1}}],["若在安装完该插件之后在",{"2":{"17":1}}],["若输出了一些版本信息",{"2":{"2":1}}],["如",{"2":{"139":1}}],["如需写入到",{"2":{"132":1}}],["如x射线或mri中的单层切片",{"2":{"90":1}}],["如右侧所示",{"2":{"80":1}}],["如图像分类",{"2":{"69":1}}],["如何添加dattention到你的结构中实现涨点",{"2":{"48":1}}],["如何添加到你的网络结构中去",{"2":{"44":1,"83":1}}],["如swinir和edt进行了比较",{"2":{"28":1}}],["如边缘",{"2":{"20":1}}],["如局部窗口",{"2":{"4":1}}],["如上图所示",{"2":{"2":1}}],["如下图所示",{"2":{"11":1,"53":1,"66":1,"96":1,"137":1}}],["如下图",{"2":{"2":1,"84":1,"151":1}}],["如果源图像为",{"2":{"148":5}}],["如果出现",{"2":{"84":1}}],["如果大家看yaml文件看的不清楚自己把结构添加到了哪里可以看下图",{"2":{"60":1}}],["如果你目前并没有数据集可以在网站上下载一个然后上传上去",{"2":{"179":1,"184":1}}],["如果你能够成功复现希望大家给博文评论支持以下",{"2":{"55":1}}],["如果你对rcs",{"2":{"52":1}}],["如果你还不会",{"2":{"44":1,"83":1}}],["如果使用onbuilt命令",{"2":{"51":1}}],["如果说论文中有很多图片或者其他元素没有嵌入字体的话",{"2":{"51":1}}],["如果您对此不感兴趣",{"2":{"51":1}}],["如果您日后需要在上述代码之后再添加其他代码",{"2":{"41":1}}],["如果您需要个性化程度高的话",{"2":{"2":1}}],["如果您想了解",{"2":{"2":1}}],["如果下载速度过慢",{"2":{"2":1}}],["vs",{"2":{"132":1,"142":2,"164":1}}],["vscode重启",{"2":{"11":1}}],["vscode的中文环境需要下载插件来进行支持",{"2":{"11":1}}],["vscode下载与安装",{"0":{"6":1}}],["vscode",{"2":{"0":3,"2":1,"6":2,"11":1,"17":1,"51":2,"73":3,"95":1,"138":1,"142":1,"151":1}}],["vscode配置latex环境",{"1":{"0":1,"2":1,"6":1,"11":1,"17":1,"24":1,"32":1,"41":1,"51":1,"62":1,"73":1,"84":1,"95":1,"108":1,"121":1,"132":1,"142":1,"151":1,"159":1,"164":1}}],["v1",{"2":{"92":2}}],["v2",{"2":{"67":2,"102":1}}],["v8",{"2":{"60":1}}],["vovnet",{"2":{"52":1}}],["very",{"2":{"45":1,"138":2}}],["vit",{"2":{"67":1}}],["viewer",{"2":{"132":4,"142":4,"164":4}}],["view",{"2":{"30":3,"41":3,"45":24,"51":1,"52":3,"92":10,"132":6,"142":10,"164":11}}],["vision",{"2":{"19":1,"48":1,"67":2,"69":1}}],["visual",{"2":{"6":1,"8":1,"11":1,"20":1}}],["var",{"2":{"52":5}}],["valueerror",{"2":{"30":2,"45":1}}],["values",{"2":{"30":1}}],["value",{"2":{"30":1,"45":5,"52":3,"81":1,"92":2,"138":1}}],["van",{"2":{"20":1}}],["v",{"2":{"2":1,"19":6,"27":7,"30":18,"45":6,"46":2,"89":14,"92":5,"102":8}}],["ri​",{"2":{"138":1}}],["ri",{"2":{"138":1}}],["right",{"2":{"138":4}}],["riωi",{"2":{"138":1}}],["r−i+1",{"2":{"138":2}}],["r+∑i=1r​ωi",{"2":{"138":1}}],["r+∑i=1r",{"2":{"138":1}}],["rpe",{"2":{"92":2,"102":17}}],["rpi=rpi",{"2":{"45":1}}],["rpi",{"2":{"45":13}}],["rbr",{"2":{"52":15}}],["rule",{"2":{"45":1}}],["running",{"2":{"52":10}}],["run",{"2":{"41":2,"51":2,"164":2}}],["rgb",{"2":{"45":2,"156":1}}],["roboflow具有的数据预处理",{"0":{"129":1},"1":{"139":1,"148":1,"156":1,"162":1,"167":1,"171":1,"175":1,"178":1,"181":1,"183":1}}],["roboflow具备数据增强的功能",{"0":{"120":1},"1":{"131":1,"141":1,"150":1,"158":1,"163":1,"168":1,"172":1,"176":1}}],["roboflow官方网址",{"2":{"118":1}}],["roboflow的官方地址",{"0":{"118":1}}],["roboflow是官方推荐的数据集获取网站",{"2":{"105":1}}],["roboflow是一个免费开源数据集管理平台",{"2":{"105":1}}],["roboflow还提供了多种数据预处理和数据增强功能",{"2":{"105":1}}],["roboflow",{"0":{"107":1},"1":{"105":1,"118":1,"129":1,"139":1,"148":1,"156":1,"162":1,"167":1,"171":1,"175":1,"178":1,"181":1,"183":1,"184":1},"2":{"107":2,"129":1,"139":1,"148":1}}],["roll",{"2":{"45":2}}],["router",{"2":{"30":3}}],["routing=self",{"2":{"30":2}}],["routing=false",{"2":{"30":6}}],["routing",{"2":{"1":1,"4":2,"30":39}}],["rwightman",{"2":{"45":2}}],["rcan",{"2":{"45":1}}],["rcan和swinir",{"2":{"36":1}}],["rcs能够在训练阶段从输入特征中学习深层表示",{"2":{"18":1}}],["rcs利用通道分割和通道shuffle操作来降低计算复杂性",{"2":{"18":1}}],["rcs模块",{"0":{"25":1},"2":{"12":1}}],["rcsosa",{"2":{"12":1,"52":2,"133":8,"143":4}}],["rcs",{"0":{"7":1,"12":1,"18":1,"52":1,"74":1,"122":1,"133":1,"143":1,"152":1},"1":{"3":1,"7":1,"12":2,"18":2,"25":2,"33":2,"42":2,"52":1,"63":1,"74":1,"85":2,"96":2,"109":2,"122":1,"133":2,"143":2,"152":2},"2":{"12":3,"18":1,"25":1,"33":1,"42":3}}],["rhag",{"2":{"28":1,"45":6}}],["r=1",{"2":{"13":1}}],["r来执行自注意力操作",{"2":{"13":1}}],["raise",{"2":{"30":5,"45":1}}],["randn",{"2":{"52":1,"101":1}}],["random",{"2":{"30":1,"45":3}}],["rand",{"2":{"19":1,"45":1,"92":1}}],["range=1",{"2":{"45":1}}],["range",{"2":{"19":5,"45":9,"52":3,"61":1,"89":1,"92":1,"101":1,"102":8}}],["rate2",{"2":{"92":3}}],["rate1",{"2":{"92":3}}],["rate=0",{"2":{"45":3}}],["rate",{"2":{"45":19,"92":5}}],["rates",{"2":{"13":1}}],["ratio=1",{"2":{"89":1}}],["ratio=0",{"2":{"45":1}}],["ratio=overlap",{"2":{"45":3}}],["ratio=2",{"2":{"45":1}}],["ratio=compress",{"2":{"45":4}}],["ratio=3",{"2":{"45":3}}],["ratio=self",{"2":{"19":2,"45":1}}],["ratio=mlp",{"2":{"19":2,"45":3}}],["ratio=4",{"2":{"19":5,"30":1,"45":4}}],["ratio",{"2":{"19":10,"30":9,"45":38,"89":9}}],["rayleizhu",{"2":{"4":1}}],["red",{"2":{"138":1}}],["reduction",{"2":{"45":3}}],["reduce",{"2":{"30":1}}],["reduced",{"2":{"3":1}}],["redundancy",{"2":{"30":1}}],["reuse",{"2":{"132":1,"142":1,"164":1}}],["ref上的",{"2":{"164":1}}],["reference",{"2":{"102":4}}],["ref",{"2":{"102":22,"132":1,"142":3,"164":1}}],["reflectionpad2d",{"2":{"92":1}}],["requires",{"2":{"92":1,"102":1}}],["reverse",{"2":{"45":4}}],["relative",{"2":{"45":48}}],["relaxing",{"2":{"19":1}}],["relu=false",{"2":{"50":1}}],["relu=true",{"2":{"50":1}}],["relu",{"2":{"45":1,"50":5,"52":2,"89":1,"102":1}}],["reconstruction",{"2":{"45":3}}],["recognition",{"2":{"8":1}}],["recipe",{"2":{"41":1,"51":1,"164":1}}],["recipes中的第一条编译链",{"2":{"51":1}}],["recipes中内容",{"2":{"51":1}}],["recipes",{"2":{"41":1,"51":3,"164":1}}],["region",{"2":{"30":1}}],["register",{"2":{"19":4,"45":3}}],["registry",{"2":{"19":1,"45":3}}],["ret",{"2":{"30":2}}],["returns",{"2":{"45":2,"52":1}}],["return",{"2":{"19":16,"27":1,"30":9,"45":23,"50":4,"52":14,"61":3,"89":4,"92":3,"101":9,"102":4}}],["rearrange",{"2":{"30":13,"45":2,"89":7,"102":6}}],["repeat",{"2":{"92":5}}],["repeats",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["repconv",{"2":{"52":2}}],["repconv块",{"2":{"25":1}}],["reparam",{"2":{"52":3}}],["reparameterized",{"2":{"12":1}}],["repvgg",{"2":{"52":10}}],["reset",{"2":{"92":2}}],["resources",{"2":{"132":1,"142":1,"164":1}}],["reso",{"2":{"67":1}}],["resolution=",{"2":{"45":1}}],["resolution=input",{"2":{"45":3}}],["resolution",{"2":{"19":3,"45":48}}],["res",{"2":{"52":1}}],["result",{"2":{"52":4}}],["results",{"2":{"45":1}}],["resi",{"2":{"45":9}}],["residual",{"2":{"45":8,"102":2}}],["reshape",{"2":{"19":9,"45":7,"52":1,"89":4,"92":1,"102":17}}],["restart",{"2":{"11":1}}],["r",{"2":{"2":1,"30":20,"45":6,"46":1,"132":1,"138":1,"142":1,"156":1,"164":1}}],["+点击",{"2":{"164":1}}],["+8",{"2":{"102":1}}],["+1",{"2":{"102":1}}],["+=",{"2":{"45":5}}],["+",{"2":{"2":1,"19":9,"23":1,"24":1,"30":4,"45":22,"50":3,"52":7,"61":2,"89":9,"92":3,"101":5,"102":7,"138":13,"156":2}}],["⑩",{"2":{"2":1}}],["几分钟左右",{"2":{"2":1}}],["会导致验证的适合报类型不匹配的错误",{"2":{"92":1}}],["会将所有的非",{"2":{"51":1}}],["会对输入进行排列",{"2":{"31":1}}],["会对所有的键",{"2":{"9":1}}],["会产生高计算复杂度和大内存占用",{"2":{"4":1}}],["会出现一些配置文件的安装运行写入",{"2":{"2":1}}],["会先出现下图",{"2":{"2":1}}],["当我们经过上面的步骤一和步骤二以后跳转到该页面",{"2":{"184":1}}],["当我们上传好自己的数据之后就可以对数据集进行数据预处理操作",{"2":{"184":1}}],["当我们上传好自己的数据之后就可以对数据集进行数据增强操作",{"2":{"179":1}}],["当我们建立好一个完整的项目并且上传好图片之后",{"2":{"179":1,"184":1}}],["当我们登录了roboflow之后需要新建一个新的项目",{"2":{"179":1,"184":1}}],["当输入完所有的信息之后即可点击create",{"2":{"179":1,"184":1}}],["当同步到外部查看器时",{"2":{"164":1}}],["当您在",{"2":{"107":1}}],["当然不一定要按照我推荐的地方添加",{"2":{"98":1,"110":1,"146":1,"149":1,"170":1,"180":1}}],["当然如果你不想用快捷键也可以自己寻找大概在",{"2":{"49":1}}],["当编译成功后",{"2":{"84":1}}],["当编译失败时",{"2":{"51":1}}],["当发现页面下方出现",{"2":{"84":1}}],["当其余编译器引用时该",{"2":{"51":1}}],["当代码被保存时自动编译文件",{"2":{"51":1}}],["当出现下图所示弹窗时",{"2":{"2":1}}],["当上面标示的时间安装完之后",{"2":{"2":1}}],["当公式比较长的时候",{"2":{"0":1}}],["可直接完整复制文末笔者的个人配置到自己的编译器内",{"2":{"132":1}}],["可选",{"0":{"95":1},"1":{"108":1,"121":1,"132":1,"142":1}}],["可自行通过上文方式设置为您想要的快捷键",{"2":{"84":1}}],["可对其设置快捷键",{"2":{"84":1}}],["可变形卷积网络",{"2":{"91":1}}],["可变形卷积能够提供一种自适应的内核形状",{"2":{"79":1}}],["可变形卷积通过添加额外的偏移量来调整标准卷积的采样位置",{"2":{"79":1}}],["可变形卷积",{"0":{"79":1},"2":{"57":1,"79":1}}],["可变形大核注意力",{"1":{"38":1,"47":1,"57":1,"68":1,"79":1,"90":1,"101":1,"114":1,"125":1,"135":1,"145":1,"153":1,"160":1,"165":1,"169":1,"173":1,"177":1,"180":1,"182":1},"2":{"38":1}}],["可变形注意力通过改变规则网格来实现图像自适应的稀疏性",{"2":{"4":1}}],["可变形注意力",{"2":{"4":1,"69":1}}],["可能会发现模型在明亮图像而不是暗图像上表现更好",{"2":{"107":1}}],["可能会导致",{"2":{"51":1}}],["可能会导致一些次要的或较远的关联信息被忽略",{"2":{"9":1}}],["可能存在信息损失",{"2":{"9":1}}],["可根据其数字来判断安装所需时间",{"2":{"2":1}}],["可以在版本记录里面看到你保存的不同版本",{"2":{"179":1}}],["可以输入一些你项目的信息例如",{"2":{"179":1,"184":1}}],["可以将",{"2":{"151":1}}],["可以将其分为以下几点",{"2":{"57":1}}],["可以包含特殊标记",{"2":{"138":1}}],["可以替换中干网络中的卷积部分",{"2":{"110":1,"170":1}}],["可以修改yaml文件中输入acmix使用这个模块了",{"2":{"147":1}}],["可以修改yaml文件中输入rcsosa使用这个模块了",{"2":{"109":1}}],["可以修改yaml文件中输入msda使用这个模块了",{"2":{"64":1}}],["可以获得每个图像增强方式的副本",{"2":{"107":1}}],["可以从中获取yolov8官方指定的数据集",{"2":{"105":1}}],["可以帮助模型更好地融合不同尺度的特征",{"2":{"98":1,"146":1}}],["可以实时进行跳转",{"2":{"95":1}}],["可以根据上文进行配置",{"2":{"84":1}}],["可以使用自己的tex文件进行测试",{"2":{"73":1}}],["可以有效地构造大卷积核",{"2":{"68":1}}],["可以用搜索也可以自己手动找",{"2":{"64":1,"109":1,"147":1}}],["可以更改的代码为",{"2":{"51":1}}],["可以跳过该小节",{"2":{"51":1}}],["可以跳过本章节",{"2":{"44":1,"83":1}}],["可以直接复制上述代码至",{"2":{"41":1}}],["可以直接按ctrl",{"2":{"24":1}}],["可以点击",{"2":{"17":1}}],["可以以内容感知的方式关注最相关的键",{"2":{"9":1}}],["可以返回前一页面",{"2":{"2":1}}],["可以查看此篇文章",{"2":{"2":1}}],["可以这么说",{"2":{"0":1}}],["可以看到结果文件中保存了我们的运行结果",{"2":{"82":1}}],["可以看到红框内有好多代码",{"2":{"77":1}}],["可以看到我们的结构以及打印在控制台了",{"2":{"71":1}}],["可以看到开始训练",{"2":{"71":1}}],["可以看到的是",{"2":{"2":1,"51":2,"151":1}}],["可以看到",{"2":{"0":1}}],["具体可以进行的数据预处理已经在前面介绍了",{"2":{"184":1}}],["具体可以进行的数据增强已经在前面介绍了",{"2":{"179":1}}],["具体见下图",{"2":{"159":1}}],["具体哪个效果好可能要大家自己进行一定的尝试才可以",{"2":{"65":1}}],["具体添加到哪里由你自己决定",{"2":{"60":1}}],["具体看下图",{"2":{"51":1}}],["具体包括",{"2":{"20":1}}],["具体安装过程与常见的软件安装过程一致",{"2":{"6":1}}],["具体的安装指标已在下图标明",{"2":{"2":1}}],["具体来说",{"2":{"1":1,"13":1}}],["接着用sigmoid函数生成注意力权重",{"2":{"31":1}}],["接着进行另一个1x1卷积",{"2":{"23":1}}],["接着通过两个全连接层",{"2":{"23":1}}],["接着",{"2":{"14":1}}],["接着就会出现下图",{"2":{"2":1}}],["接下来是",{"2":{"2":1}}],["⑨",{"2":{"2":1}}],["这可以节省内存",{"2":{"156":1}}],["这可用于提高模型的泛化性",{"2":{"150":1}}],["这可能需要更多的实验和调试工作",{"2":{"9":1}}],["这可能会在某些情况下导致模型性能的下降",{"2":{"9":1}}],["这时可以使用外部查看器进行查看",{"2":{"95":1}}],["这也是一个读者和我说的想要帮忙解决一下这个问题困扰了他很久",{"2":{"92":1}}],["这主要通过以下步骤实现",{"2":{"92":1}}],["这对于体积重建和更复杂的医学成像任务非常有用",{"2":{"90":1}}],["这对于理解图像的不同抽象层次是非常重要的",{"2":{"13":1}}],["这有助于提升分割的精确性和边缘定义",{"2":{"79":1}}],["这有助于提升模型对不同大小目标的检测能力",{"2":{"33":1}}],["这条命令是设置什么时候对上文设置的辅助文件进行清除",{"2":{"51":1}}],["这串命令则是设置编译完成后要清除掉的辅助文件类型",{"2":{"51":1}}],["这就意味着",{"2":{"51":1}}],["这两种方法的添加方式有些不同",{"2":{"83":1}}],["这两个命令是设置当文档编译错误时是否弹出显示出错和警告的弹窗",{"2":{"51":1}}],["这两步卷积操作串联执行",{"2":{"20":1}}],["这一改进显著提高了模型map",{"2":{"38":1}}],["这一机制通过动态调整卷积核的形状和大小来适应不同的图像特征",{"2":{"38":1}}],["这一模块用于增强跨窗口信息的交互",{"2":{"28":1}}],["这表明hat在精细化重建细节方面具有优势",{"2":{"36":1}}],["这幅图表展示了不同超分辨率网络的局部归因图",{"2":{"36":1}}],["这幅图描绘了混合注意力变换器",{"2":{"28":1}}],["这幅图展示了vit",{"2":{"13":1}}],["这篇论文的创新点主要包括",{"2":{"28":1}}],["这篇论文提出了一种新的混合注意力变换器",{"2":{"28":1}}],["这篇论文提出的lskattention的机制原理是针对传统大核注意力",{"2":{"20":1}}],["这与rcs的设计理念紧密相连",{"2":{"25":1}}],["这张图片展示了acmix提出的混合模块的结构",{"2":{"92":1}}],["这张图片展示了acmix中的主要概念",{"2":{"81":1}}],["这张图片展示了通过改进的线性注意力模块",{"2":{"67":1}}],["这张图片可能是在说明线性注意力如何在保持注意力机制核心功能的同时",{"2":{"46":1}}],["这张图片是一幅对比不同注意力模块的图示",{"2":{"23":1}}],["这张图展示了多尺度扩张注意力",{"2":{"13":1}}],["这在处理大尺寸核和复杂图像数据时特别有价值",{"2":{"20":1}}],["这意味着在处理图像的关键特征",{"2":{"20":1}}],["这是效率非常低的",{"2":{"107":1}}],["这是三重注意力的核心直觉和设计理念",{"2":{"16":1}}],["这是三重注意力机制中的关键步骤",{"2":{"16":1}}],["这是一个非常重要的步骤",{"2":{"4":1}}],["这里选两个来给大家展示",{"2":{"184":1}}],["这里面可以看到我们生成版本信息我们每次对数据进行一次操作之后的版本都会记录在versions里面",{"2":{"184":1}}],["这里添加acmix可以帮助模型更有效地融合不同层次的特征",{"2":{"170":1}}],["这里添加修改后的c2f",{"2":{"149":1,"180":1}}],["这里添加msda可以帮助模型更有效地融合不同层次的特征",{"2":{"110":1}}],["这里添加注意力机制可以帮助模型更有效地融合不同层次的特征",{"2":{"98":1,"146":1}}],["这里的快捷键为默认设置",{"2":{"84":1}}],["这里的n代表堆叠rcs模块的数量",{"2":{"42":1}}],["这里需要注意的是我上面提供了两段代码一个是c2f",{"2":{"83":1}}],["这里需要注意的是咱们我的网络中需要改成四种的扩张率",{"2":{"13":1}}],["这里我运行的时候有一个警告我没有关",{"2":{"112":1}}],["这里我替大家都行了修改而且在使用时无需手动添加任何参数",{"2":{"102":1}}],["这里我在三个地方添加了biformer注意力机制",{"2":{"60":1}}],["这里我们定义了一个字典",{"2":{"49":1}}],["这里提到的几个关键点包括",{"2":{"46":1}}],["这里正式开始添加biformer注意力机制",{"2":{"30":1}}],["这里先介绍我用的yolov8模型版本",{"2":{"22":1}}],["这里就不作赘述",{"2":{"6":1}}],["这样的机制使得卷积层能够更加灵活地捕捉到各种形态的结构",{"2":{"79":1}}],["这样的分解大幅降低了参数数量和计算复杂度",{"2":{"20":1}}],["这样的组合使得biformer具备了适应性和表达能力",{"2":{"15":1}}],["这样在推理阶段相比普通的3×3卷积可以减少一半的计算复杂度",{"2":{"18":1}}],["这样",{"2":{"13":1,"59":1,"70":1,"176":1}}],["这样可以提高模型的泛化能力",{"2":{"120":1}}],["这样可以整合各个头部学习到的信息",{"2":{"13":1}}],["这样可以并行处理",{"2":{"13":1}}],["这样一来",{"2":{"5":1}}],["这种分解与重构的方法减少了冗余计算",{"2":{"92":1}}],["这种动态选择机制使得模型可以更加集中地关注于那些对当前任务最重要的区域",{"2":{"69":1}}],["这种机制会处理图像中的所有像素",{"2":{"69":1}}],["这种结合使得hat能够更好地重建高频细节",{"2":{"36":1}}],["这种结合不仅保持了低成本的内存消耗",{"2":{"33":1}}],["这种结构设计用于增强模型的特征提取和利用效率",{"2":{"33":1}}],["这种结构通过不同的旋转和排列操作",{"2":{"31":1}}],["这种设计允许在训练时学习复杂特征",{"2":{"25":1}}],["这种设计允许模型在不同的尺度上理解图像",{"2":{"13":1}}],["这种模块通过将2d卷积核分解为串联的1d核",{"2":{"20":1}}],["这种方法可以显著减少计算量",{"2":{"69":1}}],["这种方法可以有效地聚合不同层次的特征",{"2":{"42":1}}],["这种方法允许网络在较大的感受野内学习特征",{"2":{"68":1}}],["这种方法对于改善视觉transformer的性能和效率具有重要意义",{"2":{"46":1}}],["这种方法在计算上是昂贵的",{"2":{"46":1}}],["这种方法通过一个高效的映射函数和秩恢复模块来提高计算效率和性能",{"2":{"29":1,"56":1}}],["这种方法特别适用于处理大尺寸的卷积核",{"2":{"20":1}}],["这种方法使模型能够构建通道与空间位置之间的相互依赖性",{"2":{"16":1}}],["这种自适应性使得模型能够更好地捕捉输入数据的语义关联",{"2":{"9":1}}],["这种做法利用了稀疏性",{"2":{"9":1}}],["这种稀疏性减少了计算和内存开销",{"2":{"9":1}}],["这种特性是有代价的",{"2":{"4":1}}],["这使得注意力机制能够根据每个查询自适应地关注最有语义相关的键",{"2":{"4":1}}],["这使得注意力机制可以集中关注输入图像的不同区域",{"2":{"4":1}}],["这些更改仅影响版本",{"2":{"178":1}}],["这些权重由crt",{"2":{"156":1}}],["这些权重是通过一个s形激活层生成的",{"2":{"16":1}}],["这些块在下采样和上采样之间交替",{"2":{"90":1}}],["这些点的偏移量是由查询通过偏移网络学习得到的",{"2":{"80":1}}],["这些代码是定义在下文",{"2":{"51":1}}],["这些创新点使得所提出的方法在超分辨率重建方面的性能显著优于现有技术",{"2":{"28":1}}],["这些模块通过不同方式计算注意力权重",{"2":{"23":1}}],["这些模式将注意力限制在特定区域",{"2":{"4":1}}],["这些特征随后被连接在一起",{"2":{"13":1}}],["这些操作在围绕红色查询块的窗口内的彩色块之间进行",{"2":{"13":1}}],["这些改进使得msda在不增加额外计算成本的情况下",{"2":{"13":1}}],["这些位置路由器根据特定的规则将图像块分配给上层和下层路由器",{"2":{"1":1}}],["这个文件是另一种添加的方式",{"2":{"119":1,"169":1}}],["这个文章是有个读者指定的所以实验结果都是刚刚出炉的",{"2":{"99":1}}],["这个我在大目标检测的输出添加了一个hattention注意力机制",{"2":{"99":1}}],["这个位置我推荐的原因是因为dcn放在残差里面效果挺好的大家可以尝试",{"2":{"98":1,"146":1}}],["这个offset",{"2":{"80":1}}],["这个hattention代码刚拿来不能够直接使用的",{"2":{"55":1}}],["这个时候可能就是由于辅助文件没有进行及时更新的缘故",{"2":{"51":1}}],["这个架构通过堆叠的rcs模块和repvgg模块",{"2":{"42":1}}],["这个注意力机制代码巨长",{"2":{"28":1}}],["这个注意力机制挺复杂的光代码就700+行",{"2":{"21":1}}],["这个在代码中均有体现",{"2":{"28":1}}],["这个图表展示了所提出的混合注意力变换器",{"2":{"28":1}}],["这个分支保持输入的身份",{"2":{"31":1}}],["这个分支首先进行相同的z池化和卷积操作",{"2":{"31":1}}],["这个分支首先沿着宽度",{"2":{"16":1}}],["这个分支对输入张量进行z池化",{"2":{"31":1}}],["这个分支沿着高度",{"2":{"16":1}}],["这个分支直接处理输入张量",{"2":{"16":1}}],["这个方法能够构建输入通道或空间位置之间的相互依赖性",{"2":{"16":1}}],["这个选项",{"2":{"6":1}}],["这个选项一定要选中",{"2":{"2":1}}],["这个模块可以替换conv",{"2":{"52":1}}],["这个模块使用全局平均池化",{"2":{"23":1}}],["这个模块包含三个分支",{"2":{"5":1}}],["这个模块的主要功能是通过减少特征图的通道数量",{"2":{"3":1}}],["这个机制可以直接使用在主干上",{"2":{"61":1}}],["这个机制",{"2":{"5":1}}],["s=1",{"2":{"101":1}}],["s",{"2":{"60":1,"86":1,"97":1,"99":1,"101":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["sqrt",{"2":{"52":1}}],["squeeze",{"2":{"23":1,"45":15,"92":1}}],["slice",{"2":{"45":6}}],["slices",{"2":{"45":4}}],["sr2",{"2":{"52":2}}],["sr1",{"2":{"52":2}}],["sr",{"2":{"45":4,"52":3,"89":10}}],["swin",{"2":{"45":1,"67":1,"102":1}}],["swinir",{"2":{"45":1}}],["sw",{"2":{"45":3}}],["synctex的参数",{"2":{"142":1,"164":1}}],["synctex",{"2":{"41":3,"51":1,"132":2,"142":4,"164":3}}],["synctex=1",{"2":{"41":3,"51":3,"164":3}}],["ssim性能指标",{"2":{"36":1}}],["same",{"2":{"101":1}}],["sampled",{"2":{"102":9}}],["sample",{"2":{"30":1,"45":2,"92":1,"102":11}}],["sampling",{"2":{"30":1}}],["save",{"2":{"45":3}}],["sa",{"2":{"45":11}}],["satge=cpe",{"2":{"19":2}}],["satge=false",{"2":{"19":3}}],["satge",{"2":{"19":9}}],["songti",{"2":{"73":1}}],["some",{"2":{"45":1}}],["so",{"2":{"30":2}}],["softplus",{"2":{"89":1}}],["soft",{"2":{"30":11}}],["softmax注意力",{"2":{"46":1}}],["softmax和线性注意力机制的对比",{"0":{"46":1}}],["softmax",{"2":{"19":2,"30":4,"45":7,"92":3,"102":1}}],["span>强大",{"2":{"138":1}}],["span",{"2":{"138":2}}],["spatial=false",{"2":{"50":1}}],["spatial",{"2":{"3":1,"27":14,"50":4,"101":4}}],["sppf",{"2":{"60":1,"86":1,"97":1,"98":1,"99":1,"106":1,"119":1,"133":1,"143":1,"146":1,"161":1,"165":1,"166":1,"169":1}}],["speed",{"2":{"45":1}}],["split",{"2":{"30":3,"45":1,"61":3,"89":3,"101":3}}],["scaling",{"2":{"30":1,"60":1,"86":1,"92":2,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["scales",{"2":{"45":2,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["scale=conv",{"2":{"45":3}}],["scale=0",{"2":{"45":2}}],["scale=self",{"2":{"30":1}}],["scale=qk",{"2":{"19":6,"45":5}}],["scale=none",{"2":{"19":8,"30":2,"45":6,"89":1}}],["scale",{"2":{"8":1,"19":15,"30":8,"45":39,"50":2,"60":1,"86":1,"89":5,"97":1,"99":1,"102":2,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["small",{"2":{"19":1,"60":4,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["small的第三个多头自注意力",{"2":{"13":1}}],["sub",{"2":{"102":4}}],["supported",{"2":{"45":3}}],["supports",{"2":{"45":1}}],["super",{"2":{"19":11,"27":1,"30":4,"45":15,"50":3,"52":4,"61":2,"89":3,"92":1,"101":6,"102":2}}],["surpported",{"2":{"30":2}}],["sumatrapdf查看",{"2":{"151":1}}],["sumatrapdf作为自己的",{"2":{"151":1}}],["sumatrapdf下载与安装",{"0":{"108":1}}],["sumatrapdf",{"0":{"95":1,"151":1},"1":{"108":1,"121":1,"132":1,"142":1},"2":{"95":1,"108":2,"132":4,"142":5,"151":2,"164":5}}],["summary",{"2":{"60":5,"86":5,"97":5,"99":5,"106":5,"119":5,"133":5,"143":5,"161":5,"165":5,"166":5,"169":5}}],["sum",{"2":{"19":5,"45":5,"89":1,"92":2,"138":1}}],["stripes",{"2":{"138":1}}],["stride",{"2":{"52":2,"92":14,"101":1,"102":8}}],["stride=self",{"2":{"92":1,"102":1}}],["stride=sr",{"2":{"89":1}}],["stride=stride",{"2":{"50":1,"52":4,"92":1,"101":2}}],["stride=window",{"2":{"45":1}}],["stride=",{"2":{"27":24}}],["stride=2",{"2":{"19":8}}],["stride=1",{"2":{"19":4,"30":1,"50":2,"52":3,"92":1,"101":2,"102":6}}],["stride=patch",{"2":{"19":1}}],["std",{"2":{"52":3}}],["std=0",{"2":{"102":2}}],["std=",{"2":{"19":1,"45":4}}],["standard",{"2":{"61":1,"89":1,"101":2}}],["start",{"2":{"45":2}}],["stackrep=true",{"2":{"52":1}}],["stack",{"2":{"45":3,"102":2}}],["stages",{"2":{"19":3}}],["stage",{"2":{"19":7}}],["stochastic",{"2":{"45":8}}],["studio",{"2":{"0":1,"6":1,"11":1}}],["sign",{"2":{"102":1}}],["sigmoid",{"2":{"45":1,"50":1,"52":1}}],["silu",{"2":{"52":1,"101":1}}],["similar",{"2":{"30":1}}],["simplified",{"2":{"11":1}}],["side",{"2":{"30":5}}],["size",{"2":{"19":36,"27":9,"30":11,"45":220,"50":5,"52":7,"89":2,"92":2,"101":5,"102":15}}],["size=x",{"2":{"89":1}}],["size=self",{"2":{"92":2,"102":1}}],["size=sr",{"2":{"89":1}}],["size=side",{"2":{"30":1}}],["size=5",{"2":{"89":1}}],["size=inputs",{"2":{"52":1}}],["size=img",{"2":{"19":1,"45":5}}],["size=64",{"2":{"45":1}}],["size=window",{"2":{"45":4}}],["size=to",{"2":{"45":1}}],["size=0",{"2":{"45":2}}],["size=7",{"2":{"45":2}}],["size=",{"2":{"27":24,"45":1,"89":3,"101":3,"102":2}}],["size=2",{"2":{"19":2}}],["size=224",{"2":{"19":2,"45":3}}],["size=1",{"2":{"19":2,"45":1,"52":3,"92":5,"102":4}}],["size=patch",{"2":{"19":2,"45":5}}],["size=4",{"2":{"19":2,"45":3}}],["size=kernel",{"2":{"19":4,"50":1,"52":3,"89":1,"101":2}}],["size=3",{"2":{"19":12,"52":1,"102":1}}],["search",{"2":{"132":2,"142":2,"164":2}}],["searchpath",{"2":{"2":1}}],["section",{"2":{"73":2}}],["see",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["se=false",{"2":{"52":2}}],["seblock",{"2":{"52":4}}],["series",{"2":{"45":1}}],["seq",{"2":{"45":4}}],["sequential",{"2":{"19":6,"45":4,"52":4,"102":2}}],["separte",{"2":{"30":1}}],["separable",{"2":{"20":2}}],["segmentation",{"2":{"30":2}}],["semantic",{"2":{"30":2}}],["setting",{"2":{"30":2}}],["set",{"2":{"30":1,"45":5}}],["sel",{"2":{"30":12}}],["select",{"2":{"30":1}}],["self",{"2":{"13":1,"15":1,"19":177,"27":33,"30":118,"45":305,"50":31,"52":76,"61":32,"68":1,"89":61,"92":96,"101":67,"102":137}}],["se",{"2":{"23":1,"52":10}}],["shifts=",{"2":{"45":2}}],["shift",{"2":{"45":24}}],["shifted",{"2":{"45":8}}],["shorcut",{"2":{"101":2}}],["shortcut=false",{"2":{"61":1,"89":1,"101":1}}],["shortcut=true",{"2":{"61":1,"89":1,"101":1}}],["shortcut",{"2":{"45":4,"61":4,"89":4,"101":4}}],["show",{"2":{"41":2,"51":2,"164":2}}],["showcontextmenu",{"2":{"41":1,"51":1,"164":1}}],["should",{"2":{"30":1,"89":1}}],["shot",{"2":{"12":2,"33":2,"42":2}}],["shallow",{"2":{"45":1}}],["shared",{"2":{"30":1}}],["shapes",{"2":{"45":1}}],["shape",{"2":{"19":5,"45":17,"52":1,"89":7,"92":5,"101":2}}],["shuntedtransformer",{"2":{"30":1}}],["shuffle",{"2":{"12":1,"33":1,"52":4}}],["⑧",{"2":{"2":1}}],["前面都有详细的介绍每一个操作能够达到的效果",{"2":{"184":1}}],["前馈神经网络子层通过多层感知机对注意力输出进行非线性变换和特征提取",{"2":{"15":1}}],["前端的选项",{"2":{"2":1}}],["前言",{"0":{"0":1}}],["安装包不到",{"2":{"95":1}}],["安装设置",{"0":{"95":1},"1":{"108":1,"121":1,"132":1,"142":1}}],["安装好之后",{"2":{"6":1}}],["安装检查",{"2":{"2":1}}],["安装后续",{"2":{"2":1}}],["安装ing",{"2":{"2":1}}],["安装",{"2":{"2":1}}],["故而选择xelatex",{"2":{"84":1}}],["故而您可以根据自己的需要更改编译链顺序",{"2":{"51":1}}],["故而笔者使用了onfailed",{"2":{"51":1}}],["故而笔者设置均设置为false",{"2":{"51":1}}],["故而取消",{"2":{"2":1}}],["故此项笔者设置为true",{"2":{"51":1}}],["故笔者写下了此文",{"2":{"0":1}}],["出现如下图页面",{"2":{"151":1}}],["出现编译好的",{"2":{"84":1}}],["出现下图后",{"2":{"2":1}}],["出现狮子",{"2":{"2":1}}],["⑦",{"2":{"2":1}}],["⑥",{"2":{"2":1,"84":1}}],["以",{"2":{"175":1}}],["以下展示由外部查看转为内部查看的操作",{"2":{"159":1}}],["以下为具体操作",{"2":{"151":1}}],["以便您看到图像的显示方式与它们在磁盘上的存储方式相同",{"2":{"139":1}}],["以扩展训练集",{"2":{"120":1}}],["以优化特征通道上的计算复杂度",{"2":{"81":1}}],["以此来选中",{"2":{"84":1}}],["以此测试其是否支持中英文",{"2":{"73":1}}],["以此可以随时对自己的配置代码进行更改",{"2":{"0":1}}],["以往的线性注意力缺乏足够的聚焦能力",{"2":{"56":1}}],["以确保特征的复用并加强不同层之间的信息流动",{"2":{"42":1}}],["以充分利用其潜力",{"2":{"28":1}}],["以进一步提升超分辨率重建的性能",{"2":{"28":1}}],["以进一步发掘hat的潜力",{"2":{"28":1}}],["以改善单图像超分辨率重建",{"2":{"28":1}}],["以激活更多像素以进行高分辨率重建",{"2":{"28":1}}],["以减少计算复杂性和内存消耗",{"2":{"25":1}}],["以及自注意力聚合",{"2":{"81":1}}],["以及cotnet",{"2":{"67":1}}],["以及t2t",{"2":{"67":1}}],["以及两种类型的检测层",{"2":{"42":1}}],["以及对应的性能指标",{"2":{"36":1}}],["以及图像重建三个主要步骤",{"2":{"28":1}}],["以及一个直接的连接",{"2":{"25":1}}],["以及在van中的实际设计",{"2":{"20":1}}],["以及它如何帮助提高处理大型数据集和复杂视觉任务的效率和准确性",{"2":{"14":1}}],["以实现显著的性能提升",{"2":{"14":1}}],["以发挥其最佳性能",{"2":{"9":1}}],["以找到最佳的参数配置",{"2":{"9":1}}],["以适应查询并实现内容感知的稀疏模式",{"2":{"4":1}}],["以免后期使用产生奇怪的问题",{"2":{"2":1}}],["以管理员身份运行",{"2":{"2":1}}],["文章的开头有链接",{"2":{"179":1,"184":1}}],["文章中指出",{"2":{"81":1}}],["文中如果出现错误的地方",{"2":{"164":1}}],["文字大家可能看我描述不太懂",{"2":{"149":1,"180":1}}],["文末有修改了官方代码bug的代码块复制粘贴即可",{"2":{"58":1}}],["文末有完整的个人配置代码",{"2":{"0":1}}],["文档时的默认编译链",{"2":{"51":1}}],["文档编译有时需要用到辅助文件",{"2":{"51":1}}],["文件清理",{"2":{"164":1}}],["文件同步到外部查看器时latex",{"2":{"142":1}}],["文件路径",{"2":{"142":2}}],["文件内后",{"2":{"151":1}}],["文件内",{"2":{"132":1}}],["文件夹",{"2":{"125":1}}],["文件在查看器中的目录",{"2":{"95":1}}],["文件的完整展现效果",{"2":{"95":1}}],["文件可以从",{"2":{"73":1}}],["文件指定位置跳转到",{"2":{"51":1}}],["文件没有正常更新的情况",{"2":{"51":1}}],["文件修改后进行编译时",{"2":{"51":1}}],["文件也会有些字体没有嵌入",{"2":{"51":1}}],["文件默认嵌入所有字体",{"2":{"51":1}}],["文件仍需要根文件完整路径",{"2":{"51":1}}],["文件相应位置",{"2":{"51":1}}],["文件编写规则",{"2":{"41":1}}],["文件中任意的代码",{"2":{"84":2}}],["文件中相应代码所在位置",{"2":{"51":1}}],["文件中",{"2":{"41":1}}],["文件",{"2":{"2":1,"24":1,"51":1,"53":1,"73":1,"84":2,"96":1,"137":1,"151":2}}],["i+1",{"2":{"138":1}}],["ir",{"2":{"138":1}}],["ir⋯",{"2":{"138":2}}],["i=1",{"2":{"138":1}}],["i=self",{"2":{"30":5}}],["ij",{"2":{"102":2}}],["it",{"2":{"45":1}}],["item",{"2":{"19":1,"45":1}}],["id=",{"2":{"138":1}}],["id",{"2":{"52":6}}],["idx=r",{"2":{"30":1}}],["idx",{"2":{"30":8,"41":1,"51":1,"164":1}}],["identity",{"2":{"19":5,"25":1,"30":7,"31":1,"45":5,"52":7,"101":1}}],["ignore",{"2":{"19":1,"45":2}}],["ist",{"2":{"41":1,"51":1,"164":1}}],["issue",{"2":{"30":1}}],["isinstance",{"2":{"19":5,"45":4,"52":3,"101":3}}],["is",{"2":{"19":2,"30":13,"45":9,"50":2,"52":4,"73":2,"92":5,"101":2,"102":1,"113":1,"138":6}}],["isn",{"2":{"19":1}}],["iso",{"2":{"2":2}}],["im",{"2":{"52":2}}],["img",{"2":{"19":13,"45":34}}],["images",{"2":{"45":1}}],["image",{"2":{"19":2,"45":19,"67":1,"92":5}}],["impact",{"2":{"45":1}}],["implemented",{"2":{"30":2}}],["implementation",{"2":{"19":5,"45":1,"61":1,"89":1,"101":1}}],["important",{"2":{"138":1}}],["import",{"2":{"19":6,"27":2,"30":6,"39":1,"45":6,"52":5,"89":3,"92":2,"101":3,"102":6,"113":1}}],["if",{"2":{"19":19,"27":1,"30":14,"45":37,"50":6,"52":13,"61":1,"89":7,"92":5,"101":8,"102":11}}],["inline",{"2":{"138":6}}],["inverse",{"2":{"132":1,"142":1,"164":1}}],["including",{"2":{"101":1}}],["instance",{"2":{"132":1,"142":1,"164":1}}],["install",{"2":{"2":1,"11":1,"17":1}}],["instead",{"2":{"61":1,"89":1,"101":1}}],["info",{"2":{"138":1}}],["inference",{"2":{"45":1}}],["inf",{"2":{"45":1}}],["inplace=true",{"2":{"45":2,"102":3}}],["input=einops",{"2":{"102":1}}],["input=x",{"2":{"102":1}}],["inputs",{"2":{"52":8}}],["input",{"2":{"19":1,"30":1,"45":45,"52":8,"61":2,"89":2,"101":3}}],["ind",{"2":{"41":1,"51":1,"164":1}}],["independent",{"2":{"30":1}}],["indexing=",{"2":{"102":2}}],["index=r",{"2":{"30":1}}],["index",{"2":{"30":4,"45":16}}],["inorporate",{"2":{"30":1}}],["into",{"2":{"45":2}}],["interpolate",{"2":{"89":1}}],["intermediate",{"2":{"45":2}}],["internal",{"2":{"41":3,"51":1,"52":2,"164":1}}],["interaction=nonstopmode",{"2":{"41":3,"51":3,"164":3}}],["intellisense",{"2":{"41":1,"51":1,"164":1}}],["int",{"2":{"19":17,"30":3,"45":51,"52":6,"61":2,"89":3,"101":4,"102":1}}],["in",{"2":{"19":28,"30":10,"44":1,"45":41,"50":2,"52":17,"61":4,"77":1,"89":6,"92":7,"101":10,"102":1,"147":1}}],["initialize",{"2":{"61":1,"89":1,"101":2}}],["initializes",{"2":{"61":1,"89":1,"101":1}}],["init",{"2":{"19":27,"27":2,"30":8,"45":33,"50":6,"52":8,"61":4,"89":6,"92":7,"101":12,"102":4,"135":1}}],["i",{"2":{"13":1,"19":26,"30":11,"45":8,"52":3,"60":1,"86":1,"89":13,"92":4,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["⑤",{"2":{"2":1,"11":1,"84":1,"151":1}}],["打开编译出的",{"2":{"151":1}}],["打开文件夹",{"2":{"84":1}}],["打开测试文件所在文件夹",{"2":{"84":1}}],["打开设置",{"2":{"24":1}}],["打开latex环境设置页面",{"0":{"24":1}}],["打开拓展",{"2":{"11":1,"17":1}}],["打开命令行窗口",{"2":{"2":1}}],["打开运行",{"2":{"2":1}}],["打开",{"2":{"2":1,"6":1}}],["资源管理器打开",{"2":{"2":1}}],["资源管理器",{"2":{"2":1}}],["wk",{"2":{"102":7}}],["wg",{"2":{"102":2}}],["w=num",{"2":{"89":1}}],["w=w",{"2":{"30":1,"89":1}}],["wse",{"2":{"45":12}}],["ws",{"2":{"45":12}}],["wrapper",{"2":{"138":1}}],["wrong",{"2":{"45":2}}],["write",{"2":{"30":1}}],["warning",{"2":{"30":1,"41":1,"51":1,"138":1,"164":1}}],["way=merging",{"2":{"19":2}}],["way=patch",{"2":{"19":1}}],["way=",{"2":{"19":2}}],["way=none",{"2":{"19":3}}],["way",{"2":{"19":15}}],["word",{"2":{"138":1}}],["world",{"2":{"73":1}}],["work",{"2":{"45":1}}],["workshop插件",{"2":{"17":1}}],["workshop",{"2":{"17":1,"41":13,"51":14,"132":6,"142":8,"164":19}}],["workshop安装",{"0":{"17":1},"2":{"17":1}}],["wo",{"2":{"30":3}}],["ww",{"2":{"30":1,"45":17}}],["www",{"2":{"2":1}}],["whose",{"2":{"45":1}}],["whether",{"2":{"45":3}}],["when",{"2":{"30":1,"45":2}}],["where",{"2":{"30":1}}],["wh",{"2":{"30":1,"45":17}}],["w2",{"2":{"30":9}}],["w^2",{"2":{"30":11}}],["were",{"2":{"30":1}}],["we",{"2":{"30":1,"45":1}}],["wether",{"2":{"30":5}}],["weight=r",{"2":{"30":1}}],["weight=mul",{"2":{"30":1}}],["weight=",{"2":{"30":1}}],["weight",{"2":{"19":3,"30":24,"45":5,"52":4,"92":1,"102":4}}],["weights",{"2":{"19":2,"30":2,"45":2}}],["will",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["wiki",{"2":{"51":1}}],["width",{"2":{"45":2,"52":3,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["wise",{"2":{"30":2,"68":2}}],["win=4",{"2":{"30":1}}],["win=7",{"2":{"30":1}}],["win",{"2":{"30":39,"45":10}}],["windowattention",{"2":{"45":2}}],["window",{"2":{"30":5,"45":132}}],["windows",{"2":{"2":2,"30":2,"45":48}}],["without",{"2":{"30":1}}],["with",{"2":{"30":3,"45":4,"48":1,"52":1,"60":2,"61":4,"69":1,"86":2,"89":4,"97":2,"99":2,"101":6,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["w是宽度",{"2":{"23":1}}],["w",{"2":{"16":1,"19":23,"23":1,"28":1,"30":40,"45":54,"89":11,"92":28,"102":40}}],["在如图所示当中我们先点击步骤1然后跳转页面以后点击步骤2即可跳转新的页面",{"2":{"184":1}}],["在使用此工具之前",{"2":{"181":1}}],["在数据集的大部分不包含感兴趣对象的情况下",{"2":{"181":1}}],["在数据集中的许多类相似的情况下",{"2":{"167":1}}],["在最终的输出层前加入d",{"2":{"180":1}}],["在最终的输出层前加入注意力机制可以使模型在做出最终预测之前",{"2":{"98":1,"146":1}}],["在本文中",{"2":{"176":1}}],["在构建失败后清除辅助文件",{"2":{"164":1}}],["在图像的水平轴或垂直轴上随机扭曲图像",{"2":{"158":1}}],["在人工智能领域中",{"2":{"120":1}}],["在残差网络的残差连接中加入d",{"2":{"180":1}}],["在残差网络的残差连接中加入acmix",{"2":{"170":1}}],["在残差网络的残差连接中加入triplet",{"2":{"149":1}}],["在残差网络的残差连接中加入mhsa",{"2":{"110":1}}],["在残差网络的残差连接中加入注意力机制",{"2":{"98":1,"146":1}}],["在特征金字塔网络之前",{"2":{"98":1,"146":1}}],["在第二阶段将两种路径得到的特征相加",{"2":{"92":1}}],["在第一阶段使用三个1x1卷积对输入特征图进行投影",{"2":{"92":1}}],["在acmix中",{"2":{"92":1}}],["在acmix模型中",{"2":{"81":1}}],["在场的focusedlinearattention代码是用于transformer的想要将其用于yolo上是需要进行很大改动的",{"2":{"89":1}}],["在编译生成的",{"2":{"84":1}}],["在编译链中定义的命令出现在了vscode右侧的工具栏中",{"2":{"51":1}}],["在编辑器页面上端进行编译链选择",{"2":{"84":1}}],["在可变形注意力机制中",{"2":{"69":1}}],["在保持或稍微增加计算量的前提下",{"2":{"67":1}}],["在开头导入我们的注意力机制",{"2":{"66":1}}],["在开始介绍作用机制之前",{"2":{"4":1}}],["在上面我们已经将代码复制粘贴到",{"2":{"66":1}}],["在其中注册我们的acmix模块",{"2":{"137":1}}],["在其中注册我们的rcs",{"2":{"96":1}}],["在其中注册我们的msda模块",{"2":{"53":1}}],["在其中创建一个文件",{"2":{"19":1}}],["在检测任何依赖项中的文件更改",{"2":{"51":1}}],["在swin",{"2":{"46":1}}],["在deformable",{"2":{"68":1}}],["在deit中d=64",{"2":{"46":1}}],["在dilateformer论文中",{"2":{"13":1}}],["在yolov8中",{"2":{"38":1}}],["在重建时使用了最多的像素",{"2":{"36":1}}],["在rcs",{"2":{"33":2,"42":1}}],["在提取特征时考虑了通道之间和空间位置之间的相关性",{"2":{"28":1}}],["在深层特征提取部分",{"2":{"28":1}}],["在不同放大倍数",{"2":{"28":1}}],["在推理时减少计算复杂度",{"2":{"25":1}}],["在推理阶段",{"2":{"12":1,"25":2}}],["在van中包括标准深度卷积",{"2":{"20":1}}],["在核大小增加时会导致更高的gflops",{"2":{"20":1}}],["在降低计算和内存成本的同时",{"2":{"20":1}}],["在进行卷积操作时",{"2":{"20":1}}],["在每个时期提供增强数据",{"2":{"107":1}}],["在每个图中",{"2":{"67":1}}],["在每个块中实现内容感知的稀疏性",{"2":{"15":1}}],["在每张图中",{"2":{"13":1}}],["在这里roboflow也官方提供了一个视频讲解大家可以观看",{"2":{"181":1}}],["在这里roboflow官方提供了一个视频讲解大家可以观看",{"2":{"178":1}}],["在这里我给大家推荐两种添加的方式",{"2":{"88":1}}],["在这里说一下这个原文是rcs",{"2":{"52":1}}],["在这里插入图片描述",{"2":{"6":2}}],["在这张图中",{"2":{"46":1}}],["在这个界面上",{"2":{"179":1,"184":1}}],["在这个添加的过程中",{"2":{"22":1}}],["在这个比较中",{"2":{"20":1}}],["在这篇文章中",{"2":{"14":1}}],["在msda中",{"2":{"13":1}}],["在训练阶段",{"2":{"12":1,"25":1}}],["在传统的注意力机制中",{"2":{"9":1}}],["在查询感知的情况下",{"2":{"9":1}}],["在包括图像分类",{"2":{"4":1}}],["在打开方式中选择",{"2":{"2":1}}],["在biformer中",{"2":{"1":1}}],["找到这个文件之后初始如下所示",{"2":{"60":1}}],["找到",{"2":{"2":1}}],["找到下载好的压缩包",{"2":{"2":1}}],["找了很多资料",{"2":{"0":1}}],["④",{"2":{"2":1,"11":1,"17":1,"24":1,"84":1,"151":1}}],["镜像列表选择",{"2":{"2":1}}],["直方图均衡",{"2":{"162":1}}],["直到下载速度在您的可接受范围内即可",{"2":{"2":1}}],["直接上图",{"2":{"0":1}}],["进一步增加了模型对复杂图像模式的适应性",{"2":{"68":1}}],["进一步证明了hat模型的有效性",{"2":{"28":1}}],["进行分屏",{"2":{"151":1}}],["进行导入和注册我们的模块",{"2":{"145":1}}],["进行文件内容查看",{"2":{"84":1}}],["进行解压",{"2":{"73":1}}],["进行编译的速度比",{"2":{"51":1}}],["进行查看",{"2":{"17":1}}],["进行swda操作",{"2":{"13":1}}],["进行",{"2":{"11":1}}],["进行等待即可",{"2":{"2":1}}],["进行安装",{"2":{"2":1,"11":1,"17":1}}],["进行重新点击",{"2":{"2":1}}],["进入设置页面",{"2":{"24":1}}],["进入代码设置页面",{"2":{"24":1}}],["进入镜像列表",{"2":{"2":1}}],["进入",{"2":{"2":1}}],["③",{"2":{"2":1,"6":1,"11":1,"17":1,"24":1,"84":1,"151":1}}],["②",{"2":{"2":1,"6":1,"11":1,"17":1,"24":1,"84":1,"151":1}}],["a4paper",{"2":{"73":1}}],["agpl",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["aggregate",{"2":{"42":1}}],["aggregation",{"2":{"12":2,"33":2,"42":1}}],["abs",{"2":{"102":1}}],["abstract",{"2":{"73":2}}],["absolute",{"2":{"19":1,"45":6}}],["about",{"2":{"51":1}}],["affine=true",{"2":{"50":1}}],["after",{"2":{"30":1,"45":4}}],["ape=false",{"2":{"45":1}}],["ape",{"2":{"45":5}}],["app",{"2":{"132":1,"142":1,"164":1}}],["applies",{"2":{"61":1,"89":1,"101":1}}],["applied",{"2":{"45":2}}],["apply",{"2":{"19":1,"45":1,"101":1}}],["append",{"2":{"19":1,"45":5}}],["author",{"2":{"73":1}}],["autopad",{"2":{"101":2}}],["autoclean",{"2":{"41":1,"51":1,"164":1}}],["autobuild",{"2":{"41":1,"51":1,"164":1}}],["auto",{"2":{"30":5,"101":1,"132":1,"142":2,"164":1}}],["aux",{"2":{"41":1,"51":1,"164":1}}],["article",{"2":{"73":1}}],["artifact",{"2":{"45":1}}],["arguments",{"2":{"61":1,"89":1,"101":2}}],["args",{"2":{"30":2,"41":4,"44":2,"45":13,"51":4,"60":1,"77":2,"86":1,"97":1,"99":1,"101":1,"106":1,"113":2,"119":1,"132":2,"133":1,"142":2,"143":1,"147":1,"161":1,"164":6,"165":1,"166":1,"169":1}}],["arange",{"2":{"45":6,"102":2}}],["archs",{"2":{"45":1}}],["arch",{"2":{"45":3}}],["are",{"2":{"30":1,"45":3,"138":2}}],["avoid",{"2":{"30":2}}],["avg",{"2":{"23":1,"31":1,"52":1,"102":1}}],["avgpool",{"2":{"19":2,"30":2}}],["avgpool2d",{"2":{"19":2,"30":1}}],["avgpool2",{"2":{"19":1}}],["avgpool3",{"2":{"19":2}}],["alert",{"2":{"138":2}}],["aligned",{"2":{"138":1}}],["align",{"2":{"102":2}}],["ali",{"2":{"73":1}}],["alg",{"2":{"41":1,"51":1,"164":1}}],["always",{"2":{"30":1}}],["all",{"2":{"30":1,"92":2,"101":1}}],["a部分",{"2":{"25":1}}],["and",{"2":{"19":2,"30":10,"45":8,"52":1,"61":2,"89":2,"101":3,"102":5}}],["at",{"2":{"19":1,"45":2}}],["att^2",{"2":{"92":4}}],["att",{"2":{"92":33}}],["att=7",{"2":{"92":1}}],["attenblocks",{"2":{"45":2}}],["attention可以帮助模型更有效地融合不同层次的特征",{"2":{"149":1}}],["attention可添加的位置",{"0":{"140":1,"149":1},"1":{"149":1,"157":1}}],["attention到模型中",{"0":{"100":1},"1":{"113":1,"124":1,"134":1,"144":1}}],["attention是一种即插即用的模块",{"2":{"149":1}}],["attention是一种无参数的注意力机制如果你想要放在主干上就按照无参数的注意力机制配置就可以",{"2":{"83":1}}],["attention是对传统线性注意力方法的一种重要改进",{"2":{"29":1,"56":1}}],["attention一个是triplet",{"2":{"83":1}}],["attention机制的c2f和bottleneck",{"0":{"61":1}}],["attention机制原理",{"0":{"10":1},"1":{"16":1,"23":1,"31":1}}],["attention通过特殊的设计来增加特征的多样性和丰富性",{"2":{"56":1}}],["attention通过改进的机制增强了这种聚焦能力",{"2":{"56":1}}],["attentiongate",{"2":{"50":5}}],["attention和其它简单注意力机制的对比",{"0":{"23":1}}],["attention=",{"2":{"19":1,"30":1}}],["attention的训练截图",{"2":{"144":1}}],["attention的训练过程截图",{"0":{"144":1}}],["attention的位置",{"2":{"106":1}}],["attention的yaml文件",{"0":{"134":1}}],["attention的yaml文件二",{"0":{"119":1}}],["attention的yaml文件一",{"0":{"106":1}}],["attention的yaml文件和训练截图",{"0":{"94":1,"124":1},"1":{"106":1,"119":1,"130":1,"134":1,"144":1}}],["attention的本体代码",{"2":{"83":1}}],["attention的添加教程",{"0":{"83":1,"113":1}}],["attention的提出",{"0":{"56":1}}],["attention的核心代码",{"0":{"50":1}}],["attention的完整代码",{"0":{"40":1},"1":{"50":1,"61":1}}],["attention的机制原理",{"0":{"37":1},"1":{"46":1,"56":1,"67":1}}],["attention的实现流程",{"0":{"31":1}}],["attention的基本原理和框架",{"2":{"29":1}}],["attention的基本原理",{"0":{"16":1}}],["attention的视觉transformer模型",{"2":{"1":1,"4":1}}],["attention三重注意力机制",{"2":{"5":1}}],["attention",{"0":{"72":1},"1":{"5":1,"10":1,"16":1,"23":1,"31":1,"40":1,"50":1,"61":1,"72":1,"83":2,"94":2,"106":2,"119":2,"130":2,"140":1,"149":1,"157":1},"2":{"3":1,"4":1,"13":1,"15":1,"16":2,"19":7,"20":4,"23":2,"28":1,"29":1,"30":14,"31":1,"45":22,"48":1,"56":2,"57":1,"67":1,"68":2,"69":2,"90":2,"101":4,"149":1,"169":3}}],["attn",{"2":{"19":37,"27":10,"30":13,"45":68,"89":3,"101":6,"102":26}}],["acmix是一种即插即用的可替换卷积的模块",{"2":{"170":1}}],["acmix是一种混合模型",{"2":{"70":1}}],["acmix添加步骤",{"0":{"116":1},"1":{"127":1,"137":1,"147":1}}],["acmix旨在通过共享计算资源",{"2":{"81":1}}],["acmix",{"2":{"81":1,"92":4,"147":1,"161":3,"166":1}}],["acmix可以灵活地嵌入到不同的网络结构中",{"2":{"81":1}}],["acmix模型的主要改进机制可以分为以下两点",{"2":{"70":1}}],["acmix的训练过程截图",{"0":{"174":1}}],["acmix的yaml版本二",{"0":{"166":1}}],["acmix的yaml版本一",{"0":{"161":1}}],["acmix的yaml文件和运行记录",{"0":{"155":1},"1":{"161":1,"166":1,"170":1,"174":1}}],["acmix的核心代码",{"2":{"92":1}}],["acmix的基本原理",{"0":{"70":1},"1":{"81":1,"92":1}}],["acmix的框架原理",{"2":{"59":1}}],["acmix既能利用自注意力的全局感知能力",{"2":{"59":1,"70":1}}],["acmix首先使用1x1卷积对输入特征图进行投影",{"2":{"59":1,"70":1}}],["acmix自注意力机制",{"1":{"59":1,"70":1,"81":1,"92":1,"103":1,"116":1,"127":1,"137":1,"147":1,"155":1,"161":1,"166":1,"170":1,"174":1}}],["acr",{"2":{"41":1,"51":1,"164":1}}],["acn",{"2":{"41":1,"51":1,"164":1}}],["according",{"2":{"30":1}}],["act=true",{"2":{"101":1}}],["act=frelu",{"2":{"61":1,"89":1,"101":1}}],["actual",{"2":{"30":2,"101":1}}],["activation",{"2":{"30":2,"45":1,"101":6}}],["act",{"2":{"19":12,"30":4,"45":8,"101":8}}],["acquire",{"2":{"2":1}}],["aside",{"2":{"138":1}}],["assert",{"2":{"19":4,"30":10,"45":4,"52":1,"89":1,"102":1}}],["as",{"2":{"19":1,"27":1,"30":4,"45":3,"52":3,"89":1,"92":1,"101":1,"102":3,"113":1}}],["a",{"2":{"4":1,"16":1,"19":2,"30":1,"45":9,"61":1,"73":2,"80":1,"81":1,"84":2,"89":1,"92":2,"101":1,"138":23}}],["addeventlistener",{"2":{"138":1}}],["addmodules",{"2":{"125":1}}],["add",{"2":{"45":7,"52":2,"61":2,"89":2,"101":2}}],["adaptivemaxpool2d",{"2":{"30":1}}],["adaptiveavgpool2d",{"2":{"30":1,"45":1}}],["adaptiveavgpool1d",{"2":{"19":1}}],["ada",{"2":{"30":3}}],["advance",{"2":{"45":1}}],["advanced",{"2":{"2":1}}],["advancde",{"2":{"2":1}}],["adjust",{"2":{"2":1}}],["twitter",{"2":{"138":1}}],["two",{"2":{"30":1,"61":1,"89":1,"101":1}}],["type",{"2":{"45":1,"92":3}}],["typing",{"2":{"30":1}}],["taborbrowser",{"2":{"142":1}}],["tab",{"2":{"142":1}}],["tab1tab2const",{"2":{"138":1}}],["tables",{"2":{"138":1}}],["tableofcontents",{"2":{"73":1}}],["table",{"2":{"45":9,"102":15}}],["tanh",{"2":{"102":1}}],["tasks",{"2":{"39":1,"49":1,"53":1,"60":1,"66":1,"86":1,"96":1,"97":1,"99":1,"106":1,"119":1,"133":1,"137":1,"143":1,"145":1,"161":1,"165":1,"166":1,"169":1}}],["tba",{"2":{"30":1}}],["test",{"2":{"73":1}}],["testfile",{"2":{"73":1}}],["testing",{"2":{"45":1}}],["temperature",{"2":{"30":1}}],["tensors",{"2":{"30":1,"45":1}}],["tensor",{"2":{"30":15,"45":5,"52":10,"92":8,"101":1,"102":1}}],["tex的latex文件路径",{"2":{"164":1}}],["text",{"2":{"138":4}}],["tex文件查看",{"2":{"84":1}}],["tex文件编译",{"0":{"62":1},"1":{"73":1,"84":1}}],["tex测试文件下载",{"0":{"73":1}}],["texstudio",{"2":{"51":1}}],["texworks",{"2":{"2":2}}],["texlive",{"2":{"2":1}}],["tex",{"0":{"2":1,"84":1},"2":{"2":6,"51":7,"73":2,"84":4,"132":1,"142":3,"151":1,"164":2}}],["tuple",{"2":{"30":2,"45":12}}],["tug",{"2":{"2":1}}],["tip",{"2":{"138":1}}],["title",{"2":{"73":1}}],["tiny作为对比的模型",{"2":{"20":1}}],["tiny",{"2":{"19":2}}],["time",{"2":{"45":1}}],["times",{"2":{"19":1,"30":1}}],["timm",{"2":{"19":3,"45":2,"102":1}}],["t",{"2":{"19":2,"30":2,"45":1,"46":1,"52":2}}],["through",{"2":{"61":1,"89":1,"101":1}}],["than",{"2":{"45":1}}],["that",{"2":{"30":1}}],["there",{"2":{"30":2}}],["the",{"2":{"19":3,"30":4,"45":13,"61":1,"73":1,"89":1,"101":1}}],["this",{"2":{"17":1,"51":1,"73":2,"138":4}}],["training",{"2":{"45":3}}],["transposed",{"2":{"101":1}}],["transpose",{"2":{"19":5,"30":2,"45":6,"52":1}}],["transformer中d=32",{"2":{"46":1}}],["transformer`",{"2":{"45":1}}],["transformer",{"2":{"8":1,"19":4,"28":1,"45":2,"48":1,"67":7,"69":1}}],["tripleat",{"2":{"61":3}}],["tripletat",{"2":{"61":3,"106":3}}],["tripletattention",{"2":{"50":2,"61":1,"119":3}}],["triplet",{"0":{"10":1,"16":1,"23":1,"31":1,"40":1,"50":1,"83":1,"94":1,"106":1,"119":1,"140":1},"1":{"5":1,"10":1,"16":2,"23":2,"31":2,"40":1,"50":2,"61":2,"72":1,"83":1,"94":1,"106":2,"119":2,"130":2,"140":1,"149":2,"157":2},"2":{"16":2,"23":1,"31":1,"83":1,"106":1,"149":2}}],["trivial和van中的lska在核大小增加时显著降低了gflops",{"2":{"20":1}}],["trivial",{"2":{"20":3}}],["true",{"2":{"19":5,"41":2,"45":13,"51":2,"60":4,"86":4,"89":1,"97":4,"99":4,"101":1,"106":4,"119":4,"133":4,"143":4,"161":4,"164":2,"165":4,"166":4,"169":4}}],["trunc",{"2":{"19":2,"45":5,"102":3}}],["tolong",{"2":{"138":1}}],["tool是name标签所对应的编译顺序",{"2":{"51":1}}],["tools",{"2":{"41":7,"51":7,"164":7}}],["tokens",{"2":{"67":1}}],["token",{"2":{"45":2,"67":1}}],["toc",{"2":{"41":1,"51":1,"164":1}}],["todo",{"2":{"30":3}}],["topk=self",{"2":{"30":1}}],["topk=4",{"2":{"30":2}}],["topk",{"2":{"30":41}}],["topkrouting",{"2":{"30":2}}],["torchvision",{"2":{"101":2}}],["torchscript",{"2":{"45":1}}],["torch",{"2":{"19":6,"27":2,"30":7,"45":31,"50":4,"52":11,"61":2,"89":15,"92":16,"101":5,"102":25}}],["to",{"2":{"6":1,"19":4,"30":11,"45":28,"52":4,"61":1,"67":1,"73":1,"89":3,"92":2,"101":3,"102":1,"108":1,"138":4}}],["tl",{"2":{"2":1}}],["①",{"2":{"2":1,"6":1,"11":1,"17":1,"24":1,"84":1,"151":1}}],["的图像是使用过滤器空时唯一受影响的图像",{"2":{"181":1}}],["的使用",{"0":{"151":1}}],["的训练截图",{"2":{"112":1}}],["的窗口位置",{"2":{"95":1}}],["的特点",{"2":{"92":1}}],["的生成也转换为1×1卷积操作",{"2":{"92":1}}],["的对比图如下",{"2":{"91":1}}],["的计算",{"2":{"68":1}}],["的模型",{"2":{"67":1}}],["的性能对比",{"2":{"67":1}}],["的top",{"2":{"67":1}}],["的基本原理是结合了大卷积核和可变形卷积的注意力机制",{"2":{"57":1}}],["的基本原理是利用三支结构捕获输入数据的跨维度交互",{"2":{"16":1}}],["的内部查看器的快捷键绑定",{"2":{"51":1}}],["的标准字体",{"2":{"51":1}}],["的引用",{"2":{"51":1}}],["的引入",{"2":{"28":1}}],["的教程",{"2":{"48":1}}],["的目录下",{"2":{"45":1,"66":1}}],["的",{"2":{"41":1,"51":1,"142":1}}],["的配置",{"2":{"41":1}}],["的开头模块导入部分在其中添加如下一行代码",{"2":{"39":1}}],["的结构",{"2":{"33":1}}],["的具体实现流程图",{"2":{"31":1}}],["的整体架构及其关键组成部分的结构",{"2":{"28":1}}],["的设计理念是通过融合通道注意力和自注意力机制来提升单图像超分辨率重建的性能",{"2":{"21":1,"36":1}}],["的两个1d核",{"2":{"20":1}}],["的维度旋转输入张量",{"2":{"16":2}}],["的主要改进点包括",{"2":{"16":1}}],["的工作原理",{"2":{"13":1}}],["的快捷方式",{"2":{"6":1}}],["的编辑器",{"2":{"2":1}}],["的下载与安装说明",{"2":{"2":1}}],["的区别",{"2":{"2":1}}],["ps",{"2":{"181":1}}],["public",{"2":{"179":1,"184":1}}],["p>",{"2":{"138":2}}],["p=none",{"2":{"101":2}}],["p=drop",{"2":{"45":1}}],["pe=false",{"2":{"102":1}}],["pe=true",{"2":{"102":2}}],["pe",{"2":{"92":7,"102":14}}],["perform",{"2":{"101":1}}],["perm2",{"2":{"50":2}}],["perm1",{"2":{"50":2}}],["permutation",{"2":{"31":1}}],["permute",{"2":{"19":13,"45":14,"50":4,"89":6,"92":1}}],["per",{"2":{"19":35,"30":12,"45":2,"52":2}}],["pvt",{"2":{"67":2}}],["p4",{"2":{"60":5,"86":5,"97":5,"99":5,"106":5,"119":5,"133":5,"143":5,"161":5,"165":5,"166":5,"169":5}}],["p1",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["p5",{"2":{"60":5,"86":5,"97":5,"99":5,"106":5,"119":5,"133":5,"143":5,"161":5,"165":5,"166":5,"169":8}}],["p3",{"2":{"60":8,"86":5,"97":5,"99":5,"106":5,"119":5,"133":5,"143":5,"161":5,"165":5,"166":5,"169":5}}],["planes",{"2":{"50":6,"92":16}}],["pw",{"2":{"45":2}}],["phosphors确定",{"2":{"156":1}}],["ph",{"2":{"45":2}}],["pdf查看器用于在",{"2":{"164":1}}],["pdf查看",{"2":{"84":1}}],["pdflatex",{"2":{"41":9,"51":13,"164":9}}],["pdf",{"0":{"159":1},"2":{"41":5,"51":7,"84":4,"95":5,"132":8,"142":16,"151":4,"164":15}}],["pyramid",{"2":{"67":1}}],["pytorch",{"2":{"45":3}}],["py配置的代码如下",{"2":{"44":1,"113":1}}],["py",{"2":{"39":1,"45":3,"49":1,"53":1,"66":2,"96":1,"135":1,"137":1,"145":1}}],["pix",{"2":{"30":22}}],["pixels",{"2":{"45":1}}],["pixelshuffledirect",{"2":{"45":1}}],["pixelshuffle",{"2":{"45":5}}],["pixel",{"2":{"30":1}}],["p2",{"2":{"30":15,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["p^2",{"2":{"30":36}}],["prob=none",{"2":{"45":1}}],["prob",{"2":{"45":9}}],["project",{"2":{"179":1,"184":1}}],["projection",{"2":{"30":1,"45":2}}],["proj",{"2":{"19":21,"45":10,"89":6,"101":4,"102":20}}],["print",{"2":{"19":1,"30":1,"52":2,"92":1,"101":1}}],["pretrained=false",{"2":{"19":1}}],["pretrained=true",{"2":{"19":3}}],["points",{"2":{"102":2}}],["pointconv",{"2":{"19":1}}],["policy",{"2":{"30":2}}],["pool2d",{"2":{"52":1,"102":1}}],["pooling",{"2":{"30":2}}],["pool",{"2":{"23":1,"31":1}}],["positional",{"2":{"89":3,"92":1}}],["position",{"2":{"45":36,"92":2}}],["pos",{"2":{"19":7,"45":6,"102":5}}],["pass",{"2":{"61":2,"89":2,"101":2}}],["paper",{"2":{"48":1}}],["padded",{"2":{"30":2}}],["padding",{"2":{"30":2,"52":5,"92":2,"101":2}}],["padding=9",{"2":{"101":1}}],["padding=2",{"2":{"101":1}}],["padding=kernel",{"2":{"89":1}}],["padding=padding",{"2":{"50":1,"52":4,"101":2}}],["padding=side",{"2":{"30":1}}],["padding=",{"2":{"27":24,"45":1,"50":1}}],["padding=0",{"2":{"19":4,"45":2,"50":1,"92":1,"102":4}}],["padding=1",{"2":{"19":11,"52":1,"92":1,"101":1,"102":1}}],["pad",{"2":{"30":15,"52":3,"92":4,"101":2,"102":2}}],["pad=true",{"2":{"30":1}}],["parse",{"2":{"49":1}}],["partition",{"2":{"45":7}}],["partial^r",{"2":{"138":1}}],["partial",{"2":{"19":2,"138":1}}],["parameters",{"2":{"60":6,"86":6,"92":2,"97":6,"99":6,"102":1,"106":6,"119":6,"133":7,"143":6,"161":6,"165":6,"166":6,"169":6}}],["parameter",{"2":{"45":5,"89":3,"92":3,"102":6}}],["param=true",{"2":{"30":1}}],["params",{"2":{"30":1,"45":8,"67":1}}],["param",{"2":{"30":20}}],["patchunembed",{"2":{"45":3}}],["patchify",{"2":{"30":1}}],["patchmerging",{"2":{"19":3,"45":1}}],["patches=64",{"2":{"89":1}}],["patches",{"2":{"19":4,"45":23,"89":1}}],["patchembed",{"2":{"19":2,"45":3}}],["patch",{"2":{"19":21,"45":52,"90":1}}],["paths",{"2":{"45":2}}],["path=dpr",{"2":{"19":2,"45":1}}],["path=drop",{"2":{"19":2,"45":2}}],["path=0",{"2":{"19":5,"45":3}}],["path",{"2":{"19":17,"45":19}}],["package",{"2":{"41":1,"51":1,"164":1}}],["pack",{"2":{"11":1}}],["p",{"2":{"2":1,"92":2,"101":4,"102":2}}],["cmd",{"2":{"164":1}}],["cmd+鼠标左键单击",{"2":{"51":1}}],["centered",{"2":{"138":1}}],["ceil",{"2":{"52":1}}],["cdots",{"2":{"138":1}}],["cg",{"2":{"102":1}}],["c=self",{"2":{"102":2}}],["ctex",{"2":{"73":1}}],["ctrl",{"2":{"51":1,"164":1}}],["cswin",{"2":{"67":1}}],["csp",{"2":{"61":2,"89":2,"101":2}}],["cvt",{"2":{"67":1}}],["cv2",{"2":{"61":6,"89":6,"101":6}}],["cv1",{"2":{"61":6,"89":7,"101":7}}],["c2",{"2":{"52":7,"61":8,"89":8,"101":12}}],["c2f",{"2":{"44":1,"60":8,"61":2,"83":1,"86":8,"89":2,"97":8,"99":8,"101":3,"106":8,"119":8,"143":4,"161":8,"165":8,"166":8,"169":8}}],["c1",{"2":{"52":8,"61":5,"89":5,"101":7}}],["cw",{"2":{"50":2}}],["cross",{"2":{"45":1}}],["crop",{"2":{"30":1}}],["cyclic",{"2":{"45":2}}],["caution",{"2":{"138":1}}],["caused",{"2":{"30":1}}],["calculate",{"2":{"45":10}}],["call",{"2":{"30":1,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["cat",{"2":{"45":2,"50":1,"52":2,"60":4,"61":2,"86":4,"89":2,"92":2,"97":4,"99":4,"101":2,"106":4,"119":4,"133":4,"143":4,"161":4,"165":4,"166":4,"169":4}}],["cascade",{"2":{"42":1}}],["case",{"2":{"30":1}}],["cannot",{"2":{"30":1,"45":1}}],["cab",{"2":{"28":1,"45":5}}],["cpu",{"2":{"107":3}}],["cpb",{"2":{"102":4}}],["cpb=false",{"2":{"102":1}}],["cpy",{"2":{"30":1}}],["cpe",{"2":{"19":29}}],["cuda=true",{"2":{"92":1}}],["cuda",{"2":{"30":1,"92":4}}],["cbam",{"2":{"23":1}}],["cnt",{"2":{"45":3}}],["cnn",{"2":{"20":1}}],["cnblogs",{"2":{"2":1}}],["cli",{"2":{"132":1,"142":1,"164":1}}],["click",{"2":{"6":1,"41":3,"51":5,"73":1,"108":1,"138":1,"164":1}}],["clahe",{"2":{"162":1}}],["clamp",{"2":{"102":1}}],["classical",{"2":{"45":2}}],["classes",{"2":{"19":4,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["classes=1000",{"2":{"19":1}}],["class",{"2":{"19":11,"27":1,"30":4,"45":14,"50":4,"52":4,"61":2,"89":3,"92":1,"101":6,"102":2}}],["cls代表检测到的对象中的类别数量",{"2":{"42":1}}],["clean",{"2":{"41":1,"51":1,"164":1}}],["clone",{"2":{"19":1,"27":1,"101":2}}],["cfg=",{"2":{"71":1}}],["cfg",{"2":{"19":7,"60":1,"71":1}}],["c",{"2":{"16":3,"19":18,"23":1,"30":53,"45":46,"52":8,"61":10,"81":1,"84":1,"89":39,"92":3,"101":8,"102":16,"138":11}}],["chunk",{"2":{"52":1,"61":2,"89":3,"101":3}}],["checkpoint=use",{"2":{"45":2}}],["checkpoint=false",{"2":{"45":3}}],["checkpointing",{"2":{"45":3}}],["checkpoint",{"2":{"45":7}}],["ch=c",{"2":{"45":1}}],["ch",{"2":{"44":1,"45":6,"61":2,"77":1,"89":2,"101":4,"113":1,"147":2}}],["chans=embed",{"2":{"45":2}}],["chans=0",{"2":{"45":2}}],["chans=in",{"2":{"19":1}}],["chans=3",{"2":{"19":2,"45":3}}],["chans",{"2":{"19":4,"45":10}}],["change",{"2":{"17":1}}],["channelattention",{"2":{"45":3}}],["channels=32",{"2":{"102":1}}],["channels=2",{"2":{"101":1}}],["channels=head",{"2":{"89":2}}],["channels=out",{"2":{"52":4}}],["channels=internal",{"2":{"52":2}}],["channels=input",{"2":{"52":2}}],["channels=in",{"2":{"52":4,"101":3}}],["channels",{"2":{"19":17,"45":10,"50":1,"52":34,"60":1,"61":3,"86":1,"89":3,"97":1,"99":1,"101":7,"102":17,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["channel",{"2":{"3":1,"12":1,"33":1,"45":4,"52":2}}],["chinese",{"2":{"11":1}}],["color",{"2":{"138":1}}],["col",{"2":{"138":2}}],["cool",{"2":{"138":1}}],["coords",{"2":{"45":39}}],["corners=true",{"2":{"102":2}}],["coatnet的性能对比",{"2":{"67":1}}],["concat",{"2":{"60":4,"86":4,"97":4,"99":4,"106":4,"119":4,"133":4,"143":4,"161":4,"165":4,"166":4,"169":4}}],["connection=resi",{"2":{"45":1}}],["connection=",{"2":{"45":2}}],["connection",{"2":{"45":9}}],["contiguous",{"2":{"30":3,"45":9,"50":4,"52":1,"102":1}}],["contextual",{"2":{"67":1}}],["context",{"2":{"23":1}}],["console",{"2":{"138":3}}],["consuming",{"2":{"45":1}}],["consumes",{"2":{"30":1}}],["consider",{"2":{"30":1}}],["const",{"2":{"138":31}}],["constants",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["constant",{"2":{"19":3,"45":3}}],["constraints",{"2":{"19":1}}],["conv=3",{"2":{"92":1}}],["convnext",{"2":{"67":1}}],["convnets",{"2":{"45":1}}],["conv1",{"2":{"27":2,"52":3,"92":2,"101":2}}],["conv0",{"2":{"101":2}}],["conv0v",{"2":{"27":7}}],["conv0h",{"2":{"27":7}}],["conv2",{"2":{"19":2,"92":2}}],["conv2d",{"2":{"19":15,"27":25,"30":1,"45":11,"50":1,"52":4,"68":2,"89":2,"92":6,"101":5,"102":7}}],["conv3",{"2":{"19":3,"52":3,"92":2}}],["convolutions",{"2":{"61":2,"89":2,"101":2}}],["convolutional",{"2":{"23":1,"45":2,"67":1}}],["convolution",{"2":{"12":1,"68":3,"79":1,"101":3}}],["conv",{"2":{"4":1,"20":3,"23":1,"27":14,"30":2,"31":1,"44":1,"45":30,"50":4,"52":6,"60":7,"61":4,"83":1,"86":7,"89":4,"92":27,"97":7,"99":7,"101":12,"102":3,"106":7,"119":7,"133":7,"143":7,"161":7,"165":7,"166":7,"169":7}}],["codes",{"2":{"45":1}}],["code插件",{"2":{"11":1}}],["code",{"2":{"6":1,"45":1,"132":2,"138":6,"142":3,"164":2}}],["code呢",{"2":{"0":1}}],["compound",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["compatible",{"2":{"45":1}}],["compress",{"2":{"45":12,"50":4}}],["command的参数",{"2":{"142":1,"164":1}}],["command",{"2":{"41":4,"51":4,"132":2,"142":2,"164":6}}],["com",{"2":{"2":1,"4":1,"45":2,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["和上面的思想也不一样",{"2":{"169":1}}],["和第",{"2":{"162":1}}],["和值",{"2":{"92":2}}],["和d",{"2":{"90":1}}],["和深度可分离的带扩张的卷积",{"2":{"68":1}}],["和top",{"2":{"67":1}}],["和repvgg",{"2":{"42":1}}],["和窗口式多头自注意力",{"2":{"28":1}}],["和一个重叠交叉注意块",{"2":{"28":1}}],["和不同数据集",{"2":{"28":1}}],["和推理阶段",{"2":{"25":1}}],["和1×1卷积",{"2":{"20":1}}],["和垂直",{"2":{"20":1}}],["和通道",{"2":{"16":2}}],["和前馈神经网络子层",{"2":{"15":1}}],["和",{"2":{"2":1,"51":1,"92":1,"151":1,"181":1}}],["系统是",{"2":{"2":1}}],["下图操作为将",{"2":{"178":1}}],["下图操作为省略",{"2":{"178":1}}],["下图为切片工具和输出的预览",{"2":{"175":1}}],["下图展示两者区别",{"2":{"51":1}}],["下文配置需要使用其路径",{"2":{"108":1}}],["下文会进行提及",{"2":{"51":1}}],["下一步我们就需要添加该机制到模型中让我们可以使用它",{"2":{"49":1}}],["下一步是应用标记到标记的注意力",{"2":{"4":1}}],["下部分支",{"2":{"31":1}}],["下面来介绍数据预处理的操作流程",{"2":{"184":1}}],["下面来介绍数据增强的操作流程",{"2":{"179":1}}],["下面来介绍作用机制biformer是一种结合了bi",{"2":{"4":1}}],["下面开始来介绍如何利用roboflow进行数据增强的具体操作",{"2":{"179":1}}],["下面提供一些指导哪种调整大小选项可能最适合您的用例",{"2":{"148":1}}],["下面介绍每个选项",{"2":{"129":1}}],["下面推荐几个版本的yaml文件给大家",{"2":{"75":1,"155":1}}],["下面是我添加了focused",{"2":{"144":1}}],["下面是我添加了lskattention的训练截图",{"2":{"76":1}}],["下面是dattention的训练过程和我添加的位置截图",{"2":{"126":1}}],["下面是添加了acmix的训练截图",{"2":{"174":1}}],["下面是添加了rcs",{"2":{"152":1}}],["下面是添加了d",{"2":{"130":1,"173":1}}],["下面是添加了msda的训练截图",{"2":{"123":1}}],["下面是添加了hattention",{"2":{"112":1}}],["下面是使用教程",{"2":{"55":1}}],["下面是对这个过程的描述",{"2":{"31":1}}],["下面进行代码注释解读",{"2":{"51":1}}],["下面先来分享我测试的对比图",{"2":{"48":1}}],["下面为大家提供的图像展示的是rcs",{"2":{"42":1}}],["下面我将详细介绍一下其中部分数据增强处理的具体的功能及其效果",{"2":{"120":1}}],["下面我将为大家展示rcs",{"2":{"33":1}}],["下面我们找到文件",{"2":{"66":1}}],["下面我来分别讲解这三种主要的改进机制",{"2":{"57":1}}],["下面我通过图片来辅助大家理解这一优势",{"2":{"9":1}}],["下面的添加acmix是我实验结果的版本",{"2":{"161":1}}],["下面的添加msda是我实验结果的版本",{"2":{"86":1}}],["下面的",{"2":{"148":1}}],["下面的是我将flattention放在neck中的截图",{"2":{"144":1}}],["下面的是将flattention机制我添加到了c2f和bottleneck",{"2":{"144":1}}],["下面的是放在c2f中的yaml配置",{"2":{"134":1}}],["下面的是放在neck部分的截图",{"2":{"134":1}}],["下面的配置文件为我修改的rcs",{"2":{"133":1}}],["下面的配置文件为我修改的c2f",{"2":{"106":1,"165":1}}],["下面的图片上可以看到roboflow具有的数据增强功能",{"2":{"120":1}}],["下面的图片是三重注意力",{"2":{"31":1}}],["下面的图片是三重注意力的一个抽象表示图",{"2":{"16":1}}],["下面的图片是论文中三重注意力机制和其它注意力机制的一个对比大家有兴趣可以看看",{"2":{"23":1}}],["下面的代码是dat的网络结构代码",{"2":{"102":1}}],["下面的代码是msda的核心代码",{"2":{"19":1}}],["下面的yaml文件我会给大家推荐",{"2":{"86":1,"161":1}}],["下载步骤如图",{"2":{"73":1}}],["下载中文插件",{"2":{"11":1}}],["下载",{"2":{"2":2,"73":1}}],["下载页面",{"2":{"2":1}}],["下载与安装",{"0":{"2":1}}],["下层路由器则使用局部自注意力机制对每个图像块与其邻近的图像块进行交互",{"2":{"1":1}}],["lr",{"2":{"36":1}}],["lce",{"2":{"30":1}}],["l是hat的一个更大的变体",{"2":{"28":1}}],["lska模块在保持与标准大核注意力",{"2":{"20":1}}],["lska",{"2":{"20":2,"27":1,"44":1}}],["lskattention可以是一种即插即用的注意力机制",{"2":{"98":1}}],["lskattention可添加的位置",{"0":{"87":1},"1":{"98":1,"111":1}}],["lskattention通过创新的核分解和串联卷积策略",{"2":{"20":1}}],["lskattention通过以下几个关键步骤和原理来解决这些问题",{"2":{"20":1}}],["lskattention不仅在图像分类任务中表现出色",{"2":{"20":1}}],["lskattention能够有效地捕捉到重要信息",{"2":{"20":1}}],["lskattention仍然能够保持类似于原始lka的性能",{"2":{"20":1}}],["lskattention在执行时的计算效率得到显著提升",{"2":{"20":1}}],["lskattention首先使用一个1d核对输入进行水平方向上的卷积",{"2":{"20":1}}],["lskattention的训练过程截图",{"0":{"76":1}}],["lskattention的yaml文件",{"0":{"65":1}}],["lskattention的yaml文件和训练截图",{"0":{"54":1},"1":{"65":1,"76":1}}],["lskattention的添加教程",{"0":{"44":1}}],["lskattention的代码",{"0":{"27":1}}],["lskattention的核心创新是将传统的2d卷积核分解为两个1d卷积核",{"2":{"20":1}}],["lskattention的机制原理",{"0":{"20":1}}],["lka是一种即插即用的模块",{"2":{"180":1}}],["lka可以使模型在做出最终预测之前",{"2":{"180":1}}],["lka可以帮助模型更有效地融合不同层次的特征",{"2":{"180":1}}],["lka可以被用于提升对小目标和不规则形状目标的检测能力",{"2":{"38":1}}],["lka可添加的位置",{"0":{"157":1,"177":1,"180":1,"182":1},"1":{"180":1,"182":1}}],["lka代码和c2f",{"0":{"101":1}}],["lka注意力机制进行特征学习",{"2":{"90":1}}],["lka块",{"2":{"90":2}}],["lka模型",{"2":{"90":4}}],["lka模块在处理大尺寸卷积核时面临着高计算和内存需求的挑战",{"2":{"20":1}}],["lka则扩展了这种技术",{"2":{"90":1}}],["lka专为处理二维图像数据设计",{"2":{"90":1}}],["lka中",{"2":{"68":1}}],["lka通过可变形卷积来灵活调整采样网格",{"2":{"57":1}}],["lka的位置",{"2":{"165":1}}],["lka的yaml文件二",{"0":{"169":1}}],["lka的yaml文件一",{"0":{"165":1}}],["lka的yaml文件和训练截图",{"0":{"160":1},"1":{"165":1,"169":1,"173":1}}],["lka的训练截图",{"2":{"130":1,"173":1}}],["lka的训练过程截图",{"0":{"130":1,"173":1}}],["lka的2d和3d版本",{"2":{"57":1}}],["lka的基本原理",{"0":{"57":1}}],["lka的朴素设计",{"2":{"20":1}}],["lka机制原理",{"0":{"47":1},"1":{"57":1,"68":1,"79":1,"90":1}}],["lka结合了大卷积核的广阔感受野和可变形卷积的灵活性",{"2":{"38":1}}],["lka",{"0":{"101":1,"114":1},"1":{"125":1,"135":1,"145":1,"153":1,"160":1,"165":1,"169":1,"173":1},"2":{"20":4,"38":2,"57":2,"68":1,"90":2,"101":6,"169":3,"180":1}}],["l",{"2":{"19":1,"30":2,"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"132":1,"133":1,"142":1,"143":1,"161":1,"164":1,"165":1,"166":1,"169":1}}],["loc",{"2":{"92":8}}],["local",{"2":{"30":3,"45":2}}],["long",{"2":{"138":4}}],["longtensor",{"2":{"30":1}}],["loner",{"2":{"73":1}}],["loss",{"2":{"44":1,"83":1}}],["lot",{"2":{"41":1,"51":1,"164":1}}],["lof",{"2":{"41":1,"51":1,"164":1}}],["look",{"2":{"19":1}}],["logy",{"2":{"138":2}}],["log⁡y",{"2":{"138":2}}],["log2",{"2":{"102":2}}],["logit",{"2":{"30":4}}],["log",{"2":{"17":1,"41":1,"45":1,"51":1,"102":5,"138":5,"164":1}}],["left",{"2":{"138":3}}],["leakyrelu",{"2":{"45":1}}],["leak",{"2":{"30":1}}],["learnable",{"2":{"30":1,"45":5}}],["lepe",{"2":{"30":7,"102":2}}],["len",{"2":{"19":2,"45":5}}],["level",{"2":{"1":1,"4":2,"30":1}}],["last",{"2":{"45":3}}],["lastused",{"2":{"41":1,"51":2,"164":1}}],["lam展示了在重建高分辨率",{"2":{"36":1}}],["lam",{"2":{"36":1}}],["lambda",{"2":{"30":1}}],["larger",{"2":{"45":1}}],["large",{"2":{"20":3,"45":1,"57":1,"60":1,"68":2,"86":1,"90":2,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":4}}],["layer=partial",{"2":{"19":1}}],["layer=none",{"2":{"45":4}}],["layer=norm",{"2":{"19":4,"45":7}}],["layer=nn",{"2":{"19":10,"45":9}}],["layer=act",{"2":{"19":4,"45":1}}],["layernormproxy",{"2":{"102":2}}],["layernorm",{"2":{"19":7,"45":12,"89":1,"102":1}}],["layer",{"2":{"19":39,"30":1,"45":50,"61":2,"89":2,"101":3}}],["layers",{"2":{"19":4,"45":8,"60":5,"86":5,"97":5,"99":5,"102":1,"106":5,"119":5,"133":5,"143":5,"161":5,"165":5,"166":5,"169":5}}],["language",{"2":{"11":1}}],["latex配置代码解读",{"0":{"51":1}}],["latex配置代码展示",{"0":{"41":1}}],["latexmk",{"2":{"41":5,"51":6,"164":5}}],["latex代码配置",{"2":{"41":1}}],["latex环境的代码配置",{"0":{"32":1},"1":{"41":1,"51":1}}],["latex的支持插件",{"0":{"17":1}}],["latex",{"0":{"17":1},"2":{"0":1,"2":1,"17":2,"41":22,"51":23,"73":1,"84":1,"132":6,"142":8,"164":26}}],["lipsum",{"2":{"73":2}}],["license",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["like",{"2":{"30":1}}],["link",{"2":{"138":6}}],["line",{"2":{"41":3,"51":3,"132":1,"142":2,"164":5}}],["linear",{"0":{"37":1,"56":1,"100":1,"113":1,"124":1,"134":1,"144":1},"1":{"46":1,"56":1,"67":1,"113":1,"124":1,"134":2,"144":2},"2":{"19":8,"29":3,"30":7,"45":11,"56":5,"89":4,"102":2,"144":1}}],["linspace",{"2":{"19":1,"45":1,"92":4,"102":2}}],["list",{"2":{"2":2,"19":2,"45":1,"61":2,"89":3,"101":3}}],["liuliang1999",{"2":{"2":1}}],["live",{"0":{"2":1},"2":{"2":5}}],["一开始的项目地方是空的",{"2":{"179":1,"184":1}}],["一种预处理工具",{"2":{"178":1}}],["一种用于局部对比度增强的算法",{"2":{"162":1}}],["一篇文章很难全部介绍到",{"2":{"110":1}}],["一组参考点均匀地放置在特征图上",{"2":{"80":1}}],["一部分直接通过",{"2":{"33":1}}],["一部分输入经过repvgg块",{"2":{"25":1}}],["一个2019年论文谷歌研究人员介绍了仅使用边界框增强为其模型创建最佳数据的想法",{"2":{"176":1}}],["一个特定的查询块",{"2":{"13":1}}],["一个分支可能专注于图像的宽度",{"2":{"5":1}}],["一次性聚合多个特征级联",{"2":{"12":1}}],["一定要选上",{"2":{"6":1}}],["一些方法引入了稀疏模式",{"2":{"4":1}}],["一",{"0":{"1":1,"3":1,"5":1,"8":1,"14":1,"21":1,"29":1,"38":1,"48":1,"59":1},"1":{"70":1,"81":1,"92":1}}],["有三个参数变量",{"2":{"142":1}}],["有三个选项",{"2":{"51":1}}],["有三种变量参数",{"2":{"142":1}}],["有序列表3",{"2":{"138":1}}],["有序列表2",{"2":{"138":1}}],["有序列表1",{"2":{"138":1}}],["有的时候",{"2":{"95":1}}],["有的地方需要更改路径",{"2":{"0":1}}],["有以下三种方法",{"2":{"84":1}}],["有两个变量",{"2":{"51":1}}],["有一个方法的名字叫",{"2":{"49":1}}],["有多个残差混合注意力组",{"2":{"28":1}}],["有效集和测试集中的所有图像",{"2":{"129":1}}],["有效地处理复杂的视觉信息",{"2":{"38":1}}],["有效地整合了全局的像素信息",{"2":{"21":1,"36":1}}],["有效降低了计算复杂度和内存需求",{"2":{"20":1}}],["有具体说明",{"2":{"0":1}}],["3d",{"2":{"90":1}}],["3d版本特别擅长于交叉深度数据理解",{"2":{"90":1}}],["3db到1",{"2":{"28":1}}],["32",{"2":{"60":2,"86":2,"97":2,"99":2,"101":2,"102":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":5}}],["365",{"2":{"60":2,"86":2,"97":2,"99":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["3157184",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["3157200",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["335",{"2":{"148":3}}],["33",{"2":{"60":2,"86":2,"97":2,"99":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["3conv",{"2":{"45":1}}],["35",{"2":{"27":1,"65":1}}],["3x3卷积通过1x1卷积的方式被分解",{"2":{"92":1}}],["3x3",{"2":{"13":1,"52":2}}],["3",{"0":{"11":1,"25":1,"31":1,"50":1,"61":1,"64":1,"67":1,"79":1,"91":1,"104":1,"109":1,"110":1,"145":1,"147":1,"170":1},"1":{"117":1,"128":1,"138":1},"2":{"0":1,"12":1,"13":2,"16":1,"19":33,"23":1,"27":10,"28":1,"30":3,"45":36,"50":5,"52":4,"57":1,"60":16,"61":6,"67":1,"68":1,"86":16,"89":8,"92":2,"97":16,"99":15,"101":8,"102":2,"106":16,"119":16,"133":16,"138":3,"143":16,"161":16,"165":10,"166":16,"169":19,"178":1}}],["并保留纵横比和原始数据",{"2":{"148":3}}],["并可能导致训练失败",{"2":{"181":1}}],["并可能因映射函数带来额外的计算开销",{"2":{"56":1}}],["并可以选择缩放到所需的尺寸集",{"2":{"148":1}}],["并检查推理中的图像是如何馈送到模型的",{"2":{"139":1}}],["并进行实验评估以确保增强后的数据符合预期的效果",{"2":{"120":1}}],["并提供了便捷的数据处理工具",{"2":{"105":1}}],["并提供灵活性和强大的表达能力",{"2":{"15":1}}],["并重新构建为更高效的形式",{"2":{"92":1}}],["并结合两种不同的聚合操作",{"2":{"81":1}}],["并通过相似度匹配计算注意力权重",{"2":{"92":1}}],["并通过先计算ktv",{"2":{"46":1}}],["并通过线性层进行特征聚合",{"2":{"13":1}}],["并最终合成三重注意力",{"2":{"31":1}}],["并在最后的特征映射中仅聚合一次所有特征",{"2":{"33":1}}],["并在推理阶段实现快速推理",{"2":{"18":1}}],["并在推理阶段通过简化为单分支结构来减少内存消耗",{"2":{"18":1}}],["并在不同的分辨率级别上使用2d",{"2":{"90":1}}],["并在不同的头部中以不同的扩张率执行多尺度swda",{"2":{"13":1}}],["并在不同的头部中以不同的扩张率执行多尺度swda来提高模型的处理效率和检测精度",{"2":{"8":1}}],["并在不需要复杂操作和额外计算成本的情况下有效地减少自注意机制的冗余",{"2":{"13":1}}],["并送入一个线性层进行特征聚合",{"2":{"13":1}}],["并且调整大小选项设置为",{"2":{"148":5}}],["并且可以作为一个模块加入到现有的网络架构中",{"2":{"31":1}}],["并且以van",{"2":{"20":1}}],["并且根据具体任务和需求可以进行不同的配置",{"2":{"15":1}}],["并且对所有的输出hi",{"2":{"13":1}}],["并且仅进行适用于gpu的密集矩阵乘法运算",{"2":{"9":1}}],["并且此文主要将",{"2":{"2":1}}],["并且页面不是很美观",{"2":{"0":1}}],["并生成局部图像表示",{"2":{"1":1}}],["并生成全局图像表示",{"2":{"1":1}}],["并不影响本文中所说的所有配置",{"2":{"0":1}}],["2x2",{"2":{"175":1}}],["2图示dat可添加的位置",{"0":{"154":1}}],["2图示lskattention可添加的位置",{"0":{"111":1}}],["2600",{"2":{"148":4}}],["2600x2080",{"2":{"148":5}}],["2^",{"2":{"138":1}}],["2^n",{"2":{"45":3}}],["2n−1−12^",{"2":{"138":1}}],["2n−1",{"2":{"138":2}}],["2125",{"2":{"156":1}}],["21",{"2":{"86":1,"106":2,"133":2,"143":2,"165":2,"166":1}}],["2编译链",{"2":{"84":1}}],["2080",{"2":{"148":4}}],["2020",{"2":{"73":1}}],["20",{"2":{"60":2,"97":2,"119":2,"161":2,"169":2}}],["295",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["28",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["22",{"2":{"86":2,"99":2,"166":2}}],["225",{"2":{"60":2,"86":2,"97":2,"99":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["224",{"2":{"19":2,"45":2,"92":2,"102":4}}],["224x224",{"2":{"19":1}}],["258",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["25902624",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["25902640",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["25",{"2":{"60":2,"86":2,"97":2,"99":2,"106":2,"119":2,"133":2,"143":2,"161":2,"163":1,"165":2,"166":2,"169":2,"172":1}}],["256",{"2":{"52":3,"60":4,"86":4,"97":4,"99":4,"106":4,"119":4,"133":4,"143":4,"161":4,"165":4,"166":4,"169":4}}],["255",{"2":{"45":1}}],["2d和3d适应性指的是deformable",{"2":{"90":1}}],["2d和3d适应性",{"0":{"90":1},"1":{"125":1,"135":1,"145":1,"153":1},"2":{"57":1}}],["2d",{"2":{"30":2,"45":1,"90":2,"101":1}}],["2db之间",{"2":{"28":1}}],["23",{"2":{"27":1,"65":1,"97":1,"119":1,"161":1,"169":1}}],["24",{"2":{"19":4,"27":2,"60":2,"92":3,"97":2,"119":2,"161":2,"169":2}}],["2tuple",{"2":{"19":3,"45":6,"102":1}}],["2",{"0":{"6":1,"12":1,"16":1,"18":2,"23":2,"25":1,"31":1,"33":1,"36":1,"42":1,"46":1,"51":1,"53":1,"54":1,"56":2,"57":1,"61":1,"65":1,"67":1,"68":2,"69":1,"70":1,"75":1,"76":2,"79":1,"80":2,"81":1,"84":1,"86":1,"90":1,"91":1,"92":2,"93":1,"94":1,"96":1,"97":2,"106":1,"112":1,"119":2,"121":1,"122":1,"124":1,"130":2,"132":1,"133":1,"134":1,"135":1,"137":1,"142":2,"143":2,"144":2,"152":2,"157":1,"160":1,"165":1,"166":1,"169":2,"173":2,"182":1},"1":{"65":1,"76":1,"81":1,"86":1,"92":1,"97":1,"104":1,"106":1,"117":1,"119":1,"125":1,"128":1,"130":1,"132":1,"133":1,"134":1,"135":1,"138":1,"142":1,"143":1,"144":1,"145":1,"152":1,"153":1,"165":1,"169":1,"173":1},"2":{"0":1,"9":2,"12":1,"13":2,"16":1,"19":50,"23":1,"27":14,"28":1,"30":6,"33":1,"41":2,"45":77,"46":1,"50":7,"51":2,"52":8,"56":1,"57":1,"60":10,"61":4,"67":1,"68":1,"70":1,"73":2,"86":10,"89":17,"90":1,"92":7,"97":10,"99":11,"101":9,"102":23,"106":10,"119":10,"133":10,"138":14,"143":10,"161":10,"162":1,"164":2,"165":4,"166":10,"169":10}}],["其操作步骤与内嵌输出",{"2":{"151":1}}],["其安装很简单",{"2":{"108":1}}],["其可以添加的位置有很多",{"2":{"98":1,"110":1,"146":1,"149":1,"170":1,"180":1}}],["其在每个分类中都显示了相对较高的准确率或者在相似的flops计算量下具有竞争力的准确率",{"2":{"67":1}}],["其变量有",{"2":{"51":1}}],["其生成的",{"2":{"51":1}}],["其内部编译命令来自上文latex",{"2":{"51":1}}],["其主要的核心思想是",{"2":{"48":1}}],["其发布于2022年cvpr2022上同时被评选为best",{"2":{"48":1}}],["其它使用方式看章节四",{"2":{"45":1}}],["其它的注意力机制添加的方式都大致相同",{"2":{"22":1}}],["其解决了两个在传统线性注意力方法中存在的问题",{"2":{"29":1}}],["其方法在定量和定性方面显著优于现有的最先进方法",{"2":{"28":1}}],["其功能是一样的",{"2":{"24":1}}],["其中像素的所有颜色大致相等",{"2":{"162":1}}],["其中侧边栏所展现的就是上文提及的新的",{"2":{"84":1}}],["其中1x1卷积在两者之间共享",{"2":{"81":1}}],["其中name是标签",{"2":{"51":1}}],["其中多出来的第一个选项为进行tex文件的编译",{"2":{"51":1}}],["其中的两外两个模块",{"2":{"64":1}}],["其中的name为这些命令的标签",{"2":{"51":1}}],["其中的",{"2":{"41":1}}],["其中c是通道数",{"2":{"23":1}}],["其中包括rcs",{"2":{"42":1}}],["其中包括",{"2":{"23":1}}],["其中包括自注意力子层",{"2":{"15":1}}],["其中",{"2":{"20":1}}],["其中只涉及到对于硬件友好的稠密矩阵乘法",{"2":{"4":1}}],["其余像素区域",{"2":{"148":3}}],["其余的你没有大家不用添加",{"2":{"77":1}}],["其余使用方式看章节四",{"2":{"19":1}}],["其余如图所示",{"2":{"6":1}}],["其余均为原创内容",{"2":{"0":1}}],["其与本质上是局部操作的卷积",{"2":{"4":1}}],["其全称是",{"2":{"3":1,"8":1}}],["其重要性自不必多说",{"2":{"0":1}}],["1推荐dat可添加的位置",{"0":{"146":1}}],["1代码解读",{"2":{"142":1}}],["19th",{"2":{"138":1}}],["19",{"2":{"97":1,"99":2,"119":1,"161":1,"169":1}}],["1e",{"2":{"89":3}}],["1准确率上相对于原始模型的提升",{"2":{"67":1}}],["1准确率",{"2":{"67":1}}],["1准确率和计算量",{"2":{"67":1}}],["1conv",{"2":{"45":5}}],["165",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["16",{"2":{"45":1,"52":1,"60":4,"86":2,"97":4,"99":4,"101":2,"106":2,"119":4,"133":2,"143":2,"161":4,"165":2,"166":2,"169":4}}],["17",{"2":{"27":2}}],["180",{"2":{"141":4}}],["18",{"2":{"27":2,"86":2,"106":2,"133":2,"143":2,"165":2,"166":2}}],["13",{"2":{"27":2,"52":2,"99":2}}],["15",{"2":{"27":2,"60":3,"86":2,"97":1,"106":2,"119":1,"133":2,"143":2,"161":1,"165":2,"166":2,"169":1}}],["1x1卷积",{"2":{"81":1}}],["1x1",{"2":{"23":1,"52":5}}],["10mb",{"2":{"95":1}}],["1024",{"2":{"60":6,"86":6,"97":6,"99":6,"106":6,"119":6,"133":6,"143":6,"161":6,"165":6,"166":6,"169":6}}],["100",{"2":{"45":1,"168":2}}],["10",{"0":{"159":1},"2":{"19":1,"73":1,"99":2}}],["123456789代码解读",{"2":{"142":1}}],["123456789101112131415161718代码解读",{"2":{"132":1}}],["123456789101112131415161718192021代码解读",{"2":{"51":1}}],["1234567891011121314151617181920212223242526272829303132333435363738394041代码解读",{"2":{"51":1}}],["123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116代码解读",{"2":{"41":1}}],["12345678910111213141516代码解读",{"2":{"73":1}}],["123代码解读",{"2":{"142":1}}],["12n−1−1",{"2":{"138":1}}],["128",{"2":{"60":2,"86":2,"97":2,"99":2,"106":2,"119":2,"133":2,"143":2,"161":2,"165":2,"166":2,"169":2}}],["12",{"2":{"19":4,"60":2,"86":2,"97":2,"106":2,"119":2,"133":2,"142":1,"143":2,"161":2,"165":2,"166":2,"169":2}}],["12656706",{"2":{"2":1}}],["1版本",{"2":{"17":1}}],["11166544",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["11166560",{"2":{"60":1,"86":1,"97":1,"99":1,"106":1,"119":1,"133":1,"143":1,"161":1,"165":1,"166":1,"169":1}}],["112x112",{"2":{"19":4}}],["11",{"0":{"164":1},"2":{"17":1,"27":3,"52":2,"65":1,"84":1}}],["1",{"0":{"2":1,"12":1,"16":1,"34":1,"36":1,"41":1,"43":2,"44":1,"46":1,"50":1,"53":1,"57":1,"64":1,"65":1,"69":1,"70":1,"73":1,"74":1,"81":2,"83":1,"85":2,"86":1,"92":1,"96":1,"98":1,"99":1,"106":1,"108":1,"109":1,"113":1,"116":1,"125":2,"126":1,"127":2,"132":1,"133":1,"134":1,"135":1,"137":1,"145":1,"147":1,"149":1,"153":1,"161":1,"165":1,"180":1},"1":{"43":1,"53":1,"64":1,"81":1,"85":1,"92":1,"96":1,"109":1,"127":1,"137":1,"147":1},"2":{"0":1,"9":2,"12":1,"13":1,"16":1,"19":45,"23":1,"24":1,"27":85,"28":1,"29":1,"30":24,"33":1,"45":127,"46":1,"50":12,"52":18,"56":1,"57":1,"60":52,"61":12,"67":1,"68":1,"70":1,"86":48,"89":39,"90":1,"92":33,"97":52,"99":48,"101":23,"102":43,"106":46,"119":52,"133":46,"138":17,"143":46,"161":52,"165":46,"166":48,"169":49}}],["注释按比例调整",{"2":{"148":1}}],["注释内容",{"2":{"138":1}}],["注释",{"2":{"138":1}}],["注意",{"2":{"138":2,"181":1}}],["注意修改路径",{"2":{"132":3,"142":3,"164":3}}],["注意到",{"2":{"84":1}}],["注意力图显示了具有高注意力得分的块在查询块周围稀疏分布",{"2":{"13":1}}],["注意力的一个关键特性是全局感受野",{"2":{"4":1}}],["注",{"2":{"0":3,"24":2,"41":2,"51":2,"73":1,"84":1,"138":1,"142":1}}],["为",{"2":{"178":1}}],["为白色像素",{"2":{"148":1}}],["为黑色像素",{"2":{"148":1}}],["为下文解读之用",{"2":{"132":1}}],["为什么选择在",{"0":{"107":1}}],["为什么这么简单是因为我修改了官方的代码",{"2":{"77":1}}],["为默认选项",{"2":{"51":1}}],["为您添加的其余代码",{"2":{"41":1}}],["为了出现和内嵌输出具有相同的效果",{"2":{"151":1}}],["为了更方便进行编译",{"2":{"84":1}}],["为了清晰展示",{"2":{"80":1}}],["为了测试",{"2":{"73":1}}],["为了解决这些问题",{"2":{"56":1}}],["为了后面提出论文提到的注意力机制在线性注意力机制上的优化",{"2":{"46":1}}],["为了后面不必要的麻烦",{"2":{"2":1}}],["为了以高效的方式全局定位有价值的键",{"2":{"4":1}}],["为了减少注意力的复杂度",{"2":{"4":1}}],["为了让更多人能够有一个比较清晰的了解",{"2":{"0":1}}],["为其专属定制编辑器",{"2":{"0":1}}],["很多博主也只是贴上了配置代码",{"2":{"0":1}}],["笔者会虚心接受这些产生错误的地方",{"2":{"164":1}}],["笔者也只是一个初学者",{"2":{"164":1}}],["笔者将快捷键设置为ctrl+alt+r",{"2":{"84":1}}],["笔者编写了一份简单的",{"2":{"73":1}}],["笔者选择",{"2":{"95":1}}],["笔者选择使用lastused",{"2":{"51":1}}],["笔者选用的",{"2":{"2":1}}],["笔者此处设置为",{"2":{"51":1}}],["笔者觉得菜单多了此选项较方便",{"2":{"51":1}}],["笔者只对几个要点进行提及",{"2":{"6":1}}],["笔者进入了清华大学镜像网站",{"2":{"2":1}}],["笔者配置了好久",{"2":{"0":1}}],["笔者前期使用的是texstudio进行文档的编译的",{"2":{"0":1}}],["最高为",{"2":{"172":1}}],["最终的效果图如下",{"2":{"80":1}}],["最终得到三重注意力输出",{"2":{"31":1}}],["最后添加完你想要的数据增强操作之后",{"2":{"179":1}}],["最后强调一下triplet",{"2":{"83":1}}],["最后",{"2":{"23":1,"28":1}}],["最后经过另一个卷积层和sigmoid函数生成注意力权重",{"2":{"23":1}}],["最后通过sigmoid函数生成每个通道的权重",{"2":{"23":1}}],["最后本文会手把手教你添加rcs",{"2":{"3":1}}],["最突出的特点就是其强大的插件功能",{"2":{"0":1}}],["最让人头疼的是",{"2":{"0":1}}],["且同样支持双向同步",{"2":{"151":1}}],["且根据需要关闭标签",{"2":{"151":1}}],["且根据笔者使用来看",{"2":{"95":1}}],["且侧面带有书签",{"2":{"151":1}}],["且支持双向同步功能",{"2":{"95":1}}],["且需要为英文路径",{"2":{"51":1}}],["且弹窗弹出比较烦人",{"2":{"51":1}}],["且代码设置可以直接克隆别人的代码到自己的编辑器中",{"2":{"24":1}}],["且所有引用在文中或文末注明了来源",{"2":{"0":1}}],["且",{"2":{"0":1}}],["颜值也很高",{"2":{"0":1}}],["不带批注的图像将导致训练数据集的性能出现问题",{"2":{"181":1}}],["不然会报错",{"2":{"142":1}}],["不给大家描述过程了",{"2":{"91":1}}],["不一定位置对并没有进行多次实验调参什么的",{"2":{"82":1}}],["不需要进行更改",{"2":{"51":1}}],["不包含外部",{"2":{"41":1}}],["不同的是",{"2":{"24":1}}],["不同的扩张率",{"2":{"13":1}}],["不同",{"2":{"4":1}}],["不同级别括号用不同颜色标注了",{"2":{"0":1}}],["不光让大家会添加到自己的模型在写论文的时候也能够有一定的参照",{"2":{"3":1}}],["不要对其进行修改",{"2":{"2":1}}],["不怎么好用",{"2":{"2":1}}],["不在本文探讨范围之内",{"2":{"0":1}}],["它使用在图像的不同图块区域计算的直方图",{"2":{"162":1}}],["它不仅提供免费的数据集",{"2":{"105":1}}],["它不仅能够对代码高亮",{"2":{"0":1}}],["它包含三个头部的1x1卷积",{"2":{"81":1}}],["它比较了卷积",{"2":{"81":1}}],["它只关注图像中的一小部分关键区域",{"2":{"69":1}}],["它是由一个标准卷积层生成",{"2":{"68":1}}],["它模仿自注意力",{"2":{"68":1}}],["它的核心思想是",{"2":{"59":1,"70":1}}],["它解决了传统线性注意力方法的两个主要问题",{"2":{"56":1}}],["它需要计算查询和键之间的成对相似度",{"2":{"46":1}}],["它们的维度为",{"2":{"46":1}}],["它们分别对应不同的感受野大小",{"2":{"13":1}}],["它在所有测试中都表现得非常好",{"2":{"28":1}}],["它结合了通道注意力和自注意力机制",{"2":{"28":1}}],["它将一个大的2d核分解成水平",{"2":{"20":1}}],["它主要通过将深度卷积层的2d卷积核分解为水平和垂直1d卷积核",{"2":{"14":1}}],["它通过三个不同的视角来分析输入的数据",{"2":{"5":1}}],["它具有较高的计算复杂度并且需要大量的内存",{"2":{"4":1}}],["它对于括号根本就没有高亮",{"2":{"0":1}}],["话不多说",{"2":{"0":1}}],["而不会影响基础数据集",{"2":{"178":1}}],["而不是",{"2":{"142":1}}],["而不是在训练时进行增强有几个关键的好处",{"2":{"107":1}}],["而不是固定地处理整个图像",{"2":{"69":1}}],["而不是直接在细粒度的标记级别上进行过滤",{"2":{"4":1}}],["而3d",{"2":{"90":1}}],["而dat引入了可变形注意力机制",{"2":{"69":1}}],["而never命令做不到这一点",{"2":{"51":1}}],["而有时候将",{"2":{"51":1}}],["而编译链就解决了这个问题",{"2":{"51":1}}],["而使用",{"2":{"51":1}}],["而",{"2":{"51":1}}],["而command为在该拓展中的编译方式",{"2":{"51":1}}],["而第二个选项为进行正向同步",{"2":{"51":1}}],["而每个代码块儿的最后一句是不需要加上",{"2":{"41":1}}],["而且对非拉丁字体的支持更好",{"2":{"51":1}}],["而且还实现了语义信息的有效提取",{"2":{"33":1}}],["而且计算代价小",{"2":{"16":1}}],["而言不那么直观",{"2":{"24":1}}],["而代码设置页面虽然相对",{"2":{"24":1}}],["而自注意力则关注于图像内部各个位置之间的关系",{"2":{"21":1,"36":1}}],["而其它块的注意力得分较低",{"2":{"13":1}}],["而在biformer中",{"2":{"9":1}}],["而对于我们大部分人来说",{"2":{"2":1}}],["而下层路由器则负责捕捉局部区域的细节",{"2":{"1":1}}],["而visual",{"2":{"0":1}}],["而选择一个比较好的编译器是很重要的",{"2":{"0":1}}],["但它们不是方形的",{"2":{"148":1}}],["但源图像数据丢失",{"2":{"148":1}}],["但不会丢失源图像数据",{"2":{"148":1}}],["但在实际实现中实际上有更多的点",{"2":{"80":1}}],["但在现代gpu上效率较低",{"2":{"4":1}}],["但其只能测试一部分功能",{"2":{"73":1}}],["但现有的线性注意力方法仍存在性能下降的问题",{"2":{"56":1}}],["但笔者不建议这么做",{"2":{"51":1}}],["但却可以对自己想要的功能直接进行代码编写",{"2":{"24":1}}],["但一些设置需要去寻找",{"2":{"24":1}}],["但是",{"2":{"175":1}}],["但是本文的方法需要按照有参的注意力机制添加但是只是不需要进行传入参数在yaml文件中",{"2":{"102":1}}],["但是如果你想要放在残差中配置c2f的时候就需要按照c2f的配置来添加",{"2":{"83":1}}],["但是如果都替换的话我觉得那就是rcs",{"2":{"52":1}}],["但是并不能产生决定性结果",{"2":{"78":1}}],["但是组合用很多具体那种最有效果都不一定",{"2":{"75":1,"155":1}}],["但是使用更少的参数和计算量",{"2":{"68":1}}],["但是在rcs",{"2":{"52":1}}],["但是可以作为一个参考",{"2":{"48":1}}],["但是其也可以用在我们的yolo系列当中从而提高检测精度",{"2":{"29":1,"56":1}}],["但是其编译速度比较慢",{"2":{"0":1}}],["但是效果挺好的也是10月份最新的成果非常适合添加到大家自己的论文中",{"2":{"21":1}}],["但建议在不明白各个选项的作用时",{"2":{"2":1}}],["但texstudio的代码高亮功能实在是",{"2":{"0":1}}],["至少对笔者而言是如此",{"2":{"0":1}}],["秃头专业",{"2":{"0":1}}]],"serializationVersion":2}';export{t as default};
